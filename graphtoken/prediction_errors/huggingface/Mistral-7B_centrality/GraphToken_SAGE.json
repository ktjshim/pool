"```json\n{\n  \"task_steps\": [\n    \"Load the audio file 'example.wav'\",\n    \"Apply audio enhancement to the loaded audio file using 'Audio Editing' task\",\n    \"Transcribe the enhanced audio using 'Automatic Speech Recognition' task\",\n    \"Load the image file 'example.jpg'\",\n    \"Classify the place depicted in the image using 'Image Classification' task\",\n    \"Extract the question 'What is the most notable feature of this place?' from the transcribed speech using 'Question Answering' task\",\n    \"Classify the tokens of the question answer using 'Token Classification' task\",\n    \"Generate a conversational response based on the classified tokens using 'Conversational' task\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Audio Editing\"\n    },\n    {\n      \"task_name\": \"Automatic Speech Recognition\"\n    },\n    {\n      \"task_name\": \"Image Classification\"\n    },\n    {\n      \"task_name\": \"Question Answering\"\n    },\n    {\n      \"task_name\": \"Token Classification\"\n    },\n    {\n      \"task_name\": \"Conversational\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Audio Editing\", \"target\": \"Automatic Speech Recognition\"},\n    {\"source\": \"Image Classification\", \"target\": \"Question Answering\"},\n    {\"source\": \"Question Answering\", \"target\": \"Token Classification\"},\n    {\"source\": \"Token Classification\", \"target\": \"Conversational\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Read the input text file and extract the speech text.\",\n    \"Use Text-to-Speech API to convert the text to natural sounding speech.\",\n    \"Use Automatic Speech Recognition API to ensure the generated speech is clear and error-free.\",\n    \"Use Audio-to-Audio API to enhance the audio quality of the generated speech.\",\n    \"Save the enhanced audio version of the speech to an output audio file.\"\n  ],\n  \"task_nodes\": [\n    \"Text-to-Speech\",\n    \"Automatic Speech Recognition\",\n    \"Audio-to-Audio\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Text-to-Speech\", \"target\": \"Automatic Speech Recognition\"},\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Audio-to-Audio\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load the audio file 'example.wav' for emotion and speaker recognition.\",\n    \"Invoke 'Automatic Speech Recognition' API to transcribe the audio file into text.\",\n    \"Invoke 'Speaker Recognition' API to identify the speaker from the transcribed text.\",\n    \"Invoke 'Emotion Recognition' API to determine the emotion from the transcribed text.\",\n    \"Generate a text description based on the emotion and speaker information.\",\n    \"Invoke 'Text-to-Image' API to create an image based on the generated text description.\",\n    \"Invoke 'Image Editing' API to edit the 'example.jpg' image using the generated text description.\",\n    \"Invoke 'Text-to-Speech' API to generate an audio file from the text description.\",\n    \"Invoke 'Audio-to-Text' API to transcribe the generated audio file and compare it with the original transcribed text to ensure accuracy.\"\n  ],\n  \"task_nodes\": [\n    \"Automatic Speech Recognition\",\n    \"Speaker Recognition\",\n    \"Emotion Recognition\",\n    \"Text Generation\",\n    \"Text-to-Image\",\n    \"Image Editing\",\n    \"Text-to-Speech\",\n    \"Audio-to-Text\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Speaker Recognition\"},\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Emotion Recognition\"},\n    {\"source\": \"Text Generation\", \"target\": \"Text-to-Image\"},\n    {\"source\": \"Text Generation\", \"target\": \"Text-to-Speech\"},\n    {\"source"
"```json\n{\n  \"task_steps\": [\n    \"Load 'example.jpg' image\",\n    \"Perform Image Preprocessing\",\n    \"Execute Image Depth Estimation\",\n    \"Extract Depth Map from output\",\n    \"Execute Object Detection\",\n    \"Parse Object Detection output\",\n    \"Identify largest object from parsed output\",\n    \"Execute Visual Question Answering\",\n    \"Provide visual question 'What is the largest object in the image?'\",\n    \"Parse Visual Question Answering output\",\n    \"Execute Text-to-Speech to read the answer\",\n    \"Execute Document Question Answering\",\n    \"Provide question 'What are the tokens in the discussion about the largest object?'\",\n    \"Parse Document Question Answering output\"\n  ],\n  \"task_nodes\": [\n    \"Image Classification\",\n    \"Depth Estimation\",\n    \"Object Detection\",\n    \"Visual Question Answering\",\n    \"Text-to-Speech\",\n    \"Document Question Answering\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification\", \"target\": \"Depth Estimation\"},\n    {\"source\": \"Depth Estimation\", \"target\": \"Object Detection\"},\n    {\"source\": \"Object Detection\", \"target\": \"Visual Question Answering\"},\n    {\"source\": \"Visual Question Answering\", \"target\": \"Text-to-Speech\"},\n    {\"source\": \"Text-to-Speech\", \"target\": \"Document Question Answering\"}\n  ]\n}\n```\n\nThis JSON format represents the task steps, task nodes, and task links required to fulfill the user's request. The task steps are described in detail, and the task nodes represent the specific tasks to be"
"```json\n{\n  \"task_steps\": [\n    \"Generate an image based on the given text using Text-to-Image task.\",\n    \"Classify the generated image using Image Classification task.\",\n    \"Extract the main subject from the given text using Question Answering task.\",\n    \"Use Text-to-Speech task to convert the answer into an audio file.\"\n  ],\n  \"task_nodes\": [\n    \"Text-to-Image\",\n    \"Image Classification\",\n    \"Question Answering\",\n    \"Text-to-Speech\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Text-to-Image\", \"target\": \"Image Classification\"},\n    {\"source\": \"Question Answering\", \"target\": \"Text-to-Speech\"},\n    {\"source\": \"Image Classification\", \"target\": \"Question Answering\"}\n  ]\n}\n```\n\nThis JSON format represents the task steps, task nodes, and task links required to fulfill the user's request. The Text-to-Image task generates an image based on the given text, the Image Classification task classifies the generated image, the Question Answering task extracts the main subject from the given text, and the Text-to-Speech task converts the answer into an audio file. The task links show the dependencies among the tasks, with the Image Classification task depending on the Text-to-Image task and the Question Answering task depending on the extracted main subject."
"```json\n{\n  \"task_steps\": [\n    {\n      \"step_description\": \"Load and preprocess the input image (example.jpg) for object detection and image classification.\",\n      \"task_name\": \"Image Classification\"\n    },\n    {\n      \"step_description\": \"Detect objects in the image using object detection model.\",\n      \"task_name\": \"Object Detection\"\n    },\n    {\n      \"step_description\": \"Extract the bounding boxes and class labels for each detected object.\",\n      \"task_name\": \"Image Segmentation\"\n    },\n    {\n      \"step_description\": \"Extract the summarized information for each detected object using summarization model.\",\n      \"task_name\": \"Summarization\"\n    },\n    {\n      \"step_description\": \"Perform token classification on the summarized information for each detected object.\",\n      \"task_name\": \"Token Classification\"\n    },\n    {\n      \"step_description\": \"Generate conversational response based on the detected objects, their summarized information, and token classification.\",\n      \"task_name\": \"Conversational\"\n    }\n  ],\n  \"task_nodes\": [\n    \"Image Classification\",\n    \"Object Detection\",\n    \"Image Segmentation\",\n    \"Summarization\",\n    \"Token Classification\",\n    \"Conversational\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification\", \"target\": \"Object Detection\"},\n    {\"source\": \"Object Detection\", \"target\": \"Image Segmentation\"},\n    {\"source\": \"Object Detection\", \"target\": \"Summarization\"},\n    {\"source\": \"Object Detection\", \"target\": \"Token Classification\"},\n   "
"```json\n{\n  \"task_steps\": [\n    \"Load image 'example.jpg' and extract text descriptions using OCR.\",\n    \"Perform text token classification using the 'Text Classification' task.\",\n    \"Detect objects present in the image using the 'Object Detection' task.\",\n    \"Classify the detected objects using the 'Image Classification' task.\",\n    \"Edit the image based on the classified tokens using the 'Image Editing' task.\",\n    \"Perform tabular classification on the edited image using the 'Tabular Classification' task.\",\n    \"Summarize the results of the previous tasks using the 'Summarization' task.\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Text Classification\"\n    },\n    {\n      \"task_name\": \"Object Detection\"\n    },\n    {\n      \"task_name\": \"Image Classification\"\n    },\n    {\n      \"task_name\": \"Image Editing\"\n    },\n    {\n      \"task_name\": \"Tabular Classification\"\n    },\n    {\n      \"task_name\": \"Summarization\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Load image and extract text descriptions\", \"target\": \"Text Classification\"},\n    {\"source\": \"Text Classification\", \"target\": \"Object Detection\"},\n    {\"source\": \"Object Detection\", \"target\": \"Image Classification\"},\n    {\"source\": \"Image Classification\", \"target\": \"Image Editing\"},\n    {\"source\": \"Image Editing\", \"target\": \"Tabular Classification\"},\n    {\"source\": \"Tabular Classification\", \"target\": \"Summarization\"}\n  ]\n}\n```"
"{\n  \"task_steps\": [\n    \"Load the audio file 'example.wav'\",\n    \"Perform Automatic Speech Recognition (ASR) to extract text from the audio file\",\n    \"Perform Text-to-Speech (TTS) to listen to the recognized text for confirmation\",\n    \"If the recognized text does not match the actual content of the audio message, repeat the ASR and TTS steps until accurate transcription is achieved\",\n    \"Summarize the content of the audio message for easier understanding\"\n  ],\n  \"task_nodes\": [\n    \"Automatic Speech Recognition\",\n    \"Text-to-Speech\",\n    \"Summarization\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Audio Classification\", \"target\": \"Automatic Speech Recognition\"},\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text-to-Speech\"},\n    {\"source\": \"Text-to-Speech\", \"target\": \"Summarization\"}\n  ]\n}\n\n# EXPLANATION #:\n# The user request is to understand the content of an audio message.\n# To accomplish this, we will first perform Automatic Speech Recognition (ASR) to extract text from the audio file.\n# Next, we will use Text-to-Speech (TTS) to listen to the recognized text for confirmation.\n# If the recognized text does not match the actual content of the audio message, we will repeat the ASR and TTS steps until accurate transcription is achieved.\n# Finally, we will summarize the content of the audio message for easier understanding.\n# The task steps and task nodes are aligned, and the task links reflect the dependencies among the tasks.\n# The task list"
"```json\n{\n  \"task_steps\": [\n    \"Load and preprocess the document image 'example.jpg' for text-to-image model\",\n    \"Perform text-to-speech conversion on the input text 'What is the fastest land animal?' using Text-to-Speech task\",\n    \"Apply audio enhancement techniques to improve the audio quality using Audio Editing task\",\n    \"Transcribe the enhanced audio back into text using Automatic Speech Recognition task\",\n    \"Load and preprocess the document image 'example.jpg' for text and question extraction using Document Question Answering task\",\n    \"Extract the question 'What is the fastest land animal?' from the transcribed text\",\n    \"Use the extracted question and the document image to find the answer using Document Question Answering task\",\n    \"Return the answer as the final result\"\n  ],\n  \"task_nodes\": [\n    \"Text-to-Speech\",\n    \"Audio Editing\",\n    \"Automatic Speech Recognition\",\n    \"Document Question Answering\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Text-to-Speech\", \"target\": \"Audio Editing\"},\n    {\"source\": \"Audio Editing\", \"target\": \"Automatic Speech Recognition\"},\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Document Question Answering\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load the document image 'example.jpg' using an Image Classification API to extract text and perform Optical Character Recognition (OCR) to extract the title text.\",\n    \"Use a Text Classification API to identify the main color mentioned in the user's question from the title text.\",\n    \"Use a Text-to-Image API to generate an image of a title with the identified main color.\",\n    \"Load the original document image 'example.jpg' using an Image Editing API to modify the title color to match the generated title image.\",\n    \"Perform Image Segmentation on the edited document image using an Image Segmentation API to extract the title region.\",\n    \"Return the segmentation result\"\n  ],\n  \"task_nodes\": [\n    \"Text Classification\",\n    \"Text-to-Image\",\n    \"Image Editing\",\n    \"Image Segmentation\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification\", \"target\": \"Text Classification\"},\n    {\"source\": \"Text Classification\", \"target\": \"Text-to-Image\"},\n    {\"source\": \"Text-to-Image\", \"target\": \"Image Editing\"},\n    {\"source\": \"Image Editing\", \"target\": \"Image Segmentation\"}\n  ]\n}\n```\n\nNote: The first task node \"Image Classification\" is assumed to be used for loading the image and performing OCR. If this functionality is not available in an Image Classification API, a separate API for loading and OCR should be used and added as a task node."
"```json\n{\n  \"task_steps\": [\n    \"Load the example.jpg image\",\n    \"Apply color transformation to change the color of the car to red\",\n    \"Save the modified image as example_red.jpg\",\n    \"Perform image classification on example_red.jpg\",\n    \"Convert the classification result to text\",\n    \"Generate speech from the textual classification result\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image Editing\",\n      \"input\": [\"example.jpg\"],\n      \"output\": [\"example_red.jpg\"]\n    },\n    {\n      \"task_name\": \"Image Classification\",\n      \"input\": [\"example_red.jpg\"],\n      \"output\": [\"classification_result\"]\n    },\n    {\n      \"task_name\": \"Text-to-Speech\",\n      \"input\": [\"classification_result\"],\n      \"output\": [\"speech_output\"]\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Editing\", \"target\": \"Image Classification\"},\n    {\"source\": \"Image Classification\", \"target\": \"Text-to-Speech\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load the example.jpg image into memory.\",\n    \"Perform object segmentation on the image to identify and extract individual objects.\",\n    \"For each object, perform depth estimation to determine its distance from the camera.\",\n    \"Classify each object based on its segmented pixels and depth estimation using a tabular classifier.\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Object Segmentation\"\n    },\n    {\n      \"task_name\": \"Depth Estimation\"\n    },\n    {\n      \"task_name\": \"Tabular Classification\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Object Segmentation\", \"target\": \"Depth Estimation\"},\n    {\"source\": \"Depth Estimation\", \"target\": \"Tabular Classification\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load and preprocess image 'example.jpg' for tabular classification.\",\n    \"Perform tabular classification on the image to extract table content.\",\n    \"Load and preprocess image 'target_example.jpg' for image classification.\",\n    \"Perform image classification on 'target_example.jpg' to understand its characteristics.\",\n    \"Extract table header from the classified table content.\",\n    \"Edit the extracted table header by changing its color to blue using image editing.\",\n    \"Merge edited table header back to the classified table content.\",\n    \"Save the edited table content as a new image.\",\n    \"Load and preprocess the new image for image-to-image task.\",\n    \"Perform image-to-image task to adjust the characteristics of the edited table image to match the target image.\"\n  ],\n  \"task_nodes\": [\n    \"Tabular Classification\",\n    \"Image Classification\",\n    \"Image Editing\",\n    \"Image-to-Image\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Tabular Classification\", \"target\": \"Image Classification\"},\n    {\"source\": \"Image Classification\", \"target\": \"Image Editing\"},\n    {\"source\": \"Image Editing\", \"target\": \"Image-to-Image\"}\n  ]\n}\n```"
"{\n  \"task_steps\": [\n    \"Load image 'example.jpg'\",\n    \"Apply image enhancement techniques to improve image quality\",\n    \"Perform image segmentation to extract text regions\",\n    \"Extract text from the segmented regions using OCR (Optical Character Recognition) technology\",\n    \"Generate a script based on the extracted text\",\n    \"Create a video using the generated script and appropriate visuals or animations\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image Classification\",\n      \"task_description\": \"Determine the image type and suitability for further processing\"\n    },\n    {\n      \"task_name\": \"Image Enhancement\",\n      \"task_description\": \"Improve the image quality by adjusting brightness, contrast, and other image properties\"\n    },\n    {\n      \"task_name\": \"Image Segmentation\",\n      \"task_description\": \"Identify and separate the text regions from the background of the image\"\n    },\n    {\n      \"task_name\": \"Text Extraction\",\n      \"task_description\": \"Extract the text from the segmented regions using OCR technology\"\n    },\n    {\n      \"task_name\": \"Text Generation\",\n      \"task_description\": \"Generate a script based on the extracted text\"\n    },\n    {\n      \"task_name\": \"Video Generation\",\n      \"task_description\": \"Create a video using the generated script and appropriate visuals or animations\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification\", \"target\": \"Image Enhancement\"},\n    {\"source\": \"Image Enhancement\", \"target\": \"Image Segmentation\"},"
"{\n  \"task_steps\": [\n    \"Load the input image 'example.jpg' for image editing.\",\n    \"Identify the river region in the image using Image Segmentation.\",\n    \"Replace the river region with a forest using Image Editing.\",\n    \"Save the edited image with a new name 'edited_example.jpg'\"\n  ],\n  \"task_nodes\": [\n    \"Image Segmentation\",\n    \"Image Editing\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification\", \"target\": \"Image Segmentation\"},\n    {\"source\": \"Image Segmentation\", \"target\": \"Image Editing\"},\n    {\"source\": \"Image Editing\", \"target\": \"Text-to-Speech\"},\n    {\"source\": \"Text-to-Speech\", \"target\": \"Automatic Speech Recognition\"},\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text-to-Text\"},\n    {\"source\": \"Text-to-Text\", \"target\": \"Text-to-Image\"},\n    {\"source\": \"Text-to-Image\", \"target\": \"Image Generation\"},\n    {\"source\": \"Image Generation\", \"target\": \"Image Classification\"}\n  ]\n  },\n  {\n    \"warning\": \"The user request does not exactly match any task in the given TASK LIST. However, based on the user's intent, the following JSON is generated as a close approximation.\",\n    \"task_steps\": [\n      \"Load the input image 'example.jpg' for image editing.\",\n      \"Identify the river region in the image using Image Segmentation.\",\n      \"Replace the river region with a forest using Image Editing.\",\n      \"Save the edited image with a new name 'ed"
"```json\n{\n  \"task_steps\": [\n    \"Load image example.jpg\",\n    \"Perform image segmentation on example.jpg to extract objects\",\n    \"For each object, perform text extraction to get text description\",\n    \"Convert text description to speech using Text-to-Speech API\",\n    \"Record speech output using Automatic Speech Recognition API\",\n    \"Transcribe recorded speech back to text\",\n    \"Compare original text description and transcribed text using Sentence Similarity API\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image Segmentation\"\n    },\n    {\n      \"task_name\": \"Text Extraction\"\n    },\n    {\n      \"task_name\": \"Text-to-Speech\"\n    },\n    {\n      \"task_name\": \"Automatic Speech Recognition\"\n    },\n    {\n      \"task_name\": \"Text Transcription\"\n    },\n    {\n      \"task_name\": \"Sentence Similarity\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Segmentation\", \"target\": \"Text Extraction\"},\n    {\"source\": \"Text Extraction\", \"target\": \"Text-to-Speech\"},\n    {\"source\": \"Text-to-Speech\", \"target\": \"Automatic Speech Recognition\"},\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text Transcription\"},\n    {\"source\": \"Text Extraction\", \"target\": \"Sentence Similarity\"},\n    {\"source\": \"Text Transcription\", \"target\": \"Sentence Similarity\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load 'example.jpg' image into memory.\",\n    \"Perform image segmentation on 'example.jpg' to extract text-containing areas.\",\n    \"For each text-containing area, perform OCR (Optical Character Recognition) to extract raw text.\",\n    \"Translate each raw text into English using a translation API.\",\n    \"Perform entity recognition on the English translated text to identify entities such as dates, individuals, and places.\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image Segmentation\"\n    },\n    {\n      \"task_name\": \"OCR (Optical Character Recognition)\"\n    },\n    {\n      \"task_name\": \"Text Translation\"\n    },\n    {\n      \"task_name\": \"Entity Recognition\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Segmentation\", \"target\": \"OCR (Optical Character Recognition)\"},\n    {\"source\": \"OCR (Optical Character Recognition)\", \"target\": \"Text Translation\"},\n    {\"source\": \"Text Translation\", \"target\": \"Entity Recognition\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load the example.wav file into the audio processing system.\",\n    \"Apply audio denoising techniques to enhance the audio quality.\",\n    \"Perform speaker separation to isolate the user's voice from other sounds.\",\n    \"Recognize the user's command using Automatic Speech Recognition (ASR).\",\n    \"Translate the recognized command from English to French using Machine Translation.\",\n    \"Generate a conversational response in French using Text Generation.\",\n    \"Create a video with the conversational response using Text-to-Video.\",\n    \"Save the final video output.\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Audio Denoising\"\n    },\n    {\n      \"task_name\": \"Speaker Separation\"\n    },\n    {\n      \"task_name\": \"ASR (Automatic Speech Recognition)\"\n    },\n    {\n      \"task_name\": \"Machine Translation\"\n    },\n    {\n      \"task_name\": \"Text Generation\"\n    },\n    {\n      \"task_name\": \"Text-to-Video\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Audio Denoising\", \"target\": \"Speaker Separation\"},\n    {\"source\": \"Speaker Separation\", \"target\": \"ASR\"},\n    {\"source\": \"ASR\", \"target\": \"Machine Translation\"},\n    {\"source\": \"Machine Translation\", \"target\": \"Text Generation\"},\n    {\"source\": \"Text Generation\", \"target\": \"Text-to-Video\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load the given audio file 'example.wav'.\",\n    \"Perform Automatic Speech Recognition (ASR) to extract text from the audio file.\",\n    \"Generate a depth image from the text description using Text-to-Image.\",\n    \"Perform Image Preprocessing on the depth image.\",\n    \"Perform Image Segmentation on the depth image to extract table region.\",\n    \"Perform Tabular Classification on the table region to identify the table.\",\n    \"Perform OCR (Optical Character Recognition) on the table to extract text content.\",\n    \"Perform Translation on the table content.\",\n    \"Perform Token Classification on the translated table content.\",\n    \"Generate a summary of the token classified table content.\"\n  ],\n  \"task_nodes\": [\n    \"Automatic Speech Recognition (ASR)\",\n    \"Text-to-Image (Depth Image Generation)\",\n    \"Image Segmentation\",\n    \"Tabular Classification\",\n    \"Optical Character Recognition (OCR)\",\n    \"Translation\",\n    \"Token Classification\",\n    \"Text Generation (Summary)\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Automatic Speech Recognition (ASR)\", \"target\": \"Text-to-Image (Depth Image Generation)\"},\n    {\"source\": \"Text-to-Image (Depth Image Generation)\", \"target\": \"Image Segmentation\"},\n    {\"source\": \"Image Segmentation\", \"target\": \"Tabular Classification\"},\n    {\"source\": \"Tabular Classification\", \"target\": \"Optical Character Recognition (OCR)\"},\n    {\"source\": \"Optical Character Recognition (OCR)\", \"target"
"{\n  \"task_steps\": [\n    \"Load and preprocess 'example.jpg' image containing the table.\",\n    \"Perform Object Detection on the image to identify and extract table regions.\",\n    \"Perform Tabular Classification on the extracted table regions to identify and extract relevant columns and rows.\",\n    \"Perform Text Extraction on the identified columns and rows to obtain the textual data.\",\n    \"Perform Text Preprocessing on the extracted textual data to clean and normalize it.\",\n    \"Perform Text-to-Frequency analysis on the preprocessed textual data to determine the frequency of each item.\",\n    \"Identify the most common item based on the frequency analysis.\",\n    \"Generate a summary text describing the most common item.\",\n    \"Generate a text-to-speech output of the summary text.\",\n    \"Generate a blank slide for the video.\",\n    \"Overlay the text-to-speech output as text on the blank slide.\",\n    \"Create an animation effect to highlight the most common item in the table.\",\n    \"Combine the slide with the animation effect and the text-to-speech output to create a video segment.\",\n    \"Repeat the process for all identified questions and table images.\",\n    \"Combine all video segments into a final video.\"\n  ],\n  \"task_nodes\": [\n    \"Object Detection\",\n    \"Tabular Classification\",\n    \"Text Extraction\",\n    \"Text Preprocessing\",\n    \"Text-to-Frequency\",\n    \"Text-to-Speech\",\n    \"Video Generation\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Preprocessing\", \"target\": \"Object Detection\"},\n    {\"source\": \"Object Detection\", \"target\": \"Tabular Classification\"},\n"
"```json\n{\n  \"task_steps\": [\n    {\n      \"step_description\": \"Perform Automatic Speech Recognition (ASR) on the audio file 'example.wav' to extract the command text.\",\n      \"task_name\": \"Automatic Speech Recognition\"\n    },\n    {\n      \"step_description\": \"Understand the command text and generate the corresponding image modification task.\",\n      \"task_name\": \"Question Answering\"\n    },\n    {\n      \"step_description\": \"Execute the image modification task on the image 'example.jpg' to get the modified image.\",\n      \"task_name\": \"Image Editing\"\n    },\n    {\n      \"step_description\": \"Generate a description of the image modification.\",\n      \"task_name\": \"Text Generation\"\n    },\n    {\n      \"step_description\": \"Perform Text-to-Speech (TTS) conversion on the command text to get the text transcription.\",\n      \"task_name\": \"Text-to-Speech\"\n    }\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Automatic Speech Recognition\"\n    },\n    {\n      \"task_name\": \"Question Answering\"\n    },\n    {\n      \"task_name\": \"Image Editing\"\n    },\n    {\n      \"task_name\": \"Text Generation\"\n    },\n    {\n      \"task_name\": \"Text-to-Speech\"\n    }\n  ],\n  \"task_links\": [\n    {\n      \"source\": \"Automatic Speech Recognition\",\n      \"target\": \"Question Answering\"\n    },\n    {\n      \"source"
"```json\n{\n  \"task_steps\": [\n    \"Load the example.jpg image into memory.\",\n    \"Perform object detection on the image using Object Detection task.\",\n    \"Extract the labels of the detected objects.\",\n    \"Invoke Text-to-Speech task to convert the labels into speech.\",\n    \"Record the speech output.\",\n    \"Invoke Automatic Speech Recognition task to transcribe the recorded speech back into text.\"\n  ],\n  \"task_nodes\": [\n    \"Object Detection\",\n    \"Text-to-Speech\",\n    \"Automatic Speech Recognition\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Object Detection\", \"target\": \"Text-to-Speech\"},\n    {\"source\": \"Text-to-Speech\", \"target\": \"Automatic Speech Recognition\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load image 'example.jpg' for image-to-image transformation.\",\n    \"Apply image-to-image transformation to 'example.jpg' to match target image domain.\",\n    \"Perform depth estimation on the transformed image.\",\n    \"Classify the table created from depth estimation result.\",\n    \"Compare the table classification result with the given text: 'Measurement results of depth estimation.'\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image-to-Image Transformation\"\n    },\n    {\n      \"task_name\": \"Depth Estimation\"\n    },\n    {\n      \"task_name\": \"Table Classification\"\n    },\n    {\n      \"task_name\": \"Text Comparison\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Image-to-Image Transformation\", \"target\": \"Depth Estimation\"},\n    {\"source\": \"Depth Estimation\", \"target\": \"Table Classification\"},\n    {\"source\": \"Table Classification\", \"target\": \"Text Comparison\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load the original image (example.jpg) using an Image Classification API to identify and extract objects.\",\n    \"Use an Object Detection API to detect and segment the objects in the original image.\",\n    \"Generate a new image based on the detected objects using an Image-to-Image API.\",\n    \"Load the generated image and use a Color Histogram or Color Palette Analysis API to determine the most prominent colors in the image.\"\n  ],\n  \"task_nodes\": [\n    \"Image Classification: Object Detection\",\n    \"Image-to-Image: Object Generation\",\n    \"Color Analysis\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification: Object Detection\", \"target\": \"Image-to-Image: Object Generation\"},\n    {\"source\": \"Image-to-Image: Object Generation\", \"target\": \"Color Analysis\"}\n  ]\n}\n```"
"{\n  \"task_steps\": [\n    \"Load the example.wav file into an audio processing library for noise reduction.\",\n    \"Apply noise reduction algorithm to enhance the audio quality.\",\n    \"Save the enhanced audio file as improved_example.wav\",\n    \"Load the improved_example.wav file into an automatic speech recognition (ASR) model for transcription.\",\n    \"Use the ASR model to transcribe the enhanced audio to text.\",\n    \"Load the transcribed text into a paraphrasing model.\",\n    \"Use the paraphrasing model to generate a paraphrased version of the conversation.\",\n    \"Save the paraphrased text as paraphrased_conversation.txt\",\n    \"Load the paraphrased_conversation.txt file into a text-to-speech (TTS) model.\",\n    \"Use the TTS model to convert the paraphrased text back to audio.\",\n    \"Save the generated audio as enhanced_conversation.wav\"\n  ],\n  \"task_nodes\": [\n    \"Image-to-Audio (Noise Reduction)\",\n    \"Automatic Speech Recognition (ASR)\",\n    \"Text-to-Speech (TTS)\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image-to-Audio (Noise Reduction)\", \"target\": \"Automatic Speech Recognition (ASR)\"},\n    {\"source\": \"Automatic Speech Recognition (ASR)\", \"target\": \"Text-to-Speech (TTS)\"},\n    {\"source\": \"Image-to-Audio (Noise Reduction)\", \"target\": \"Text-to-Speech (TTS)\"},\n    {\"source\": \"Text-to-Speech (TTS)\","
"```json\n{\n  \"task_steps\": [\n    \"Load the image 'example.jpg' for processing.\",\n    \"Perform image enhancement to improve the quality of the table image.\",\n    \"Perform image-to-text conversion to extract text data from the enhanced image.\",\n    \"Perform text preprocessing to clean and format the extracted text data.\",\n    \"Perform tabular classification to identify and separate the table data from the text.\",\n    \"Perform text summarization to extract the necessary information from the table data.\",\n    \"Perform question answering on the summarized table data to find the answer to the question 'What is the total revenue for the year 2021?'.\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image Enhancement\"\n    },\n    {\n      \"task_name\": \"Text Extraction\"\n    },\n    {\n      \"task_name\": \"Text Preprocessing\"\n    },\n    {\n      \"task_name\": \"Tabular Classification\"\n    },\n    {\n      \"task_name\": \"Text Summarization\"\n    },\n    {\n      \"task_name\": \"Question Answering\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Enhancement\", \"target\": \"Text Extraction\"},\n    {\"source\": \"Text Extraction\", \"target\": \"Text Preprocessing\"},\n    {\"source\": \"Text Preprocessing\", \"target\": \"Tabular Classification\"},\n    {\"source\": \"Tabular Classification\", \"target\": \"Text Summarization\"},\n    {\"source\": \"Text Summarization\", \"target\": \"Question Answering\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load and preprocess the input text description using Text-to-Table task.\",\n    \"Use Tabular Classification task to classify each cell in the table based on the given description and assign scores.\",\n    \"Generate an initial image of the table using Text-to-Image task with the given header and light blue background.\",\n    \"Update the colors of the cells in the image based on the classification results. High-scoring cells will be colored green, and low-scoring cells will be colored red.\"\n  ],\n  \"task_nodes\": [\n    \"Text-to-Table\",\n    \"Tabular Classification\",\n    \"Text-to-Image\",\n    \"Image Editing\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Text-to-Table\", \"target\": \"Tabular Classification\"},\n    {\"source\": \"Tabular Classification\", \"target\": \"Text-to-Image\"},\n    {\"source\": \"Text-to-Image\", \"target\": \"Image Editing\"}\n  ]\n}\n```"
"{\n  \"task_steps\": [\n    \"Load the image 'example.jpg' for editing.\",\n    \"Perform image editing to change all blue cars to red.\",\n    \"Save the edited image with a new name (e.g., 'edited_example.jpg').\",\n    \"Load the edited image 'edited_example.jpg' for object detection and labeling.\",\n    \"Perform object detection and labeling on all objects in the edited image.\",\n    \"Perform token classification on the detected and labeled objects.\",\n    \"Ask the question 'How many red cars are there in the image?'.\",\n    \"Invoke the question answering model to get the answer based on the detection, labeling, and classification results.\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image Editing\",\n      \"input\": \"example.jpg\",\n      \"output\": \"edited_example.jpg\"\n    },\n    {\n      \"task_name\": \"Object Detection and Labeling\",\n      \"input\": \"edited_example.jpg\",\n      \"output\": \"labeled_edited_example.jpg\"\n    },\n    {\n      \"task_name\": \"Token Classification\",\n      \"input\": \"labeled_edited_example.jpg\",\n      \"output\": \"classified_objects.json\"\n    },\n    {\n      \"task_name\": \"Question Answering\",\n      \"input\": \"classified_objects.json\",\n      \"output\": \"answer.txt\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Editing\", \"target\": \"Object Detection and Labeling\"},\n    {\"source\": \"Object Detection and Labeling\", \"target\": \""
"```json\n{\n  \"task_steps\": [\n    \"Perform Optical Character Recognition (OCR) on 'example.jpg' to extract text.\",\n    \"Use Text Summarization model to identify the main topic of the extracted text.\",\n    \"Generate an image based on the main topic using Text-to-Image model.\",\n    \"Perform Image Segmentation on the generated image to extract the text region.\",\n    \"Use Optical Character Recognition (OCR) on the segmented image to extract the text.\",\n    \"Answer the question 'What is the main topic of the document?' based on the extracted text.\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Text-to-Image\",\n      \"input\": {\n        \"question\": \"What is the main topic of the document?\"\n      },\n      \"output\": {\n        \"answer\": \"Main topic image\"\n      }\n    },\n    {\n      \"task_name\": \"Image Segmentation\",\n      \"input\": {\n        \"image\": \"Main topic image\"\n      },\n      \"output\": {\n        \"segmented_image\": \"Segmented image\"\n      }\n    },\n    {\n      \"task_name\": \"Optical Character Recognition (OCR)\",\n      \"input\": {\n        \"image\": \"example.jpg\"\n      },\n      \"output\": {\n        \"text\": \"Extracted text from example.jpg\"\n      }\n    },\n    {\n      \"task_name\": \"Text Summarization\",\n      \"input\": {\n        \"text\": \"Extracted text from example.jpg\"\n      },\n      \"output\": {\n        \"summary\": \"Main topic summary\"\n      }"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Load the text file 'example.txt' and extract the description or instructions for generating an image.\",\n            \"task_name\": \"Text-to-Image\"\n        },\n        {\n            \"step_description\": \"Generate an image based on the text description or instructions.\",\n            \"task_name\": \"Text-to-Image\"\n        },\n        {\n            \"step_description\": \"Load the text file 'example_target.txt' and extract the target category.\",\n            \"task_name\": \"Text-File-Loading\"\n        },\n        {\n            \"step_description\": \"Perform image classification on the generated image to determine its category.\",\n            \"task_name\": \"Image-Classification\"\n        },\n        {\n            \"step_description\": \"Compare the generated image's category with the target category.\",\n            \"task_name\": \"Sentence-Similarity\"\n        },\n        {\n            \"step_description\": \"Determine the similarity between the generated image's category and the target category.\",\n            \"task_name\": \"Summarization\"\n        },\n        {\n            \"step_description\": \"Output the similarity score between the generated image's category and the target category.\",\n            \"task_name\": \"Text-to-Speech\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Text-to-Image\",\n        \"Text-File-Loading\",\n        \"Image-Classification\",\n        \"Sentence-Similarity\",\n        \"Summarization\",\n        \"Text-to-Speech\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Text-to-Image\", \"target"
"```json\n{\n  \"task_steps\": [\n    \"Load the audio file 'example.wav'\",\n    \"Apply audio enhancement techniques to improve the audio quality\",\n    \"Perform Automatic Speech Recognition (ASR) to transcribe the enhanced audio\",\n    \"Classify the transcribed command using Text Classification\",\n    \"Load the document 'instructions.txt'\",\n    \"Use Text-to-Speech to read the document and compare it with the transcribed command\",\n    \"Use Text Similarity to measure the similarity between the transcribed command and the document\",\n    \"If the similarity score is above a certain threshold, return the corresponding explanation from the document\"\n  ],\n  \"task_nodes\": [\n    \"Audio-to-Audio (audio enhancement)\",\n    \"Automatic Speech Recognition (ASR)\",\n    \"Text Classification\",\n    \"Text-to-Speech\",\n    \"Text Similarity\",\n    \"Document Loading\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Audio-to-Audio\", \"target\": \"Automatic Speech Recognition\"},\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text Classification\"},\n    {\"source\": \"Text Classification\", \"target\": \"Text-to-Speech\"},\n    {\"source\": \"Text-to-Speech\", \"target\": \"Text Similarity\"},\n    {\"source\": \"Text Similarity\", \"target\": \"Document Question Answering\"},\n    {\"source\": \"Document Loading\", \"target\": \"Text Similarity\"}\n  ]\n}\n```\n\nThis JSON format includes the task steps, task nodes, and task links as required. The user's request is resolved by the given task nodes, which"
"```json\n{\n  \"task_steps\": [\n    \"Load image 'example.jpg' for tabular classification.\",\n    \"Perform tabular classification on the loaded image to extract table data.\",\n    \"Extract text from the classified table data.\",\n    \"Identify specific entities (dates, persons, places) within the extracted text.\",\n    \"Generate an audio version of the classified text using a text-to-speech tool.\",\n    \"Classify the generated audio using a keyword spotting or voice command recognition model.\",\n    \"Translate the audio classification result to Spanish.\"\n  ],\n  \"task_nodes\": [\n    \"Image Classification: Tabular\",\n    \"Text Extraction: Table\",\n    \"Named Entity Recognition: Table\",\n    \"Text-to-Speech\",\n    \"Audio Classification: Keyword Spotting or Voice Command Recognition\",\n    \"Translation: Spanish\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification: Tabular\", \"target\": \"Text Extraction: Table\"},\n    {\"source\": \"Text Extraction: Table\", \"target\": \"Named Entity Recognition: Table\"},\n    {\"source\": \"Named Entity Recognition: Table\", \"target\": \"Text-to-Speech\"},\n    {\"source\": \"Text-to-Speech\", \"target\": \"Audio Classification: Keyword Spotting or Voice Command Recognition\"},\n    {\"source\": \"Audio Classification: Keyword Spotting or Voice Command Recognition\", \"target\": \"Translation: Spanish\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load 'example.wav' audio file\",\n    \"Apply audio enhancement techniques to improve audio quality\",\n    \"Perform Automatic Speech Recognition (ASR) on the enhanced audio to extract speech text\",\n    \"Perform Speaker Emotion Recognition on the speech text to identify emotions\",\n    \"Generate a text prompt based on the identified emotions and the given image 'example.jpg'\",\n    \"Load 'example.jpg' image file\",\n    \"Edit the image based on the generated text prompt\",\n    \"Identify objects in the edited image using Object Detection\",\n    \"Compare the identified objects with the given text 'birthday party' using Text-to-Image Similarity\",\n    \"Determine the similarity scores between the identified objects and the given text\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Audio Enhancement\"\n    },\n    {\n      \"task_name\": \"Speech Recognition\"\n    },\n    {\n      \"task_name\": \"Speaker Emotion Recognition\"\n    },\n    {\n      \"task_name\": \"Text Prompt Generation\"\n    },\n    {\n      \"task_name\": \"Image Loading\"\n    },\n    {\n      \"task_name\": \"Image Editing\"\n    },\n    {\n      \"task_name\": \"Object Detection\"\n    },\n    {\n      \"task_name\": \"Text-to-Image Similarity\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Audio Enhancement\", \"target\": \"Speech Recognition\"},\n    {\"source\": \"Speech Recognition"
"{\n  \"task_steps\": [\n    \"Load user input text: 'The Eiffel Tower is an iron lattice tower located on the Champ de Mars in Paris, France. It is named after the engineer Gustave Eiffel, whose company designed and built the tower.'\",\n    \"Perform English to French translation using Translation task node\",\n    \"Store translated text: 'La Tour Eiffel est une tour en fer \u00e0 mailles situ\u00e9e sur le Champ de Mars \u00e0 Paris, France. Elle est nomm\u00e9e d'apr\u00e8s l'ing\u00e9nieur Gustave Eiffel, dont l'entreprise a con\u00e7u et construit la tour.'\",\n    \"Perform Question Answering using Question Answering task node with question: 'Qui est l'ing\u00e9nieur qui a con\u00e7u la Tour Eiffel?'\",\n    \"Store answer: 'Gustave Eiffel'\",\n    \"Perform Image Generation using Text-to-Image task node with input: 'Gustave Eiffel'\",\n    \"Store generated image\",\n    \"Perform Image Classification using Tabular Classification task node\",\n    \"Store classification result\",\n    \"Perform Sentence Similarity using Text Similarity task node with input: 'The name of the engineer who designed the Eiffel Tower is Gustave Eiffel.' and the classification result\"\n  ],\n  \"task_nodes\": [\n    \"Translation\",\n    \"Question Answering\",\n    \"Text-to-Image\",\n    \"Tabular Classification\",\n    \"Text Similarity\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Translation\", \"target\": \"Question Answering\"},\n    {\"source\": \"Question Answering\", \"target\": \"Text-to-Image\"},\n    {\"source"
"```json\n{\n  \"task_steps\": [\n    \"Load 'example.wav' for audio processing\",\n    \"Apply audio denoising to improve quality\",\n    \"Transcribe the denoised audio into text using Automatic Speech Recognition (ASR)\",\n    \"Load 'example.jpg' for text processing\",\n    \"Perform Optical Character Recognition (OCR) on the document image to extract text\",\n    \"Combine the transcribed text and extracted text from the document\",\n    \"Process the combined text to identify key events using Text Processing and Question Answering\",\n    \"Determine the most important event mentioned in the interview\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Audio Denoising\"\n    },\n    {\n      \"task_name\": \"Automatic Speech Recognition (ASR)\"\n    },\n    {\n      \"task_name\": \"Text Extraction (OCR)\"\n    },\n    {\n      \"task_name\": \"Text Processing\"\n    },\n    {\n      \"task_name\": \"Question Answering\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Audio Denoising\", \"target\": \"Automatic Speech Recognition (ASR)\"},\n    {\"source\": \"Text Extraction (OCR)\", \"target\": \"Text Processing\"},\n    {\"source\": \"Text Processing\", \"target\": \"Question Answering\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load 'example.jpg' image\",\n    \"Perform Object Detection on the image to identify objects and their locations\",\n    \"Use Object Detection results to identify key entities and actions in the scene\",\n    \"Perform Text Generation to create a short description of the scene based on the identified entities and actions\",\n    \"Perform Text-to-Speech to convert the generated text into speech\",\n    \"Perform Automatic Speech Recognition to convert the speech back into text\",\n    \"Perform Audio Classification to identify the type of audio content generated from the speech\"\n  ],\n  \"task_nodes\": [\n    \"Image Classification: Object Detection\",\n    \"Text Generation\",\n    \"Text-to-Speech\",\n    \"Automatic Speech Recognition\",\n    \"Audio Classification\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification: Object Detection\", \"target\": \"Text Generation\"},\n    {\"source\": \"Text Generation\", \"target\": \"Text-to-Speech\"},\n    {\"source\": \"Text-to-Speech\", \"target\": \"Automatic Speech Recognition\"},\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Audio Classification\"}\n  ]\n}\n```"
"{\n  \"task_steps\": [\n    \"Load the document image 'example.jpg'\",\n    \"Perform Optical Character Recognition (OCR) on the image to extract text content\",\n    \"Clean and preprocess the extracted text to remove noise and inconsistencies\",\n    \"Perform Text Summarization to identify the main topics in the document text\",\n    \"Generate the answer for the question 'What is the main topic of the document?' using the summarized text\",\n    \"Compare the generated answer with the reference text 'Image Processing'\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image-to-Text\",\n      \"input\": \"example.jpg\",\n      \"output\": \"extracted_text\"\n    },\n    {\n      \"task_name\": \"Text Preprocessing\",\n      \"input\": \"extracted_text\",\n      \"output\": \"cleaned_text\"\n    },\n    {\n      \"task_name\": \"Text Summarization\",\n      \"input\": \"cleaned_text\",\n      \"output\": \"summarized_text\"\n    },\n    {\n      \"task_name\": \"Question Answering\",\n      \"input\": \"summarized_text\",\n      \"output\": \"answer\"\n    },\n    {\n      \"task_name\": \"String Comparison\",\n      \"input\": \"answer, reference_text\",\n      \"output\": \"comparison_result\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Image-to-Text\", \"target\": \"Text Preprocessing\"},\n    {\"source\": \"Text Preprocessing\", \"target\": \"Text Summarization\"},\n    {\"source\": \"Text Summarization\", \"target\":"
"```json\n{\n  \"task_steps\": [\n    \"Load the 'example.jpg' image and apply a stylization filter to create a new image.\",\n    \"Extract any text present in the stylized image using Text-to-Text or Optical Character Recognition (OCR) model.\",\n    \"Generate a conversational response based on the extracted text using a Conversational model.\",\n    \"Edit the stylized image according to the generated response using Image Editing or Manipulation API.\",\n    \"Estimate the depth of objects in the edited image using Depth Estimation model.\"\n  ],\n  \"task_nodes\": [\n    \"Image Classification or Image-to-Image: Stylization\",\n    \"Text-to-Text or OCR: Text Extraction\",\n    \"Conversational: Response Generation\",\n    \"Image Editing or Manipulation: Image Editing\",\n    \"Depth Estimation: Depth Estimation\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification or Image-to-Image: Stylization\", \"target\": \"Text-to-Text or OCR: Text Extraction\"},\n    {\"source\": \"Text-to-Text or OCR: Text Extraction\", \"target\": \"Conversational: Response Generation\"},\n    {\"source\": \"Conversational: Response Generation\", \"target\": \"Image Editing or Manipulation: Image Editing\"},\n    {\"source\": \"Image Editing or Manipulation: Image Editing\", \"target\": \"Depth Estimation: Depth Estimation\"}\n  ]\n}\n```\n\nThis JSON format provides the required task steps, task nodes, and task links to fulfill the user's request. The task steps are described in detail, and the task nodes"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Understand the user's request and extract necessary information: 'What is global warming and how does it affect the Earth?'\"\n        },\n        {\n            \"step_description\": \"Perform Text-to-Video task to create an animated video explaining the concept of global warming.\"\n        },\n        {\n            \"step_description\": \"Perform Text-to-Speech task to generate a voiceover for the video explaining the concept of global warming.\"\n        },\n        {\n            \"step_description\": \"Perform Question Answering task to gather information about the causes and effects of global warming.\"\n        },\n        {\n            \"step_description\": \"Perform Text Summarization task to create concise summaries of the gathered information.\"\n        },\n        {\n            \"step_description\": \"Combine the summaries, voiceover, and animated video to create the final video.\"\n        }\n    ],\n    \"task_nodes\": [\n        {\n            \"task_name\": \"Text-to-Video\"\n        },\n        {\n            \"task_name\": \"Text-to-Speech\"\n        },\n        {\n            \"task_name\": \"Question Answering\"\n        },\n        {\n            \"task_name\": \"Text Summarization\"\n        }\n    ],\n    \"task_links\": [\n        {\n            \"source\": \"Understand user's request\",\n            \"target\": \"Text-to-Video\"\n        },\n        {\n            \"source\": \"Understand user's request\",\n            \"target\": \"Question Answering\"\n        },\n        {\n            \"source\": \"Question Answering\",\n           "
"```json\n{\n  \"task_steps\": [\n    \"Load the example.wav audio file\",\n    \"Perform Automatic Speech Recognition (ASR) on the audio file to extract text\",\n    \"Use Text-to-Speech (TTS) to generate an audio response acknowledging the speaker's emotion\",\n    \"Transcribe the generated audio response into text using ASR\",\n    \"Perform Question Answering on the document 'What are the benefits of expressing emotions?' using the transcribed text as the question\",\n    \"Extract the answer from the Question Answering API\",\n    \"Create a video based on the answer using Text-to-Video API\"\n  ],\n  \"task_nodes\": [\n    \"Automatic Speech Recognition\",\n    \"Text-to-Speech\",\n    \"Question Answering\",\n    \"Text-to-Video\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text-to-Speech\"},\n    {\"source\": \"Text-to-Speech\", \"target\": \"Automatic Speech Recognition\"},\n    {\"source\": \"Text-to-Speech\", \"target\": \"Question Answering\"},\n    {\"source\": \"Question Answering\", \"target\": \"Text-to-Video\"}\n  ]\n}\n```\n\nThis JSON format represents the task steps, task nodes, and task links required to fulfill the user's request. The task steps are described in plain text, while the task nodes are the specific tasks that need to be executed in sequence. The task links represent the dependencies among the tasks, indicating the order in which they should be invoked."
"```json\n{\n  \"task_steps\": [\n    \"Load 'example.jpg' image into memory.\",\n    \"Perform object detection on the image to identify table objects.\",\n    \"Perform depth estimation on each object to determine their depth in the image.\",\n    \"Store the detected objects and their corresponding depth values in a dictionary.\",\n    \"Generate text descriptions for each object using Text-to-Speech API.\",\n    \"Store the generated text descriptions in a list.\",\n    \"Compare the generated text descriptions with the reference text using Sentence Similarity API.\",\n    \"Print the similarity score and the objects with the highest similarity.\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Object Detection\"\n    },\n    {\n      \"task_name\": \"Depth Estimation\"\n    },\n    {\n      \"task_name\": \"Text-to-Speech\"\n    },\n    {\n      \"task_name\": \"Sentence Similarity\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Object Detection\", \"target\": \"Depth Estimation\"},\n    {\"source\": \"Depth Estimation\", \"target\": \"Text-to-Speech\"},\n    {\"source\": \"Text-to-Speech\", \"target\": \"Sentence Similarity\"}\n  ]\n}\n```"
"{\n  \"task_steps\": [\n    \"Identify the type and size of the coffee stain on the white shirt.\",\n    \"Gather necessary materials: a clean cloth, white vinegar, and cold water.\",\n    \"Blot the coffee stain with a clean cloth to remove excess coffee.\",\n    \"Mix equal parts of white vinegar and cold water in a bowl.\",\n    \"Dab the mixture onto the coffee stain with a clean cloth.\",\n    \"Rinse the stained area with cold water.\",\n    \"Blot the area dry with a clean towel.\",\n    \"Repeat the process if the stain is not completely removed.\",\n    \"Wash the shirt in cold water with a mild detergent.\",\n    \"Dry the shirt in the sun or using a low heat setting on a dryer.\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Identify Coffee Stain\"\n    },\n    {\n      \"task_name\": \"Gather Necessary Materials\"\n    },\n    {\n      \"task_name\": \"Blot Excess Coffee\"\n    },\n    {\n      \"task_name\": \"Prepare Vinegar and Water Solution\"\n    },\n    {\n      \"task_name\": \"Apply Vinegar and Water Solution\"\n    },\n    {\n      \"task_name\": \"Rinse the Stained Area\"\n    },\n    {\n      \"task_name\": \"Blot the Area Dry\"\n    },\n    {\n      \"task_name\": \"Repeat the Process\"\n    },\n    {\n      \"task_name\": \"Wash the Shirt\"\n    },\n    {\n      \"task_name\": \"Dry the Shirt\"\n    }\n  ],\n"
"{\n  \"task_steps\": [\n    \"Load 'example.jpg' image into memory.\",\n    \"Perform object detection on the image to identify the cat and the sofa.\",\n    \"Extract the region of interest (ROI) of the sofa from the image.\",\n    \"Apply image editing techniques to change the color of the sofa to blue.\",\n    \"Save the edited image with a new name, e.g., 'example_edited.jpg'.\",\n    \"Perform textual description generation on the image caption 'A cat is sitting on a blue sofa'.\",\n    \"Identify specific entities and their corresponding parts of speech in the generated description.\"\n  ],\n  \"task_nodes\": [\n    \"Image Classification (Object Detection)\",\n    \"Image Editing (Image-to-Image)\",\n    \"Text Generation (Textual description)\",\n    \"Text Processing (Part-of-Speech Tagging)\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification (Object Detection)\", \"target\": \"Image Editing (Image-to-Image)\"},\n    {\"source\": \"Image Editing (Image-to-Image)\", \"target\": \"Text Generation (Textual description)\"},\n    {\"source\": \"Text Generation (Textual description)\", \"target\": \"Text Processing (Part-of-Speech Tagging)\"},\n  ]\n}"
"```json\n{\n  \"task_steps\": [\n    \"Load the 'example.jpg' image.\",\n    \"Perform image editing to modify the color of the car to blue.\",\n    \"Apply cartoonish style to the edited image.\",\n    \"Perform image classification to determine the category of the transformed image.\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image Classification\"\n    },\n    {\n      \"task_name\": \"Text-to-Image\"\n    },\n    {\n      \"task_name\": \"Image Editing\"\n    },\n    {\n      \"task_name\": \"Image Classification\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Editing\", \"target\": \"Image Classification\"},\n    {\"source\": \"Text-to-Image\", \"target\": \"Image Editing\"},\n    {\"source\": \"Image Classification\", \"target\": \"Image Classification\"}\n  ]\n}\n```\n\nExplanation:\n\n1. The user request can be broken down into the following tasks: Image Editing (color modification), Text-to-Image (cartoonish style transformation), and Image Classification.\n2. The task steps are described in the JSON object under the \"task_steps\" key.\n3. The tasks to be executed in sequence to fulfill the user's request are listed under the \"task_nodes\" key.\n4. The dependencies among the tasks are reflected in the \"task_links\" key. The image editing task depends on the text-to-image task, and both tasks depend on the image classification task."
"```json\n{\n  \"task_steps\": [\n    \"Load 'example.jpg' image and perform Object Detection to identify table in the image.\",\n    \"Perform Tabular Classification on the identified table to classify the data.\",\n    \"Extract information about the classified data.\",\n    \"Generate answer to the question 'What is the significance of the data?' based on the extracted information.\",\n    \"Perform Text Classification to classify the generated answer.\",\n    \"Invoke Text-to-Speech API to convert the English answer to speech.\",\n    \"Invoke Text-to-Translation API to translate the English answer to French text.\",\n    \"Invoke Text-to-Speech API again to convert the French text to speech.\"\n  ],\n  \"task_nodes\": [\n    \"Object Detection\",\n    \"Tabular Classification\",\n    \"Information Extraction\",\n    \"Question Answering\",\n    \"Text Classification\",\n    \"Text-to-Speech (English)\",\n    \"Text-to-Translation\",\n    \"Text-to-Speech (French)\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Object Detection\", \"target\": \"Tabular Classification\"},\n    {\"source\": \"Tabular Classification\", \"target\": \"Information Extraction\"},\n    {\"source\": \"Information Extraction\", \"target\": \"Question Answering\"},\n    {\"source\": \"Question Answering\", \"target\": \"Text Classification\"},\n    {\"source\": \"Text Classification\", \"target\": \"Text-to-Speech (English)\"},\n    {\"source\": \"Text-to-Speech (English)\", \"target\": \"Text-to-Translation\"},\n    {\"source\": \"Text-to-Translation\", \"target\": \"Text-to"
"```json\n{\n  \"task_steps\": [\n    \"Load 'example.jpg' image\",\n    \"Perform Image Classification on 'example.jpg' to determine its class\",\n    \"Based on the class, generate a new image using Image-to-Image model\",\n    \"Perform Image Segmentation on the new image to segment it into constituent objects\",\n    \"Determine the largest object in the segmented image using Object Detection\",\n    \"Convert the largest object's name into speech using Text-to-Speech model\",\n    \"Enhance the speech audio using Audio Editing\",\n    \"Perform Audio Classification on the enhanced audio to determine its emotion\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image Classification\"\n    },\n    {\n      \"task_name\": \"Image-to-Image\"\n    },\n    {\n      \"task_name\": \"Image Segmentation\"\n    },\n    {\n      \"task_name\": \"Object Detection\"\n    },\n    {\n      \"task_name\": \"Text-to-Speech\"\n    },\n    {\n      \"task_name\": \"Audio Editing\"\n    },\n    {\n      \"task_name\": \"Audio Classification\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification\", \"target\": \"Image-to-Image\"},\n    {\"source\": \"Image-to-Image\", \"target\": \"Image Segmentation\"},\n    {\"source\": \"Image Segmentation\", \"target\": \"Object Detection\"},\n    {\"source\": \"Object Detection\", \"target\": \"Text-to-Speech\"},\n    {\"source\": \"Text-to-Spe"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Use Text-to-Image API to generate an image based on the text 'A sunny day at the beach'\"\n        },\n        {\n            \"step_description\": \"Extract text from the generated image using OCR or Text-from-Image API\"\n        },\n        {\n            \"step_description\": \"Generate a new text based on the extracted text\"\n        },\n        {\n            \"step_description\": \"Use Visual Question Answering API to answer the question 'What is the main activity?' with the new generated text and the image 'example.jpg'\"\n        },\n        {\n            \"step_description\": \"Perform token classification on the answered question's text using a Token Classification API\"\n        },\n        {\n            \"step_description\": \"Use Question Answering API to answer the question 'What time does the event take place?' based on the classified text as context\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Text-to-Image\",\n        \"Text-from-Image or OCR\",\n        \"Text Generation\",\n        \"Visual Question Answering\",\n        \"Token Classification\",\n        \"Question Answering\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Text-to-Image\", \"target\": \"Text-from-Image or OCR\"},\n        {\"source\": \"Text-from-Image or OCR\", \"target\": \"Text Generation\"},\n        {\"source\": \"Text Generation\", \"target\": \"Visual Question Answering\"},\n        {\"source\": \"Visual Question Answering\", \"target\": \"Token Classification\"},\n        {\"source\": \"Token Classification\", \"target\": \"Question Answering\"}\n   "
"```json\n{\n  \"task_steps\": [\n    \"Load the 'example.jpg' image into memory.\",\n    \"Perform object detection on the loaded image using Object Detection task.\",\n    \"Extract the bounding boxes and object labels from the Object Detection task output.\",\n    \"Filter the output to keep only the cars.\",\n    \"Change the color of each car in the image using Image Editing task.\",\n    \"Specify the new color as red.\",\n    \"Perform image classification on the edited image using Scene Classification task.\",\n    \"Extract the scene type label from the Scene Classification task output.\"\n  ],\n  \"task_nodes\": [\n    \"Object Detection\",\n    \"Image Editing\",\n    \"Scene Classification\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Object Detection\", \"target\": \"Image Editing\"},\n    {\"source\": \"Image Editing\", \"target\": \"Scene Classification\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load 'example.jpg' image into memory.\",\n    \"Perform image preprocessing to enhance the quality and readability of the table in the image.\",\n    \"Apply Text-to-Image model to recognize and extract text data from the table.\",\n    \"Perform Tabular Classification on the extracted data to classify each entry.\",\n    \"Apply Text-to-Speech model to convert the classified data into an audio file.\",\n    \"Perform audio preprocessing to improve the audio quality of the output file.\"\n  ],\n  \"task_nodes\": [\n    \"Image Classification (Image-to-Text)\",\n    \"Text Preprocessing (Text-to-Image)\",\n    \"Tabular Classification (Tabular Classification)\",\n    \"Text-to-Speech (Text-to-Speech)\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification\", \"target\": \"Text Preprocessing\"},\n    {\"source\": \"Text Preprocessing\", \"target\": \"Tabular Classification\"},\n    {\"source\": \"Tabular Classification\", \"target\": \"Text-to-Speech\"}\n  ]\n}\n```"
"{\n    \"task_steps\": [\n        {\n            \"step\": \"Perform Question Understanding\",\n            \"description\": \"Understand the user's request about the impact of global warming on polar bears.\"\n        },\n        {\n            \"step\": \"Perform Text Summarization\",\n            \"description\": \"Summarize the information related to the impact of global warming on polar bears from a reliable source.\"\n        },\n        {\n            \"step\": \"Perform Text-to-Speech\",\n            \"description\": \"Convert the summarized text into an audible response for the user.\"\n        },\n        {\n            \"step\": \"Perform Conversational Response\",\n            \"description\": \"Generate a conversational response based on the summarized information.\"\n        },\n        {\n            \"step\": \"Perform Token Classification\",\n            \"description\": \"Classify the tokens in the user's original question and the conversational response to measure their similarity.\"\n        },\n        {\n            \"step\": \"Perform Sentence Similarity\",\n            \"description\": \"Measure the similarity between the user's original question and the conversational response using sentence similarity algorithms.\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Question Understanding\",\n        \"Text Summarization\",\n        \"Text-to-Speech\",\n        \"Conversational Response\",\n        \"Token Classification\",\n        \"Sentence Similarity\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Question Understanding\", \"target\": \"Text Summarization\"},\n        {\"source\": \"Text Summarization\", \"target\": \"Text-to-Speech\"},\n        {\"source\": \"Text Summarization\", \"target\": \"Conversational Response\"},"
"```json\n{\n  \"task_steps\": [\n    \"Load the audio file 'example.wav'\",\n    \"Perform Automatic Speech Recognition (ASR) to transcribe the audio to text\",\n    \"Parse the transcribed text to identify relevant tokens related to image edits\",\n    \"Load the image file 'example.jpg'\",\n    \"Perform Text-to-Image generation to apply identified image edits based on the tokens\",\n    \"Save the edited image\"\n  ],\n  \"task_nodes\": [\n    \"Automatic Speech Recognition\",\n    \"Text Parsing\",\n    \"Text-to-Image Generation\",\n    \"Image Manipulation\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Load the audio file\", \"target\": \"Perform Automatic Speech Recognition\"},\n    {\"source\": \"Perform Automatic Speech Recognition\", \"target\": \"Parse the transcribed text\"},\n    {\"source\": \"Parse the transcribed text\", \"target\": \"Load the image file\"},\n    {\"source\": \"Load the image file\", \"target\": \"Perform Text-to-Image generation\"},\n    {\"source\": \"Perform Text-to-Image generation\", \"target\": \"Save the edited image\"}\n  ]\n}\n```"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Text-to-Speech: Convert the given text 'The quick brown fox jumps over the lazy dog.' into speech using Text-to-Speech API.\",\n            \"task_name\": \"Text-to-Speech\"\n        },\n        {\n            \"step_description\": \"Audio Enhancement: Enhance the quality of the generated speech using Audio Enhancement API.\",\n            \"task_name\": \"Audio Enhancement\"\n        },\n        {\n            \"step_description\": \"Automatic Speech Recognition: Convert the enhanced speech back into text for comparison.\",\n            \"task_name\": \"Automatic Speech Recognition\"\n        },\n        {\n            \"step_description\": \"Text Comparison: Compare the original text 'The quick brown fox jumps over the lazy dog.' with the transcribed text from Automatic Speech Recognition to ensure the message is clear.\",\n            \"task_name\": \"Text Comparison\"\n        },\n        {\n            \"step_description\": \"Audio Classification: Classify the enhanced audio to ensure the quality is as expected.\",\n            \"task_name\": \"Audio Classification\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Text-to-Speech\",\n        \"Audio Enhancement\",\n        \"Automatic Speech Recognition\",\n        \"Text Comparison\",\n        \"Audio Classification\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Text-to-Speech\", \"target\": \"Audio Enhancement\"},\n        {\"source\": \"Audio Enhancement\", \"target\": \"Automatic Speech Recognition\"},\n        {\"source"
"```json\n{\n  \"task_steps\": [\n    \"Load image 'example.jpg'\",\n    \"Perform image preprocessing for table image\",\n    \"Perform tabular classification on the table image to extract content\",\n    \"Perform text-to-image generation to modify the background color to blue\",\n    \"Perform image segmentation to separate the table from the background\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image Classification\",\n      \"input\": \"example.jpg\",\n      \"output\": \"preprocessed_table_image.jpg\"\n    },\n    {\n      \"task_name\": \"Tabular Classification\",\n      \"input\": \"preprocessed_table_image.jpg\",\n      \"output\": \"tabulated_content.txt\"\n    },\n    {\n      \"task_name\": \"Text-to-Image\",\n      \"input\": \"tabulated_content.txt, blue_background.jpg\",\n      \"output\": \"modified_background_image.jpg\"\n    },\n    {\n      \"task_name\": \"Image Segmentation\",\n      \"input\": \"modified_background_image.jpg\",\n      \"output\": \"segmented_table_image.jpg\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification\", \"target\": \"Tabular Classification\"},\n    {\"source\": \"Tabular Classification\", \"target\": \"Text-to-Image\"},\n    {\"source\": \"Text-to-Image\", \"target\": \"Image Segmentation\"}\n  ]\n}\n```\n\nThis JSON format represents the task steps, task nodes, and task links required to fulfill the user's request. The image is first pre"
"{\n  \"task_steps\": [\n    \"Step 1: Text Translation\",\n    \"Step 2: Generate new text description based on translated text\",\n    \"Step 3: Image Editing based on new text description\",\n    \"Step 4: Image Classification\",\n    \"Step 5: Create a video inspired by image's classification\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Text Translation\",\n      \"input\": {\n        \"text\": \"The city at night is beautiful with colorful lights.\"\n      },\n      \"output\": {\n        \"translated_text\": \"\"\n      }\n    },\n    {\n      \"task_name\": \"Generate new text description\",\n      \"input\": {\n        \"translated_text\": \"\"\n      },\n      \"output\": {\n        \"new_text_description\": \"\"\n      }\n    },\n    {\n      \"task_name\": \"Image Editing\",\n      \"input\": {\n        \"image_path\": \"example.jpg\",\n        \"text_description\": \"\"\n      },\n      \"output\": {\n        \"edited_image_path\": \"\"\n      }\n    },\n    {\n      \"task_name\": \"Image Classification\",\n      \"input\": {\n        \"image_path\": \"\"\n      },\n      \"output\": {\n        \"image_category\": \"\"\n      }\n    },\n    {\n      \"task_name\": \"Create a video\",\n      \"input\": {\n        \"image_category\": \"\",\n        \"edited_image_path\": \"\"\n      },\n      \"output\": {\n        \"video_path\": \"\"\n      }\n    }\n  ],\n  \"task_links"
"{\n    \"task_steps\": [\n        \"Load 'example.jpg' image\",\n        \"Apply image-to-domain transformation on 'example.jpg'\",\n        \"Perform image segmentation on transformed image\",\n        \"Extract text from segmented image parts\",\n        \"Generate new image from extracted text\",\n        \"Perform object detection on final image\",\n        \"Identify main object in final image\"\n    ],\n    \"task_nodes\": [\n        {\n            \"task_name\": \"Image Classification\",\n            \"input\": \"example.jpg\",\n            \"output\": \"transformed_image.jpg\"\n        },\n        {\n            \"task_name\": \"Image Segmentation\",\n            \"input\": \"transformed_image.jpg\",\n            \"output\": \"segmented_image.png\"\n        },\n        {\n            \"task_name\": \"Text Extraction\",\n            \"input\": \"segmented_image.png\",\n            \"output\": \"extracted_text.txt\"\n        },\n        {\n            \"task_name\": \"Text-to-Image\",\n            \"input\": \"extracted_text.txt\",\n            \"output\": \"generated_image.jpg\"\n        },\n        {\n            \"task_name\": \"Object Detection\",\n            \"input\": \"generated_image.jpg\",\n            \"output\": \"final_image.jpg\"\n        },\n        {\n            \"task_name\": \"Question Answering\",\n            \"input\": \"final_image.jpg\",\n            \"output\": \"answer.txt\"\n        }\n    ],\n    \"task_links\": [\n        {\"source\": \"Image Classification\", \"target\": \"Image Segmentation\"},\n        {\"source\": \"Image Segment"
"```json\n{\n  \"task_steps\": [\n    \"Load the noisy audio file 'example.wav'\",\n    \"Perform Automatic Speech Recognition (ASR) to extract text from the audio file\",\n    \"Perform Text-to-Speech (TTS) to ensure the extracted text is accurate\",\n    \"Perform Object Detection on the text to identify the specific object mentioned in the conversation\",\n    \"Perform Image Classification to confirm the identified object is present in the images\",\n    \"Perform Image-to-Image to generate images of the object based on the text description\",\n    \"Perform Image Segmentation to isolate the object from the background in the generated images\",\n    \"Perform Depth Estimation to estimate the depth of the object in the images\",\n    \"Perform Text-to-Question to generate a question about the object's dimensions\",\n    \"Perform Question Answering to extract the general dimensions of the object from the text description or the depth estimation results\"\n  ],\n  \"task_nodes\": [\n    \"Automatic Speech Recognition\",\n    \"Text-to-Speech\",\n    \"Object Detection\",\n    \"Image Classification\",\n    \"Image-to-Image\",\n    \"Image Segmentation\",\n    \"Depth Estimation\",\n    \"Question Answering\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text-to-Speech\"},\n    {\"source\": \"Text-to-Speech\", \"target\": \"Object Detection\"},\n    {\"source\": \"Object Detection\", \"target\": \"Image Classification\"},\n    {\"source\": \"Image Classification\", \"target\": \"Image-to-Image\"},"
"```json\n{\n  \"task_steps\": [\n    \"Load image 'example.jpg'\",\n    \"Perform Object Detection to identify table in image\",\n    \"Perform Tabular Classification on identified table\",\n    \"Extract text from classified table\",\n    \"Perform Text-to-Speech to pronounce French text from table\",\n    \"Perform Speech-to-Text to convert French speech to text\",\n    \"Perform Text Translation to translate French text to English\",\n    \"Compare English text to reference text 'This is an important reference text.' using Text Similarity\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Object Detection\"\n    },\n    {\n      \"task_name\": \"Tabular Classification\"\n    },\n    {\n      \"task_name\": \"Text-to-Speech\"\n    },\n    {\n      \"task_name\": \"Speech-to-Text\"\n    },\n    {\n      \"task_name\": \"Text Translation\"\n    },\n    {\n      \"task_name\": \"Text Similarity\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Object Detection\", \"target\": \"Tabular Classification\"},\n    {\"source\": \"Tabular Classification\", \"target\": \"Text-to-Speech\"},\n    {\"source\": \"Text-to-Speech\", \"target\": \"Speech-to-Text\"},\n    {\"source\": \"Speech-to-Text\", \"target\": \"Text Translation\"},\n    {\"source\": \"Text Translation\", \"target\": \"Text Similarity\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load the image 'example.jpg' using an Image Classification API.\",\n    \"Perform Object Detection on the loaded image to identify and extract table regions.\",\n    \"Use a Tabular Classification API to classify the identified table regions.\",\n    \"Extract the table data from the classified table regions.\",\n    \"Use a Summarization API to generate a summarized text of the extracted table data.\"\n  ],\n  \"task_nodes\": [\n    \"Image Classification: Object Detection\",\n    \"Tabular Classification\",\n    \"Summarization: Text\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification\", \"target\": \"Tabular Classification\"},\n    {\"source\": \"Tabular Classification\", \"target\": \"Summarization\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load 'example.wav' audio file\",\n    \"Perform Automatic Speech Recognition (ASR) on the audio file to extract text\",\n    \"Load 'example.jpg' image for reference\",\n    \"Perform Text-to-Image generation to create an image based on the extracted text\",\n    \"Perform Image Segmentation on the generated image to identify main subjects\",\n    \"Perform Object Detection on the segmented image to extract main subject's location and features\",\n    \"Extract text from the 'example.jpg' image using Optical Character Recognition (OCR) or Text-to-Speech and Text-to-Text to convert it to text if necessary\",\n    \"Combine the text extracted from the image and the generated image in a document\",\n    \"Perform Question Answering on the document to determine the main subject in the scene\"\n  ],\n  \"task_nodes\": [\n    \"Automatic Speech Recognition\",\n    \"Text-to-Image generation\",\n    \"Image Segmentation\",\n    \"Object Detection\",\n    \"Text extraction (OCR or Text-to-Speech and Text-to-Text)\",\n    \"Question Answering\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text-to-Image generation\"},\n    {\"source\": \"Text-to-Image generation\", \"target\": \"Image Segmentation\"},\n    {\"source\": \"Image Segmentation\", \"target\": \"Object Detection\"},\n    {\"source\": \"Text-to-Image generation\", \"target\": \"Text extraction\"},\n    {\"source\": \"Text extraction\", \"target\": \""
"```json\n{\n  \"task_steps\": [\n    \"Load the example.wav file into an audio processing system.\",\n    \"Apply audio noise reduction techniques to improve the overall audio quality.\",\n    \"Perform speaker diarization to separate the voices of different speakers.\",\n    \"Apply speaker embedding techniques to extract unique representations of each speaker's voice.\",\n    \"Use automatic speech recognition (ASR) to transcribe each speaker's statements.\",\n    \"Apply text summarization techniques to generate summaries of each speaker's statements.\",\n    \"Use contextual information to expand the summaries with additional context.\",\n    \"Output the improved audio quality, separated speaker voices, and summaries in a desired format.\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Audio Preprocessing\",\n      \"task_description\": \"Apply audio noise reduction and other preprocessing techniques to improve the overall audio quality.\"\n    },\n    {\n      \"task_name\": \"Speaker Diarization\",\n      \"task_description\": \"Separate the voices of different speakers in the audio file.\"\n    },\n    {\n      \"task_name\": \"Speaker Embedding\",\n      \"task_description\": \"Extract unique representations of each speaker's voice.\"\n    },\n    {\n      \"task_name\": \"Automatic Speech Recognition\",\n      \"task_description\": \"Transcribe each speaker's statements from the audio file.\"\n    },\n    {\n      \"task_name\": \"Text Summarization\",\n      \"task_description\": \"Generate summaries of each speaker's statements.\"\n    },\n    {\n      \"task_name\": \"Contextual Expansion\",\n      \"task_description\": \"Expand the summaries with additional context.\""
"```json\n{\n  \"task_steps\": [\n    \"Load image 'example.jpg'\",\n    \"Perform image classification using 'Image Classification' task node\",\n    \"Identify table in the classified image using 'Object Detection' task node\",\n    \"Perform tabular data extraction using 'Tabular Classification' task node\",\n    \"Extract bird species and their wingspan data from the extracted table\",\n    \"Filter bird species with wingspan larger than 1 meter using 'Text Processing' task node\",\n    \"Generate speech audio describing the filtered data using 'Text-to-Speech' task node\",\n    \"Record and save the generated speech audio using 'Automatic Speech Recognition' task node\",\n    \"Transcribe the recorded speech back to written text using 'Text-to-Text' task node\",\n    \"Formulate a question 'What species have a wingspan larger than 1 meter?' using 'Text Processing' task node\",\n    \"Compare the question and retrieved answers using 'Sentence Similarity' task node\"\n  ],\n  \"task_nodes\": [\n    \"Image Classification\",\n    \"Object Detection\",\n    \"Tabular Classification\",\n    \"Text-to-Speech\",\n    \"Automatic Speech Recognition\",\n    \"Text-to-Text\",\n    \"Sentence Similarity\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification\", \"target\": \"Object Detection\"},\n    {\"source\": \"Object Detection\", \"target\": \"Tabular Classification\"},\n    {\"source\": \"Tabular Classification\", \"target\": \"Text-to-Speech\"},\n    {\"source\": \"Text-to-Speech\", \"target\": \"Automatic Speech Recognition"
"{\n  \"task_steps\": [\n    \"Generate an image based on the text prompt 'A cat sitting on a windowsill'.\",\n    \"Classify the generated image into a specific category.\",\n    \"Generate a possible color for the cat in the generated image.\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Text-to-Image\"\n    },\n    {\n      \"task_name\": \"Image Classification\"\n    },\n    {\n      \"task_name\": \"Text-to-Speech\"\n    },\n    {\n      \"task_name\": \"Image Segmentation\"\n    },\n    {\n      \"task_name\": \"Color Detection\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Text-to-Image\", \"target\": \"Image Classification\"},\n    {\"source\": \"Image Classification\", \"target\": \"Image Segmentation\"},\n    {\"source\": \"Text-to-Speech\", \"target\": \"Text-to-Text\"},\n    {\"source\": \"Text-to-Text\", \"target\": \"Color Detection\"},\n    {\"source\": \"Text-to-Image\", \"target\": \"Image Segmentation\"}\n  ]\n}\n\n# Explanation #:\n# The user request involves generating an image based on a text prompt, classifying the image, and then determining a possible color for the cat in the image.\n# To accomplish this, we will first use the Text-to-Image task to generate an image based on the text prompt.\n# Next, we will use the Image Classification task to classify the generated image into a specific category.\n# After that, we will use the Text-to-Speech task to convert the text prompt into spoken language for"
"```json\n{\n  \"task_steps\": [\n    \"Load 'example.jpg' image file\",\n    \"Apply image enhancement techniques to improve quality\",\n    \"Perform text extraction from the enhanced image\",\n    \"Convert extracted text into speech using Text-to-Speech API\",\n    \"Perform Automatic Speech Recognition on the speech\",\n    \"Classify the recognized speech using Audio Classification API\",\n    \"Translate the classification result into French using Translation API\",\n    \"Generate a video using Text-to-Video API with the translated text\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image Classification\"\n    },\n    {\n      \"task_name\": \"Text-to-Speech\"\n    },\n    {\n      \"task_name\": \"Automatic Speech Recognition\"\n    },\n    {\n      \"task_name\": \"Audio Classification\"\n    },\n    {\n      \"task_name\": \"Translation\"\n    },\n    {\n      \"task_name\": \"Text-to-Video\"\n    },\n    {\n      \"task_name\": \"Image Enhancement\"\n    },\n    {\n      \"task_name\": \"Text Extraction\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification\", \"target\": \"Text Extraction\"},\n    {\"source\": \"Text Extraction\", \"target\": \"Text-to-Speech\"},\n    {\"source\": \"Text-to-Speech\", \"target\": \"Automatic Speech Recognition\"},\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Audio Classification\"},\n    {\"source\": \"Audio"
"```json\n{\n  \"task_steps\": [\n    \"Load the 'example.jpg' image into memory.\",\n    \"Perform Object Detection on the loaded image to identify and locate objects.\",\n    \"Extract the bounding boxes and class labels of the detected objects.\",\n    \"For each object, use Text-to-Speech to generate a spoken description.\",\n    \"Combine all the spoken descriptions into a single textual description.\",\n    \"Output the generated textual description.\"\n  ],\n  \"task_nodes\": [\n    \"Image Classification: Object Detection\",\n    \"Text-to-Speech: Multiple\",\n    \"Concatenation: Text\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification: Object Detection\", \"target\": \"Text-to-Speech: Multiple\"},\n    {\"source\": \"Text-to-Speech: Multiple\", \"target\": \"Concatenation: Text\"},\n    {\"source\": \"Image Classification: Object Detection\", \"target\": \"Concatenation: Text\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load the example.wav file into an audio processing library\",\n    \"Apply noise reduction algorithm to improve audio quality\",\n    \"Extract speech signals from the improved audio\",\n    \"Convert speech signals to text using Automatic Speech Recognition (ASR) model\",\n    \"Load a Text-to-Speech (TTS) model with a different voice\",\n    \"Convert the text back to speech\",\n    \"Apply Emotion Detection model to the new audio\"\n  ],\n  \"task_nodes\": [\n    \"Audio Classification: Noise Reduction\",\n    \"Automatic Speech Recognition (ASR)\",\n    \"Text-to-Speech (TTS)\",\n    \"Emotion Detection\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Audio Classification: Noise Reduction\", \"target\": \"Automatic Speech Recognitation (ASR)\"},\n    {\"source\": \"Automatic Speech Recognition (ASR)\", \"target\": \"Text-to-Speech (TTS)\"},\n    {\"source\": \"Text-to-Speech (TTS)\", \"target\": \"Emotion Detection\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    {\n      \"step_description\": \"Load the input text file (example.txt) for text analysis.\"\n    },\n    {\n      \"step_description\": \"Perform named entity recognition on the input text.\"\n    },\n    {\n      \"step_description\": \"Summarize the input text.\"\n    },\n    {\n      \"step_description\": \"Generate audio from the summarized text.\"\n    },\n    {\n      \"step_description\": \"Perform emotion classification on the generated audio.\"\n    },\n    {\n      \"step_description\": \"Perform command classification on the generated audio.\"\n    },\n    {\n      \"step_description\": \"Load the input image file (example.jpg) for image processing.\"\n    },\n    {\n      \"step_description\": \"Edit the input image based on the analysis results.\"\n    },\n    {\n      \"step_description\": \"Perform image classification on the edited image.\"\n    },\n    {\n      \"step_description\": \"Calculate the text-image similarity based on the initial text and the edited image's classification.\"\n    }\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Text Analysis (Token Classification, Summarization)\"\n    },\n    {\n      \"task_name\": \"Text-to-Speech\"\n    },\n    {\n      \"task_name\": \"Audio Processing (Emotion Classification, Command Classification)\"\n    },\n    {\n      \"task_name\": \"Image Processing (Image Editing)\"\n    },\n    {\n      \"task_name\": \"Image Classification\"\n    },\n    {\n      \"task_name\": \"Text"
"```json\n{\n  \"task_steps\": [\n    \"Load the audio file 'example.wav'\",\n    \"Apply Automatic Speech Recognition (ASR) to extract text from the audio file\",\n    \"Parse the extracted text to identify commands\",\n    \"Invoke Text-to-Image API with identified commands to generate corresponding image edits\",\n    \"Load the image file 'example.jpg'\",\n    \"Apply Image Preprocessing to remove background noise if necessary\",\n    \"Detect and extract table from the image using Tabular Classification\",\n    \"Perform Object Detection on the table to identify and classify each cell\"\n  ],\n  \"task_nodes\": [\n    \"Automatic Speech Recognition\",\n    \"Text-to-Image\",\n    \"Tabular Classification\",\n    \"Object Detection\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Load the audio file 'example.wav'\", \"target\": \"Apply Automatic Speech Recognition\"},\n    {\"source\": \"Apply Automatic Speech Recognition\", \"target\": \"Parse the extracted text to identify commands\"},\n    {\"source\": \"Parse the extracted text to identify commands\", \"target\": \"Invoke Text-to-Image API with identified commands\"},\n    {\"source\": \"Invoke Text-to-Image API with identified commands\", \"target\": \"Load the image file 'example.jpg'\"},\n    {\"source\": \"Load the image file 'example.jpg'\", \"target\": \"Apply Image Preprocessing\"},\n    {\"source\": \"Apply Image Preprocessing\", \"target\": \"Detect and extract table from the image using Tabular Classification\"},\n    {\"source\": \"Detect and extract table from the image using Tabular Classification\", \"target\": \"Perform Object Detection on the table"
"```json\n{\n  \"task_steps\": [\n    \"Load image 'example.jpg' for object depth estimation.\",\n    \"Perform image segmentation on 'example.jpg' to identify individual objects.\",\n    \"For each object, perform depth estimation using image depth estimation API.\",\n    \"Determine the largest object based on the depth estimates.\",\n    \"Load text document 'example.txt' for additional information.\",\n    \"Perform text-to-speech conversion of the text document to provide final answer.\",\n    \"If document image 'example.png' is available, perform OCR to extract text and add to information source.\",\n    \"Perform question answering on the combined information sources to answer the question: 'What is the largest object in the image?'\"\n  ],\n  \"task_nodes\": [\n    \"Image Segmentation\",\n    \"Object Detection\",\n    \"Depth Estimation\",\n    \"Question Answering\",\n    \"Text-to-Speech\",\n    \"OCR (if document image is available)\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Segmentation\", \"target\": \"Object Detection\"},\n    {\"source\": \"Object Detection\", \"target\": \"Depth Estimation\"},\n    {\"source\": \"Depth Estimation\", \"target\": \"Question Answering\"},\n    {\"source\": \"Question Answering\", \"target\": \"Text-to-Speech\"},\n    {\"source\": \"Question Answering\", \"target\": \"OCR (if document image is available)\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load the image file 'example.jpg' using an Image Classification API to identify the main object and its labels.\",\n    \"Using the identified labels from the Image Classification API, extract the most probable label as the main object.\",\n    \"Use a Text-to-Speech API to read out the identified main object.\",\n    \"Ask a question 'What color is the main object in the image?' using a Conversational API.\",\n    \"Use a Question Answering API to extract the answer to the question.\",\n    \"Compare the answer to the question 'What color is the main object in the image?' with the sentence 'The main object in the image is blue.' using a Sentence Similarity API.\",\n    \"Return the similarity score between the answer and the sentence.\"\n  ],\n  \"task_nodes\": [\n    \"Image Classification\",\n    \"Question Answering\",\n    \"Sentence Similarity\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification\", \"target\": \"Question Answering\"},\n    {\"source\": \"Question Answering\", \"target\": \"Sentence Similarity\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load the document image 'example.jpg'\",\n    \"Perform Optical Character Recognition (OCR) to extract text from the document image using Text-to-Text model\",\n    \"Perform Named Entity Recognition (NER) on the extracted text to identify important entities related to the historical event\",\n    \"Use a Document Question Answering (DQA) model to determine the main cause of the historical event from the extracted text\",\n    \"Generate a conversational response explaining the main cause of the event using a Conversational model\",\n    \"Highlight the named entities within the conversational response using Text Annotation\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image-to-Text\",\n      \"input\": \"example.jpg\",\n      \"output\": \"Text extracted from the document image\"\n    },\n    {\n      \"task_name\": \"Named Entity Recognition\",\n      \"input\": \"Text extracted from the document image\",\n      \"output\": \"Named entities identified in the text\"\n    },\n    {\n      \"task_name\": \"Document Question Answering\",\n      \"input\": {\n        \"document\": \"Text extracted from the document image\",\n        \"question\": \"What was the main cause of the event?\"\n      },\n      \"output\": \"Answer to the question 'What was the main cause of the event?'\"\n    },\n    {\n      \"task_name\": \"Conversational\",\n      \"input\": {\n        \"question\": \"What was the main cause of the event?\",\n        \"answer\": \"Answer to the question 'What was the main cause of the event?'\"\n      },\n      \"output\": \""
"{\n  \"task_steps\": [\n    {\n      \"step_description\": \"Load and preprocess the input image 'example.jpg' for text description and video generation tasks.\"\n    },\n    {\n      \"step_description\": \"Perform Image-to-Text task to generate a creative description of the image 'example.jpg'.\"\n    },\n    {\n      \"step_description\": \"Perform Text-to-Speech task to convert the generated description into an audio format.\"\n    },\n    {\n      \"step_description\": \"Perform Text-to-Video task to create a video based on the generated description and audio.\"\n    },\n    {\n      \"step_description\": \"Save the generated video and the creative description for further use.\"\n    }\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image-to-Text\"\n    },\n    {\n      \"task_name\": \"Text-to-Speech\"\n    },\n    {\n      \"task_name\": \"Text-to-Video\"\n    }\n  ],\n  \"task_links\": [\n    {\n      \"source\": \"Image Classification\",\n      \"target\": \"Image-to-Text\"\n    },\n    {\n      \"source\": \"Image-to-Text\",\n      \"target\": \"Text-to-Speech\"\n    },\n    {\n      \"source\": \"Text-to-Speech\",\n      \"target\": \"Text-to-Video\"\n    }\n  ]\n}\n\n# Explanation:\n# The user request involves generating a creative description for an image and creating a video based on this description.\n# To accomplish this, we need to perform the following tasks:\n# 1. Image pre"
"```json\n{\n  \"task_steps\": [\n    \"Load image 'example.jpg' and perform table extraction to get city information.\",\n    \"Load image 'example.png' and perform object detection to identify key elements in the image.\",\n    \"Compare the identified key elements in the image with the city information in the table.\",\n    \"If a match is found, extract the city name from the table and perform token classification on it.\",\n    \"Output the token classified city name as the final answer.\"\n  ],\n  \"task_nodes\": [\n    \"Tabular Classification: Table Extraction\",\n    \"Object Detection\",\n    \"Image Comparison\",\n    \"Token Classification\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Tabular Classification: Table Extraction\", \"target\": \"Object Detection\"},\n    {\"source\": \"Object Detection\", \"target\": \"Image Comparison\"},\n    {\"source\": \"Image Comparison\", \"target\": \"Token Classification\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load the example.jpg image into memory.\",\n    \"Perform image preprocessing to prepare the image for further analysis.\",\n    \"Invoke Image Classification API to classify the image and extract its category.\",\n    \"Invoke Depth Estimation API to generate a depth map of the image.\",\n    \"Invoke Text-to-Speech API to generate a description of the scene based on the image category and depth map information.\"\n  ],\n  \"task_nodes\": [\n    \"Image Classification\",\n    \"Depth Estimation\",\n    \"Text-to-Speech\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification\", \"target\": \"Depth Estimation\"},\n    {\"source\": \"Depth Estimation\", \"target\": \"Text-to-Speech\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load 'example.jpg' image into memory.\",\n    \"Perform text detection on the image to extract text regions.\",\n    \"Extract text from the detected regions.\",\n    \"Perform text summarization to generate a related paragraph based on the extracted text.\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image-to-Text\"\n    },\n    {\n      \"task_name\": \"Text Summarization\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Image-to-Text\", \"target\": \"Text Summarization\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load example.jpg image\",\n    \"Perform image-to-image task to change the color of the dress based on emotional input from example.wav using 'Image Editing' task node\",\n    \"Extract text from the modified image using 'Text-to-Image' and 'Text Extraction' tasks\",\n    \"Perform 'Text Classification' task to determine the main color mentioned in the extracted text\",\n    \"Answer the question 'What is the main color of the dress now?' using the output of the 'Text Classification' task\"\n  ],\n  \"task_nodes\": [\n    \"Image Classification: Image-to-Image\",\n    \"Text Extraction: Text-to-Image\",\n    \"Text Classification: Summarization\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification: Image-to-Image\", \"target\": \"Text Extraction: Text-to-Image\"},\n    {\"source\": \"Text Extraction: Text-to-Image\", \"target\": \"Text Classification: Summarization\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    {\n      \"step_description\": \"Load the audio file 'example.wav' and perform Automatic Speech Recognition to extract text from the audio.\",\n      \"task_name\": \"Automatic Speech Recognition\"\n    },\n    {\n      \"step_description\": \"Use Text-to-Question model to formulate the question 'What are the main colors in the scene?' from the extracted text.\",\n      \"task_name\": \"Text-to-Question\"\n    },\n    {\n      \"step_description\": \"Send the question to the Document Question Answering model to extract the answer related to the main colors in the scene.\",\n      \"task_name\": \"Document Question Answering\"\n    },\n    {\n      \"step_description\": \"Load the image file 'example.jpg' and perform Image-to-Text conversion to extract textual descriptions of the image.\",\n      \"task_name\": \"Image-to-Text\"\n    },\n    {\n      \"step_description\": \"Use Object Detection model to identify and extract the objects in the image.\",\n      \"task_name\": \"Object Detection\"\n    },\n    {\n      \"step_description\": \"Use Image Editing techniques to modify the image based on the answer from the audio, specifically to highlight or enhance the main colors in the scene.\",\n      \"task_name\": \"Image Editing\"\n    },\n    {\n      \"step_description\": \"Perform Image Segmentation on the edited image to extract the regions corresponding to the main colors.\",\n      \"task_name\": \"Image Segmentation\"\n    },\n    {\n      \"step_description\": \"Use Depth Estimation model to extract depth information of the objects in the image"
"```json\n{\n  \"task_steps\": [\n    \"Load the poor quality audio file 'example.wav'.\",\n    \"Apply audio enhancement techniques to improve the quality of the audio file.\",\n    \"Perform automatic speech recognition to extract the French speech from the enhanced audio file.\",\n    \"Detect and recognize the emotion in the speaker's voice.\",\n    \"Translate the French speech to English using a translation model.\",\n    \"Generate an audio file with the translated English speech.\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Audio Enhancement\"\n    },\n    {\n      \"task_name\": \"Speech Recognition (French)\"\n    },\n    {\n      \"task_name\": \"Emotion Detection\"\n    },\n    {\n      \"task_name\": \"Translation (French to English)\"\n    },\n    {\n      \"task_name\": \"Text-to-Speech (English)\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Audio Enhancement\", \"target\": \"Speech Recognition (French)\"},\n    {\"source\": \"Speech Recognition (French)\", \"target\": \"Emotion Detection\"},\n    {\"source\": \"Emotion Detection\", \"target\": \"Translation (French to English)\"},\n    {\"source\": \"Translation (French to English)\", \"target\": \"Text-to-Speech (English)\"},\n    {\"source\": \"Text-to-Speech (English)\", \"target\": \"Generate an audio file with the translated English speech\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load the image 'example.jpg'\",\n    \"Perform Object Detection on the image to identify objects\",\n    \"For each identified object, perform Text-to-Speech to generate spoken name\",\n    \"Save or display the spoken names\",\n    \"Perform Audio Classification on the generated audio\"\n  ],\n  \"task_nodes\": [\n    \"Object Detection\",\n    \"Text-to-Speech (for each identified object)\",\n    \"Audio Classification\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Object Detection\", \"target\": \"Text-to-Speech\"},\n    {\"source\": \"Text-to-Speech\", \"target\": \"Audio Classification\"}\n  ]\n}\n```"
"{\n  \"task_steps\": [\n    \"Load the audio file 'example.wav' for speech recognition.\",\n    \"Perform Automatic Speech Recognition (ASR) on the audio file to extract text instructions.\",\n    \"Parse the extracted text instructions to identify image modification tasks.\",\n    \"Load the image file 'example.jpg' for image processing.\",\n    \"Perform Image-to-Text task to extract relevant information from the image if necessary.\",\n    \"For each identified image modification task, invoke the corresponding task node:\",\n      {\n        \"Task Type\": \"Image Editing\",\n        \"Task Description\": \"Modify the image based on the given instructions.\"\n      }\n    \"Save the modified image with a new name.\"\n  ],\n  \"task_nodes\": [\n    {\n      \"Task Type\": \"Automatic Speech Recognition\",\n      \"Task Description\": \"Perform ASR on the given audio file and extract text instructions.\"\n    },\n    {\n      \"Task Type\": \"Image Editing\",\n      \"Task Description\": \"Modify the image based on the given instructions.\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Parse Text Instructions\"},\n    {\"source\": \"Parse Text Instructions\", \"target\": \"Image Editing\"}\n  ]\n}"
"```json\n{\n  \"task_steps\": [\n    \"Load the 'example.jpg' image into memory.\",\n    \"Perform image classification on the loaded image using 'Image Classification' task.\",\n    \"Obtain the classification result from the 'Image Classification' task.\",\n    \"Invoke 'Text-to-Speech' task to convert the classification result into speech.\",\n    \"Invoke 'Automatic Speech Recognition' task to enhance the audio quality of the generated speech.\"\n  ],\n  \"task_nodes\": [\n    \"Image Classification\",\n    \"Text-to-Speech\",\n    \"Automatic Speech Recognition\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification\", \"target\": \"Text-to-Speech\"},\n    {\"source\": \"Text-to-Speech\", \"target\": \"Automatic Speech Recognition\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load the provided example.jpg document image.\",\n    \"Perform Object Detection on the image to identify and extract the text from the region containing the historical event mention.\",\n    \"Perform Text Classification on the extracted text to determine the historical event and identify the leader's name.\",\n    \"Perform Image-to-Text task to generate a textual description of the leader.\",\n    \"Perform Text-to-Image task to generate an image of the identified leader.\",\n    \"Perform Image Classification on the generated leader image to ensure its quality and accuracy.\",\n    \"Perform Depth Estimation on the original example.jpg document image.\",\n    \"Apply a stylized effect to the depth image.\",\n    \"Perform Text-to-Speech to read out the leader's name.\",\n    \"Perform Automatic Speech Recognition to extract the text from the speech.\",\n    \"Perform Text-to-Image task to generate a textual description of the stylized depth image.\",\n    \"Perform Image-to-Text task to extract the text from the stylized depth image.\",\n    \"Compare the extracted text from the stylized depth image with the initial textual description of the leader to ensure consistency.\"\n  ],\n  \"task_nodes\": [\n    \"Object Detection\",\n    \"Text Classification\",\n    \"Text-to-Image (Leader)\",\n    \"Image Classification (Leader)\",\n    \"Depth Estimation\",\n    \"Image-to-Text (Stylized Depth)\",\n    \"Text-to-Image (Stylized Depth)\",\n    \"Image-to-Text (Stylized Depth Text)\"\n  ],\n  \"task_links\": [\n    {\"source\":"
"{\n  \"task_steps\": [\n    \"Load the example.jpg image into the system.\",\n    \"Perform Object Detection on the image to identify and extract text regions from the image.\",\n    \"Use Text Extraction API to extract text from the identified regions.\",\n    \"Perform Text Classification to determine the main topic of the extracted text.\",\n    \"Generate a summary of the main topic.\",\n    \"Use Text-to-Speech API to create an audio version of the summary.\",\n    \"Use Image-to-Text API to generate text from the created short video illustrating the main topic.\",\n    \"Combine the text from the summary and the text from the video in a coherent manner.\",\n    \"Use Text Generation API to create a final answer in the format: 'The main topic discussed in the document is [summary]'.\",\n    \"Use Text-to-Video API to create a short video illustrating the answer.\",\n    \"Save the final answer and the short video for future reference.\"\n  ],\n  \"task_nodes\": [\n    \"Object Detection\",\n    \"Text Extraction\",\n    \"Text Classification\",\n    \"Text Generation\",\n    \"Text-to-Speech\",\n    \"Image-to-Text\",\n    \"Text-to-Video\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Load image\", \"target\": \"Object Detection\"},\n    {\"source\": \"Object Detection\", \"target\": \"Text Extraction\"},\n    {\"source\": \"Text Extraction\", \"target\": \"Text Classification\"},\n    {\"source\": \"Text Classification\", \"target\": \"Text Generation\"},\n    {\"source\": \"Text Generation\", \"target\": \"Text-to-Speech\"},\n    {\"source\": \"Text Generation\", \""
"```json\n{\n  \"task_steps\": [\n    \"Load 'example.jpg' for image processing tasks\",\n    \"Perform image segmentation on 'example.jpg' to identify car and other objects\",\n    \"Determine color of car in image segmentation result\",\n    \"Edit 'example.jpg' based on identified car color\",\n    \"Perform depth estimation on 'example.jpg' to identify objects and their distances from viewer\",\n    \"Determine object closest to viewer in depth estimation result\",\n    \"Convert text answer to speech using Text-to-Speech API\",\n    \"Transcribe speech back into text using Automatic Speech Recognition API\"\n  ],\n  \"task_nodes\": [\n    \"Image Segmentation\",\n    \"Color Detection\",\n    \"Image Editing\",\n    \"Depth Estimation\",\n    \"Document Question Answering\",\n    \"Text-to-Speech\",\n    \"Automatic Speech Recognition\",\n    \"Text-to-Text\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Segmentation\", \"target\": \"Color Detection\"},\n    {\"source\": \"Color Detection\", \"target\": \"Image Editing\"},\n    {\"source\": \"Image Segmentation\", \"target\": \"Depth Estimation\"},\n    {\"source\": \"Depth Estimation\", \"target\": \"Document Question Answering\"},\n    {\"source\": \"Document Question Answering\", \"target\": \"Text-to-Speech\"},\n    {\"source\": \"Text-to-Speech\", \"target\": \"Automatic Speech Recognition\"},\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text-to-Text\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load the example image using an Image Classification API to identify the image content and extract relevant labels.\",\n    \"Use a Text-to-Speech API to read out the image labels for better understanding.\",\n    \"Use a Text-to-Question API to generate potential study questions based on the image labels.\",\n    \"Use a Question Answering API to find answers to the study questions from a relevant text corpus.\",\n    \"Use a Text Generation API to summarize the answers into concise study notes.\",\n    \"Use a Document Question Answering API to validate the accuracy of the study notes.\",\n    \"Use a Text-to-Speech API to read out the study notes for review.\",\n    \"Use an Image-to-Text API to generate a description of the image for additional context.\",\n    \"Use a Text-to-Video API to create a visual representation of the study notes.\",\n    \"Review and edit the study guide using a Text Editor API.\"\n  ],\n  \"task_nodes\": [\n    \"Image Classification\",\n    \"Text-to-Speech\",\n    \"Text-to-Question\",\n    \"Question Answering\",\n    \"Text Generation\",\n    \"Document Question Answering\",\n    \"Text-to-Speech\",\n    \"Image-to-Text\",\n    \"Text-to-Video\",\n    \"Text Editor\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification\", \"target\": \"Text-to-Speech\"},\n    {\"source\": \"Text-to-Speech\", \"target\": \"Text-to-Question\"},\n    {\"source\": \"Text-to-Question\", \"target\": \"Question Answering\"},\n    {\"source\": \"Question An"
"```json\n{\n  \"task_steps\": [\n    \"Identify the table in the image using Image-to-Text API.\",\n    \"Extract the table data from the text output.\",\n    \"Convert the extracted table data into spoken words using Text-to-Speech API.\"\n  ],\n  \"task_nodes\": [\n    \"Image-to-Text\",\n    \"Text Processing (Table Extraction)\",\n    \"Text-to-Speech\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image-to-Text\", \"target\": \"Text Processing (Table Extraction)\"},\n    {\"source\": \"Text Processing (Table Extraction)\", \"target\": \"Text-to-Speech\"}\n  ]\n}\n```"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Load the audio recording file for speech-to-text conversion\"\n        },\n        {\n            \"step_description\": \"Invoke Automatic Speech Recognition API to transcribe the audio recording\"\n        },\n        {\n            \"step_description\": \"Preprocess the transcribed text to remove stop words and irrelevant information\"\n        },\n        {\n            \"step_description\": \"Invoke Text Summarization API to generate a summary of the key points from the transcribed text\"\n        },\n        {\n            \"step_description\": \"Load the image file for text and object recognition\"\n        },\n        {\n            \"step_description\": \"Invoke Image-to-Text API to extract text from the image\"\n        },\n        {\n            \"step_description\": \"Preprocess the extracted text to remove stop words and irrelevant information\"\n        },\n        {\n            \"step_description\": \"Invoke Object Detection API to identify and extract information from objects in the image\"\n        },\n        {\n            \"step_description\": \"Compare the summarized key points from the meeting with the extracted information from the image\"\n        },\n        {\n            \"step_description\": \"Generate a report explaining how the image is related to the key points from the meeting\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Automatic Speech Recognition\",\n        \"Text Summarization\",\n        \"Image-to-Text\",\n        \"Object Detection\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text Summarization\"},\n        {\"source\": \"Text Summarization\", \"target\": \"Generate Report\"},\n        {\""
"{\n  \"task_steps\": [\n    \"Load the Spanish text: 'Mis amigos y yo vamos a la playa este fin de semana.'\",\n    \"Perform Spanish to English translation using a translation API\",\n    \"Store the translated text: 'My friends and I are going to the beach this weekend.'\",\n    \"Load the example.jpg document image\",\n    \"Perform image-to-text extraction using an OCR API to extract text from the image\",\n    \"Store the extracted text from the image\",\n    \"Compare the translated text and the text extracted from the image using a text similarity API\",\n    \"Generate a new text based on the translated content and the text from the image using a text generation API\",\n    \"Store the generated text\",\n    \"Answer the question 'How does it relate to my translated text?' using a question answering API\",\n    \"Store the answer\",\n    \"Generate a conversational response using a conversational AI model\"\n  ],\n  \"task_nodes\": [\n    \"Spanish to English Translation\",\n    \"Image-to-Text Extraction\",\n    \"Text Similarity\",\n    \"Text Generation\",\n    \"Question Answering\",\n    \"Conversational AI\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Spanish to English Translation\", \"target\": \"Text Generation\"},\n    {\"source\": \"Spanish to English Translation\", \"target\": \"Question Answering\"},\n    {\"source\": \"Image-to-Text Extraction\", \"target\": \"Text Similarity\"},\n    {\"source\": \"Image-to-Text Extraction\", \"target\": \"Text Generation\"},\n    {\"source\": \"Text Similarity\", \"target\": \"Question Answering\"},\n    {\"source"
"```json\n{\n  \"task_steps\": [\n    \"Load the audio file 'example.wav' using Automatic Speech Recognition (ASR) API for speech-to-text conversion.\",\n    \"Parse the recognized text to extract the command related to editing an image and table.\",\n    \"Load the image file 'example.jpg' using Image Classification or Image-to-Text API for text extraction from the image if necessary.\",\n    \"Use Image Editing API to edit the image based on the command.\",\n    \"Load the edited image using Image Classification or Object Detection API to locate and extract the table from the image.\",\n    \"Use Tabular Classification API to classify the table and extract the necessary data.\",\n    \"Use Text-to-Speech API to generate an audio file with the answer to the question 'What is the total revenue?'.\",\n    \"Use Text Summarization API to generate a summary of the answer.\"\n  ],\n  \"task_nodes\": [\n    \"Automatic Speech Recognition\",\n    \"Image Editing\",\n    \"Text or Object Extraction (Image Classification or Object Detection)\",\n    \"Tabular Classification\",\n    \"Text-to-Speech\",\n    \"Text Summarization\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text or Object Extraction\"},\n    {\"source\": \"Text or Object Extraction\", \"target\": \"Image Editing\"},\n    {\"source\": \"Text or Object Extraction\", \"target\": \"Tabular Classification\"},\n    {\"source\": \"Tabular Classification\", \"target\": \"Text-to-Speech\"},\n    {\"source\": \"Text-to-Speech\", \"target\": \""
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Load and preprocess the input image example.jpg for object detection.\",\n            \"task_name\": \"Image Classification\"\n        },\n        {\n            \"step_description\": \"Run object detection model to identify and extract objects present in the image.\",\n            \"task_name\": \"Object Detection\"\n        },\n        {\n            \"step_description\": \"Extract relevant information from the detected objects, such as object names and locations.\",\n            \"task_name\": \"Text Extraction\"\n        },\n        {\n            \"step_description\": \"Generate a text summary of the objects present in the image.\",\n            \"task_name\": \"Summarization\"\n        },\n        {\n            \"step_description\": \"Create a storyboard for the video based on the text summary.\",\n            \"task_name\": \"Text-to-Video\"\n        },\n        {\n            \"step_description\": \"Generate the video frames for each scene in the storyboard.\",\n            \"task_name\": \"Video Generation\"\n        },\n        {\n            \"step_description\": \"Combine the generated video frames to create the final video.\",\n            \"task_name\": \"Video Editing\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Image Classification\",\n        \"Object Detection\",\n        \"Text Extraction\",\n        \"Summarization\",\n        \"Text-to-Video\",\n        \"Video Generation\",\n        \"Video Editing\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Image Classification\", \"target\": \"Object Detection\"},\n        {\"source\": \"Object Detection\", \"target\": \"Text Extraction\"},\n        {\"source\":"
"```json\n{\n  \"task_steps\": [\n    \"Load the example.wav audio file\",\n    \"Apply audio noise reduction to enhance the audio quality\",\n    \"Perform Automatic Speech Recognition (ASR) to transcribe the audio to text\",\n    \"Generate a new, clearer speech audio from the transcribed text using Text-to-Speech (TTS)\",\n    \"Perform Speaker Emotion Classification on the transcribed text\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Audio Classification and Enhancement\",\n      \"task_description\": \"Apply audio noise reduction to enhance the audio quality\"\n    },\n    {\n      \"task_name\": \"Automatic Speech Recognition\",\n      \"task_description\": \"Transcribe the audio to text\"\n    },\n    {\n      \"task_name\": \"Text-to-Speech\",\n      \"task_description\": \"Generate a new, clearer speech audio from the text\"\n    },\n    {\n      \"task_name\": \"Speaker Emotion Classification\",\n      \"task_description\": \"Classify the speaker's emotion from the transcribed text\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Audio Classification and Enhancement\", \"target\": \"Automatic Speech Recognition\"},\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text-to-Speech\"},\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Speaker Emotion Classification\"}\n  ]\n}\n```"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Load the audio file 'example.wav' for automatic speech recognition\",\n            \"task_name\": \"Automatic Speech Recognition\"\n        },\n        {\n            \"step_description\": \"Transcribe the speech from the audio file to text in English\",\n            \"task_name\": \"Text-to-Speech (for inverse process)\",\n            \"depends_on\": [\"Automatic Speech Recognition\"]\n        },\n        {\n            \"step_description\": \"Translate the English text to French\",\n            \"task_name\": \"Translation\"\n        },\n        {\n            \"step_description\": \"Generate an image representation of the French instruction\",\n            \"task_name\": \"Text-to-Image\"\n        },\n        {\n            \"step_description\": \"Perform image-level object detection on the generated image to identify the main action\",\n            \"task_name\": \"Object Detection\"\n        },\n        {\n            \"step_description\": \"Extract the main action label from the object detection results\",\n            \"task_name\": \"Question Answering\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Automatic Speech Recognition\",\n        \"Text-to-Speech\",\n        \"Translation\",\n        \"Text-to-Image\",\n        \"Object Detection\",\n        \"Question Answering\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text-to-Speech\"},\n        {\"source\": \"Text-to-Speech\", \"target\": \"Translation\"},\n        {\"source\": \"Translation\", \"target\": \"Text-to-"
"{\n  \"task_steps\": [\n    {\n      \"step_description\": \"Perform image classification to identify the presence of a table in the image.\",\n      \"task_name\": \"Image Classification\"\n    },\n    {\n      \"step_description\": \"Extract text from the table using OCR (Optical Character Recognition) technology.\",\n      \"task_name\": \"Text-to-Image, Image-to-Text (for generating table image if needed)\",\n      \"depends_on\": [\"Image Classification\"]\n    },\n    {\n      \"step_description\": \"Perform text summarization to extract the main idea from each quote.\",\n      \"task_name\": \"Summarization\"\n    },\n    {\n      \"step_description\": \"Generate paraphrased versions of the quotes using a text generation model.\",\n      \"task_name\": \"Text Generation\"\n    },\n    {\n      \"step_description\": \"Create visuals based on the quote content using an image generation model.\",\n      \"task_name\": \"Text-to-Image\"\n    },\n    {\n      \"step_description\": \"Combine the paraphrased quotes and visuals to create a storyboard for the video.\",\n      \"task_name\": \"Text-to-Video\"\n    },\n    {\n      \"step_description\": \"Create the final video using the storyboard and the generated visuals and paraphrased quotes.\",\n      \"task_name\": \"Video Production\"\n    }\n  ],\n  \"task_nodes\": [\n    \"Image Classification\",\n    \"Text-to-Image, Image-to-Text\",\n    \"Summarization\",\n    \"Text Generation\",\n    \"Text-to-Image\",\n    \"Text-to-Video"
"{\n  \"task_steps\": [\n    \"Load the document image 'example.jpg'\",\n    \"Perform Optical Character Recognition (OCR) on the document image to extract text\",\n    \"Perform Document Question Answering (DQA) on the extracted text to find the answer to the question\",\n    \"Load the audio file 'example.wav'\",\n    \"Perform Automatic Speech Recognition (ASR) on the audio file to extract the question in text format\",\n    \"Compare the text of the question from the audio and the text extracted from the document image to ensure they match\",\n    \"Perform Text-to-Speech (TTS) to read the answer out loud in English\",\n    \"Perform Machine Translation to translate the answer from English to Spanish\",\n    \"Perform Text-to-Speech (TTS) to read the translated answer out loud in Spanish\"\n  ],\n  \"task_nodes\": [\n    \"Text-to-Image, Object Detection or Tabular Classification (for OCR) to extract text from document image\",\n    \"Document Question Answering\",\n    \"Automatic Speech Recognition\",\n    \"Text-to-Text (for Machine Translation)\",\n    \"Text-to-Speech (for English)\",\n    \"Text-to-Speech (for Spanish)\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Text-to-Image, Object Detection or Tabular Classification\", \"target\": \"Document Question Answering\"},\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Document Question Answering\"},\n    {\"source\": \"Document Question Answering\", \"target\": \"Text-to-Text\"},\n    {\"source\": \"Text-to"
"```json\n{\n  \"task_steps\": [\n    \"Load example.txt and example.jpg into memory.\",\n    \"Perform text summarization on example.txt to generate summarized_text.txt.\",\n    \"Perform question answering on summarized_text.txt and example.jpg to get answer.\",\n    \"Generate new text description based on answer.\",\n    \"Edit example.jpg according to new text description.\",\n    \"Perform depth estimation on edited_example.jpg to get depth_map.\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Text Summarization\",\n      \"input\": [\"example.txt\"],\n      \"output\": [\"summarized_text.txt\"]\n    },\n    {\n      \"task_name\": \"Question Answering\",\n      \"input\": [\"summarized_text.txt\", \"example.jpg\"],\n      \"output\": [\"answer\"]\n    },\n    {\n      \"task_name\": \"Text Generation\",\n      \"input\": [\"answer\"],\n      \"output\": [\"new_text_description\"]\n    },\n    {\n      \"task_name\": \"Image Editing\",\n      \"input\": [\"example.jpg\", \"new_text_description\"],\n      \"output\": [\"edited_example.jpg\"]\n    },\n    {\n      \"task_name\": \"Depth Estimation\",\n      \"input\": [\"edited_example.jpg\"],\n      \"output\": [\"depth_map\"]\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Text Summarization\", \"target\": \"Question Answering\"},\n    {\"source\": \"Question Answering\", \"target\": \"Text Generation\"},\n    {\"source\": \"Text Generation\", \"target\":"
"```json\n{\n  \"task_steps\": [\n    \"Load the audio file 'example.wav'\",\n    \"Perform Automatic Speech Recognition (ASR) to extract text from the audio file\",\n    \"Generate an image based on the text description using Text-to-Image model\",\n    \"Perform Object Detection on the generated image to identify objects\",\n    \"Extract tokens associated with the identified objects using Token Extraction model\",\n    \"Perform Token Classification on the extracted tokens using a pre-trained model\"\n  ],\n  \"task_nodes\": [\n    \"Automatic Speech Recognition\",\n    \"Text-to-Image Generation\",\n    \"Object Detection\",\n    \"Token Extraction\",\n    \"Token Classification\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text-to-Image Generation\"},\n    {\"source\": \"Text-to-Image Generation\", \"target\": \"Object Detection\"},\n    {\"source\": \"Object Detection\", \"target\": \"Token Extraction\"},\n    {\"source\": \"Token Extraction\", \"target\": \"Token Classification\"}\n  ]\n}\n```"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Read the content of 'example.txt' file to extract the name of the artist.\"\n        },\n        {\n            \"step_description\": \"Use Text Classification or Named Entity Recognition to extract the artist's name from the text file.\"\n        },\n        {\n            \"step_description\": \"Use Image Classification or Image-to-Text API to search for the painting based on the artist's name.\"\n        },\n        {\n            \"step_description\": \"Download the image of the painting and save it as 'example.jpg'.\"\n        },\n        {\n            \"step_description\": \"Use Image Analysis or Color Detection API to determine the dominant color in the painting.\"\n        },\n        {\n            \"step_description\": \"Generate an audio answer for the dominant color using Text-to-Speech API.\"\n        },\n        {\n            \"step_description\": \"Save the audio answer as 'example.wav'.\"\n        }\n    ],\n    \"task_nodes\": [\n        {\n            \"task_name\": \"Text Classification or Named Entity Recognition\"\n        },\n        {\n            \"task_name\": \"Image Classification or Image-to-Text\"\n        },\n        {\n            \"task_name\": \"Image Analysis or Color Detection\"\n        },\n        {\n            \"task_name\": \"Text-to-Speech\"\n        }\n    ],\n    \"task_links\": [\n        {\"source\": \"Text Classification or Named Entity Recognition\", \"target\": \"Image Classification or Image-to-Text\"},\n        {\"source\": \"Image Classification or Image-to-Text\", \"target\": \"Image Analysis"
"```json\n{\n  \"task_steps\": [\n    \"Load the example.jpg image.\",\n    \"Perform image segmentation to identify and separate objects in the image.\",\n    \"Perform depth estimation to calculate the depth of each object in the image.\",\n    \"Generate a text description of the depth of each object.\",\n    \"Use text-to-speech API to convert the text description into spoken words.\",\n    \"Combine the spoken words with visuals of the original image and the depth information to create a video.\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image Segmentation\"\n    },\n    {\n      \"task_name\": \"Depth Estimation\"\n    },\n    {\n      \"task_name\": \"Text Generation\"\n    },\n    {\n      \"task_name\": \"Text-to-Speech\"\n    },\n    {\n      \"task_name\": \"Video Generation\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Segmentation\", \"target\": \"Depth Estimation\"},\n    {\"source\": \"Depth Estimation\", \"target\": \"Text Generation\"},\n    {\"source\": \"Text Generation\", \"target\": \"Text-to-Speech\"},\n    {\"source\": \"Text-to-Speech\", \"target\": \"Video Generation\"}\n  ]\n}\n```"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Perform image-to-text conversion to extract the English paragraph from the image.\",\n            \"task_name\": \"Image-to-Text\"\n        },\n        {\n            \"step_description\": \"Perform text summarization to extract the main topic of the English paragraph.\",\n            \"task_name\": \"Summarization\"\n        },\n        {\n            \"step_description\": \"Perform text-to-speech conversion of the main topic in English to check its accuracy.\",\n            \"task_name\": \"Text-to-Speech\"\n        },\n        {\n            \"step_description\": \"Perform automatic speech recognition to transcribe the spoken English main topic.\",\n            \"task_name\": \"Automatic Speech Recognition\"\n        },\n        {\n            \"step_description\": \"Perform translation of the English main topic to French.\",\n            \"task_name\": \"Translation\"\n        },\n        {\n            \"step_description\": \"Perform text comparison to determine the similarity between the translated answer and the sentence 'Le sujet principal est la technologie.'\",\n            \"task_name\": \"Sentence Similarity\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Image-to-Text\",\n        \"Summarization\",\n        \"Text-to-Speech\",\n        \"Automatic Speech Recognition\",\n        \"Translation\",\n        \"Sentence Similarity\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Image-to-Text\", \"target\": \"Summarization\"},\n        {\"source\": \"Summarization\", \"target\": \"Text-to-Speech\"},\n        {\"source\": \"Text-to-"
"```json\n{\n  \"task_steps\": [\n    \"Load the audio file 'example.wav' for automatic speech recognition.\",\n    \"Perform Automatic Speech Recognition (ASR) on the loaded audio file to extract the command.\",\n    \"Search for the command in the provided text 'How to train your dog: step by step guide'.\",\n    \"Identify the corresponding step number and description related to the command.\",\n    \"Use the step number and description to query the Tabular Classification model to find the related image.\",\n    \"Generate the related image using the Text-to-Image model based on the step description.\"\n  ],\n  \"task_nodes\": [\n    \"Automatic Speech Recognition\",\n    \"Text Search\",\n    \"Tabular Classification\",\n    \"Text-to-Image Generation\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text Search\"},\n    {\"source\": \"Text Search\", \"target\": \"Tabular Classification\"},\n    {\"source\": \"Tabular Classification\", \"target\": \"Text-to-Image Generation\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load example.jpg image\",\n    \"Generate image from text 'A beautiful sunset over the ocean with dolphins jumping'\",\n    \"Perform depth estimation on generated image\",\n    \"Detect objects in depth-estimated image\",\n    \"Extract labels of detected objects\",\n    \"Calculate object label similarity with reference text 'sun, ocean, dolphins'\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Text-to-Image\"\n    },\n    {\n      \"task_name\": \"Image Generation\"\n    },\n    {\n      \"task_name\": \"Depth Estimation\"\n    },\n    {\n      \"task_name\": \"Object Detection\"\n    },\n    {\n      \"task_name\": \"Text Similarity\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Text-to-Image\", \"target\": \"Image Generation\"},\n    {\"source\": \"Image Generation\", \"target\": \"Depth Estimation\"},\n    {\"source\": \"Depth Estimation\", \"target\": \"Object Detection\"},\n    {\"source\": \"Object Detection\", \"target\": \"Text Similarity\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load the image 'example.jpg' and extract text from it using an OCR (Optical Character Recognition) model.\",\n    \"Perform Text-to-Speech conversion on the extracted text for better understanding and verification.\",\n    \"Use a Text Classification model to determine the main topic of the text.\",\n    \"Compare the determined topic with the reference sentence 'The topic is about computer science and programming.' using a Sentence Similarity model.\",\n    \"Return the result of the comparison, indicating the similarity score and a boolean value indicating if the topics match.\"\n  ],\n  \"task_nodes\": [\n    \"Text-to-Image or Image-to-Text to convert the image text to plain text using OCR\",\n    \"Text Classification to determine the main topic of the text\",\n    \"Sentence Similarity to compare the determined topic with the reference sentence\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image-to-Text or Text-to-Image\", \"target\": \"Text-to-Speech\"},\n    {\"source\": \"Text-to-Speech\", \"target\": \"Text Classification\"},\n    {\"source\": \"Text Classification\", \"target\": \"Sentence Similarity\"}\n  ]\n}\n```"
"{\n  \"task_steps\": [\n    \"Load the input image 'example.jpg'\",\n    \"Apply color change filter to the image to make the car blue\",\n    \"Save the edited image with a new name 'edited_example.jpg'\",\n    \"Load the edited image 'edited_example.jpg'\",\n    \"Perform object detection on the edited image to identify objects\",\n    \"Generate a text description of the identified objects\",\n    \"Convert the text description to an audio file\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image Editing\",\n      \"input\": {\n        \"image_path\": \"example.jpg\",\n        \"color\": \"blue\"\n      },\n      \"output\": {\n        \"edited_image_path\": \"edited_example.jpg\"\n      }\n    },\n    {\n      \"task_name\": \"Object Detection\",\n      \"input\": {\n        \"image_path\": \"edited_example.jpg\"\n      },\n      \"output\": {\n        \"object_detections\": []\n      }\n    },\n    {\n      \"task_name\": \"Text Generation\",\n      \"input\": {\n        \"object_detections\": \"${ObjectDetection.output.object_detections}\"\n      },\n      \"output\": {\n        \"text_description\": \"\"\n      }\n    },\n    {\n      \"task_name\": \"Text-to-Speech\",\n      \"input\": {\n        \"text\": \"${TextGeneration.output.text_description}\"\n      },\n      \"output\": {\n        \"audio_file_path\": \"\"\n      }\n    }\n  ],\n  \"task_links\": [\n   "
"```json\n{\n  \"task_steps\": [\n    \"Load the image 'example.jpg' using an Image Classification API to identify the image type and preprocess it for further tasks.\",\n    \"Run Object Detection API to identify and locate all objects present in the image.\",\n    \"For each object detected, run an Image Classification API to identify the object category.\",\n    \"Generate a summary of the detected objects and their categories using a Text Summarization API.\"\n  ],\n  \"task_nodes\": [\n    \"Image Classification: Preprocess Image\",\n    \"Object Detection\",\n    \"Image Classification: Object Category Identification\",\n    \"Text Summarization: Generate Object Summary\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification: Preprocess Image\", \"target\": \"Object Detection\"},\n    {\"source\": \"Object Detection\", \"target\": \"Image Classification: Object Category Identification\"},\n    {\"source\": \"Image Classification: Object Category Identification\", \"target\": \"Text Summarization: Generate Object Summary\"}\n  ]\n}\n```"
"{\n  \"task_steps\": [\n    \"Step 1: Use Object Detection task to identify and label objects in example.jpg.\",\n    \"Step 2: Generate a response to the prompt 'What do you see in the image?' using Question Answering task.\",\n    \"Step 3: Use Text-to-Speech task to generate an audio response in English for the identified objects.\",\n    \"Step 4: Use Automatic Speech Recognition task to transcribe the English audio response into text.\",\n    \"Step 5: Use Translation task to translate the text response into French.\",\n    \"Step 6: Use Text-to-Image task to generate an image of the labeled objects based on the French text response.\",\n    \"Step 7: Use Image Editing task to modify example.jpg based on the generated image from step 6.\",\n    \"Step 8: Use Depth Estimation task to estimate depth information of the objects in the modified image.\",\n    \"Step 9: Use Image-to-Image task to apply the depth estimation information to modify the image further.\",\n    \"Step 10: Use Object Detection task again to identify and label objects in the modified image.\",\n    \"Step 11: Use Tabular Classification task to classify the objects in the resulting image.\"\n  ],\n  \"task_nodes\": [\n    \"Object Detection\",\n    \"Question Answering\",\n    \"Text-to-Speech\",\n    \"Automatic Speech Recognition\",\n    \"Translation\",\n    \"Text-to-Image\",\n    \"Image Editing\",\n    \"Depth Estimation\",\n    \"Image-to-Image\",\n    \"Object Detection\",\n    \"Tabular Classification\"\n  ],\n  \"task_links\": [\n    {\""
"```json\n{\n  \"task_steps\": [\n    \"Load the audio file 'example.wav' using an Automatic Speech Recognition (ASR) API to extract the text commands.\",\n    \"Preprocess the extracted text commands to identify the image modification instructions.\",\n    \"Load the image file 'example.jpg' using an Image Classification or Object Detection API to identify and locate the main object in the image.\",\n    \"Apply the identified image modification instructions to the main object in the image using an Image Editing API.\",\n    \"Save the modified image with a new name.\",\n    \"Load the saved image using an Image Classification or Object Detection API to determine the dominant color of the main object.\",\n    \"Convert the determined color name to speech using a Text-to-Speech API.\",\n    \"Save the speech output as a new audio file.\"\n  ],\n  \"task_nodes\": [\n    \"Automatic Speech Recognition\",\n    \"Image Classification or Object Detection\",\n    \"Image Editing\",\n    \"Image Classification or Object Detection\",\n    \"Text-to-Speech\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Image Classification or Object Detection\"},\n    {\"source\": \"Image Classification or Object Detection\", \"target\": \"Image Editing\"},\n    {\"source\": \"Image Editing\", \"target\": \"Image Classification or Object Detection\"},\n    {\"source\": \"Image Classification or Object Detection\", \"target\": \"Text-to-Speech\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load the example.jpg image\",\n    \"Perform Image Classification to identify the main object in the image\",\n    \"Change the color of the identified object to blue using Image Editing\",\n    \"Perform Object Detection to locate the position of the blue object in the modified image\",\n    \"Generate a summary of the position of the blue object\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image Classification\"\n    },\n    {\n      \"task_name\": \"Image Editing\"\n    },\n    {\n      \"task_name\": \"Object Detection\"\n    },\n    {\n      \"task_name\": \"Text Generation\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification\", \"target\": \"Image Editing\"},\n    {\"source\": \"Image Editing\", \"target\": \"Object Detection\"},\n    {\"source\": \"Object Detection\", \"target\": \"Text Generation\"}\n  ]\n}\n```\n\nThis JSON format represents the task steps, task nodes, and task links required to fulfill the user's request. The user's request involves identifying the main object in an image, changing its color to blue, and then determining the position of the blue object. The task steps are aligned with the tasks nodes, and the number of task steps matches the number of task nodes. The task links reflect the dependencies among the tasks, indicating the order in which the APIs are invoked. The tasks used are Image Classification, Image Editing, Object Detection, and Text Generation."
"```json\n{\n  \"task_steps\": [\n    \"Load and preprocess document image 'example.jpg' using Image-to-Text API.\",\n    \"Use Text-to-Question Answering API to extract answer to the question 'What are the main benefits of the product described in the document?' from the extracted text.\",\n    \"Convert the extracted answer to an audio file using Text-to-Speech API.\",\n    \"Apply audio enhancement and modification using Audio Editing API.\",\n    \"Classify the enhanced audio using Audio Classification API to extract relevant information.\",\n    \"Load and preprocess image 'example.png' using Image Classification or Image-to-Text API.\",\n    \"Use the extracted relevant information from the audio classification to edit the image using Image Editing API.\",\n    \"Convert the edited image back to text using Text-to-Image or Text-to-Speech and Image-to-Text API.\"\n  ],\n  \"task_nodes\": [\n    \"Image-to-Text\",\n    \"Text-to-Question Answering\",\n    \"Text-to-Speech\",\n    \"Audio Editing\",\n    \"Audio Classification\",\n    \"Image Classification or Image-to-Text\",\n    \"Image Editing\",\n    \"Text-to-Image or Text-to-Speech\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image-to-Text\", \"target\": \"Text-to-Question Answering\"},\n    {\"source\": \"Text-to-Question Answering\", \"target\": \"Text-to-Speech\"},\n    {\"source\": \"Text-to-Speech\", \"target\": \"Audio Editing\"},\n    {\"source\": \"Audio Editing\", \"target\": \"Audio Classification\"},\n    {\"source"
"```json\n{\n  \"task_steps\": [\n    \"Load 'example.wav' audio file\",\n    \"Apply audio enhancement techniques to improve quality\",\n    \"Perform source separation on the enhanced audio\",\n    \"Transcribe the separated instructional speech into text\",\n    \"Load 'example.jpg' image file\",\n    \"Apply text-based image editing based on the transcribed text\",\n    \"Classify the modified image to determine its category\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Audio Enhancement and Source Separation\"\n    },\n    {\n      \"task_name\": \"Speech-to-Text Transcription\"\n    },\n    {\n      \"task_name\": \"Text-based Image Editing\"\n    },\n    {\n      \"task_name\": \"Image Classification\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Audio Enhancement and Source Separation\", \"target\": \"Speech-to-Text Transcription\"},\n    {\"source\": \"Speech-to-Text Transcription\", \"target\": \"Text-based Image Editing\"},\n    {\"source\": \"Text-based Image Editing\", \"target\": \"Image Classification\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load the example.jpg image into the system.\",\n    \"Perform image-to-text conversion to extract the chart data as text.\",\n    \"Use text-to-table conversion to transform the chart data into a table format.\",\n    \"Perform tabular classification on the generated table to identify the content.\",\n    \"Use summarization techniques to extract the important information from the classified table.\",\n    \"Edit the example.jpg image based on the findings from the summarization step.\",\n    \"Perform image classification on the edited image to ensure the desired changes have been made.\"\n  ],\n  \"task_nodes\": [\n    \"Image-to-Text\",\n    \"Text-to-Table\",\n    \"Tabular Classification\",\n    \"Summarization\",\n    \"Image Editing\",\n    \"Image Classification\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image-to-Text\", \"target\": \"Text-to-Table\"},\n    {\"source\": \"Text-to-Table\", \"target\": \"Tabular Classification\"},\n    {\"source\": \"Tabular Classification\", \"target\": \"Summarization\"},\n    {\"source\": \"Summarization\", \"target\": \"Image Editing\"},\n    {\"source\": \"Image Editing\", \"target\": \"Image Classification\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    {\n      \"step_description\": \"Perform object detection on example.jpg to extract text labels for detected objects.\"\n    },\n    {\n      \"step_description\": \"Use Text-to-Classification API to get a high-level classification based on the extracted text labels.\"\n    }\n  ],\n  \"task_nodes\": [\n    \"Object Detection\",\n    \"Text-to-Classification\"\n  ],\n  \"task_links\": [\n    {\n      \"source\": \"Object Detection\",\n      \"target\": \"Text-to-Classification\"\n    }\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Generate an image based on the description 'a beautiful sunset on the beach'.\",\n    \"Create a question: 'What is the main color in the image?'.\",\n    \"Perform Text-to-Image task to generate a question image from the question text.\",\n    \"Perform Object Detection task on the generated image to identify the main color.\",\n    \"Perform Text-to-Speech task to convert the identified color into an audio file.\",\n    \"Perform Automatic Speech Recognition task to transcribe the audio file into text.\",\n    \"Perform Text Classification or Emotion Detection task on the transcribed text.\",\n    \"Generate a new text based on the classification or emotion.\",\n    \"Perform Sentence Similarity task to compare the new text with the original description.\"\n  ],\n  \"task_nodes\": [\n    \"Text-to-Image\",\n    \"Object Detection\",\n    \"Text-to-Speech\",\n    \"Automatic Speech Recognition\",\n    \"Text Classification or Emotion Detection\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Text-to-Image\", \"target\": \"Object Detection\"},\n    {\"source\": \"Object Detection\", \"target\": \"Text-to-Speech\"},\n    {\"source\": \"Text-to-Speech\", \"target\": \"Automatic Speech Recognition\"},\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text Classification or Emotion Detection\"},\n    {\"source\": \"Text Classification or Emotion Detection\", \"target\": \"Sentence Similarity\"}\n  ]\n}\n```\n\nThis JSON format represents the task steps, task nodes, and"
"{\n  \"task_steps\": [\n    \"Load 'example.wav' audio file\",\n    \"Improve audio quality using Audio Editing\",\n    \"Transcribe improved audio to text using Automatic Speech Recognition\",\n    \"Classify transcribed text using Text Classification\",\n    \"Generate additional text using Text Generation\",\n    \"Summarize text using Summarization\",\n    \"Convert summarized text back to audio using Text-to-Speech\",\n    \"Combine summarized audio and original audio using Audio Editing\",\n    \"Create a PowerPoint presentation using Text-to-Video\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Audio Editing\"\n    },\n    {\n      \"task_name\": \"Automatic Speech Recognition\"\n    },\n    {\n      \"task_name\": \"Text Classification\"\n    },\n    {\n      \"task_name\": \"Text Generation\"\n    },\n    {\n      \"task_name\": \"Summarization\"\n    },\n    {\n      \"task_name\": \"Text-to-Speech\"\n    },\n    {\n      \"task_name\": \"PowerPoint Presentation Creation\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Audio Editing\", \"target\": \"Automatic Speech Recognition\"},\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text Classification\"},\n    {\"source\": \"Text Classification\", \"target\": \"Text Generation\"},\n    {\"source\": \"Text Generation\", \"target\": \"Summarization\"},\n    {\"source\": \"Summarization\", \"target\": \"Text-to-Speech\"},\n    {\"source\": \""
"```json\n{\n  \"task_steps\": [\n    \"Load the example.wav audio file\",\n    \"Perform Automatic Speech Recognition (ASR) to extract text from the audio file\",\n    \"Translate the recognized text from the source language to English using Translation API\",\n    \"Compare the translated text with the predefined command set using Text Comparison API\",\n    \"Determine the most similar command from the predefined command set\",\n    \"Execute the determined command\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Automatic Speech Recognition\"\n    },\n    {\n      \"task_name\": \"Text Translation\"\n    },\n    {\n      \"task_name\": \"Text Comparison\"\n    },\n    {\n      \"task_name\": \"Command Execution\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text Translation\"},\n    {\"source\": \"Text Translation\", \"target\": \"Text Comparison\"},\n    {\"source\": \"Text Comparison\", \"target\": \"Command Execution\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load 'example.wav' audio file\",\n    \"Improve audio quality using Audio Editing\",\n    \"Transcribe improved audio to text using Automatic Speech Recognition and Text-to-Text\",\n    \"Load 'example.jpg' document image\",\n    \"Extract text from 'example.jpg' using Optical Character Recognition and Text-to-Text\",\n    \"Combine transcribed text and extracted text\",\n    \"Find answer to question 'What is the main idea discussed in the audio?' using Question Answering and Document Question Answering\",\n    \"Create visualization of answer using Text-to-Image\",\n    \"Classify visualization image using Image Classification\"\n  ],\n  \"task_nodes\": [\n    \"Audio Editing\",\n    \"Automatic Speech Recognition\",\n    \"Text-to-Text\",\n    \"Optical Character Recognition\",\n    \"Text-to-Text\",\n    \"Question Answering\",\n    \"Document Question Answering\",\n    \"Text-to-Image\",\n    \"Image Classification\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Audio Editing\", \"target\": \"Automatic Speech Recognition\"},\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text-to-Text\"},\n    {\"source\": \"Text-to-Text\", \"target\": \"Optical Character Recognition\"},\n    {\"source\": \"Text-to-Text\", \"target\": \"Question Answering\"},\n    {\"source\": \"Question Answering\", \"target\": \"Document Question Answering\"},\n    {\"source\": \"Document Question Answering\", \"target\": \"Text"
"```json\n{\n  \"task_steps\": [\n    \"Load the audio file 'example.wav'\",\n    \"Perform Automatic Speech Recognition (ASR) on the audio file to extract text description\",\n    \"Perform Text-to-Image generation using the extracted text description\",\n    \"Perform Image-to-Text generation on the generated image to obtain text description\"\n  ],\n  \"task_nodes\": [\n    \"Automatic Speech Recognition\",\n    \"Text-to-Image Generation\",\n    \"Image-to-Text Generation\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text-to-Image Generation\"},\n    {\"source\": \"Text-to-Image Generation\", \"target\": \"Image-to-Text Generation\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load 'example.wav' audio file\",\n    \"Transcribe the audio file using Automatic Speech Recognition (ASR)\",\n    \"Obtain transcribed text from ASR\",\n    \"Load 'example.jpg' document image\",\n    \"Perform Document Question Answering (DQA) using transcribed text as question\",\n    \"Extract information from document image using DQA\",\n    \"Perform Token Classification on extracted text to identify specific entities\",\n    \"Load empty video template 'example.mp4'\",\n    \"Create video frames based on extracted information using Text-to-Video\",\n    \"Save final video 'example.mp4'\"\n  ],\n  \"task_nodes\": [\n    \"Automatic Speech Recognition\",\n    \"Document Question Answering\",\n    \"Token Classification\",\n    \"Text-to-Video\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Token Classification\"},\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Document Question Answering\"},\n    {\"source\": \"Document Question Answering\", \"target\": \"Token Classification\"},\n    {\"source\": \"Document Question Answering\", \"target\": \"Text-to-Video\"},\n    {\"source\": \"Text-to-Video\", \"target\": \"Save final video\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load the audio file 'example.wav'\",\n    \"Perform Automatic Speech Recognition (ASR) on the audio file to extract text\",\n    \"Summarize the extracted text using Text Summarization\",\n    \"Load the image file 'example.jpg'\",\n    \"Perform Image-to-Text model to extract text from the image\",\n    \"Compare the summarized text with the extracted text using Text Similarity\",\n    \"If the text similarity score is above a certain threshold, proceed with the next step, else ask the user to re-record the audio or provide the correct text\",\n    \"Perform Image Editing based on the summarized text\",\n    \"Perform Image Classification on the edited image to determine its category\"\n  ],\n  \"task_nodes\": [\n    \"Automatic Speech Recognition\",\n    \"Text Summarization\",\n    \"Image-to-Text\",\n    \"Text Similarity\",\n    \"Image Editing\",\n    \"Image Classification\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text Summarization\"},\n    {\"source\": \"Text Summarization\", \"target\": \"Image-to-Text\"},\n    {\"source\": \"Image-to-Text\", \"target\": \"Text Similarity\"},\n    {\"source\": \"Text Similarity\", \"target\": \"Image Editing\"},\n    {\"source\": \"Image Editing\", \"target\": \"Image Classification\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load the example.jpg image\",\n    \"Perform image-to-image transformation to match target image characteristics using Image-to-Image task\",\n    \"Perform depth estimation using Depth Estimation task\",\n    \"Perform object detection and labeling using Object Detection task\",\n    \"Convert object labels to speech using Text-to-Speech task\",\n    \"Record and save the speech output\",\n    \"Perform Automatic Speech Recognition to transcribe the speech back to text\",\n    \"Compare the similarity between the original labels and the transcribed text using Sentence Similarity task\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image-to-Image\"\n    },\n    {\n      \"task_name\": \"Depth Estimation\"\n    },\n    {\n      \"task_name\": \"Object Detection\"\n    },\n    {\n      \"task_name\": \"Text-to-Speech\"\n    },\n    {\n      \"task_name\": \"Automatic Speech Recognition\"\n    },\n    {\n      \"task_name\": \"Sentence Similarity\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Image-to-Image\", \"target\": \"Depth Estimation\"},\n    {\"source\": \"Depth Estimation\", \"target\": \"Object Detection\"},\n    {\"source\": \"Object Detection\", \"target\": \"Text-to-Speech\"},\n    {\"source\": \"Text-to-Speech\", \"target\": \"Automatic Speech Recognition\"},\n    {\"source\": \"Object Detection\", \"target\": \"Sentence Similarity\"},\n    {\"source\": \"Automatic"
"```json\n{\n  \"task_steps\": [\n    \"Load the audio file 'example.wav' for automatic speech recognition.\",\n    \"Perform Automatic Speech Recognition (ASR) on the audio file to extract the command text.\",\n    \"Load the document image 'example.jpg' for text extraction.\",\n    \"Perform Optical Character Recognition (OCR) on the document image to extract the text information.\",\n    \"Combine the command text and the text information.\",\n    \"Generate a response text based on the combined text.\",\n    \"Perform Text-to-Speech (TTS) to transcribe the response text back into audio.\"\n  ],\n  \"task_nodes\": [\n    \"Automatic Speech Recognition (ASR)\",\n    \"Optical Character Recognition (OCR)\",\n    \"Text Generation\",\n    \"Text-to-Speech (TTS)\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Automatic Speech Recognition (ASR)\", \"target\": \"Text Generation\"},\n    {\"source\": \"Optical Character Recognition (OCR)\", \"target\": \"Text Generation\"},\n    {\"source\": \"Text Generation\", \"target\": \"Text-to-Speech (TTS)\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load 'example.jpg' image into memory.\",\n    \"Perform image preprocessing to enhance table image quality.\",\n    \"Perform OCR (Optical Character Recognition) to extract text from the enhanced table image.\",\n    \"Translate the extracted text into English.\",\n    \"Perform tabular classification on the translated text to identify and extract the required column and row data.\",\n    \"Calculate the total revenue for the year 2020 based on the extracted data.\",\n    \"Generate the answer in English.\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image Classification\",\n      \"input\": \"example.jpg\",\n      \"output\": \"enhanced_example.jpg\"\n    },\n    {\n      \"task_name\": \"OCR\",\n      \"input\": \"enhanced_example.jpg\",\n      \"output\": \"extracted_text.txt\"\n    },\n    {\n      \"task_name\": \"Translation\",\n      \"input\": \"extracted_text.txt\",\n      \"output\": \"translated_text.txt\"\n    },\n    {\n      \"task_name\": \"Tabular Classification\",\n      \"input\": \"translated_text.txt\",\n      \"output\": \"processed_data.json\"\n    },\n    {\n      \"task_name\": \"Calculation\",\n      \"input\": \"processed_data.json\",\n      \"output\": \"answer.txt\"\n    },\n    {\n      \"task_name\": \"Text Generation\",\n      \"input\": \"answer.txt\",\n      \"output\": \"final_answer.txt\"\n    }\n  ],\n  \"task_links"
"```json\n{\n  \"task_steps\": [\n    \"Load the example.jpg image into memory.\",\n    \"Perform image segmentation on the image to divide it into segments.\",\n    \"For each segment, perform text extraction to obtain text data.\",\n    \"Pass each text data to a text summarization model to generate a coherent and meaningful sentence.\"\n  ],\n  \"task_nodes\": [\n    \"Image Segmentation\",\n    \"Text Extraction for each segment\",\n    \"Text Summarization for each segment\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification\", \"target\": \"Image Segmentation\"},\n    {\"source\": \"Image Segmentation\", \"target\": \"Text Extraction for each segment\"},\n    {\"source\": \"Text Extraction for each segment\", \"target\": \"Text Summarization for each segment\"},\n    {\"source\": \"Text Summarization for each segment\", \"target\": \"Text Generation\"}\n  ]\n}\n```\n\nNote: I assumed \"Image Classification\" as a prerequisite task to ensure the image is properly understood before performing segmentation. If it's not required, the task link between \"Image Classification\" and \"Image Segmentation\" can be removed."
"{\n  \"task_steps\": [\n    \"Load 'example.jpg' image into memory\",\n    \"Apply image enhancement techniques to improve image quality\",\n    \"Perform image segmentation to separate objects from background\",\n    \"Run object detection algorithm to identify objects in the image\",\n    \"Estimate depth of each object using depth estimation algorithm\",\n    \"Save the enhanced image with object detections and depth estimates\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image Classification\",\n      \"task_description\": \"Classify the image format and validate the image\"\n    },\n    {\n      \"task_name\": \"Image Editing\",\n      \"task_description\": \"Apply image enhancement techniques to improve image quality\"\n    },\n    {\n      \"task_name\": \"Image Segmentation\",\n      \"task_description\": \"Segment the image into objects and background\"\n    },\n    {\n      \"task_name\": \"Object Detection\",\n      \"task_description\": \"Detect objects in the image\"\n    },\n    {\n      \"task_name\": \"Depth Estimation\",\n      \"task_description\": \"Estimate depth of each object in the image\"\n    },\n    {\n      \"task_name\": \"Save Enhanced Image\",\n      \"task_description\": \"Save the enhanced image with object detections and depth estimates\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification\", \"target\": \"Image Editing\"},\n    {\"source\": \"Image Editing\", \"target\": \"Image Segmentation\"},\n    {\"source\": \"Image Segmentation\", \"target\": \"Object Detection\"},\n    {\"source\": \"Object Detection\", \"target\": \""
"{\n    \"task_steps\": [\n        \"Load 'example.wav' audio file\",\n        \"Apply audio enhancement to 'example.wav'\",\n        \"Load 'example.jpg' image file\",\n        \"Apply conversation-based image editing to 'example.jpg'\",\n        \"Apply image enhancement to the edited image\",\n        \"Generate a descriptive label for the enhanced image\",\n        \"Extract significant entities from the label\",\n        \"Identify the event date from the extracted entities\",\n        \"Return the event date as the answer to the query\"\n    ],\n    \"task_nodes\": [\n        {\n            \"task_name\": \"Audio Enhancement\"\n        },\n        {\n            \"task_name\": \"Conversation-based Image Editing\"\n        },\n        {\n            \"task_name\": \"Image Enhancement\"\n        },\n        {\n            \"task_name\": \"Label Generation\"\n        },\n        {\n            \"task_name\": \"Entity Extraction\"\n        },\n        {\n            \"task_name\": \"Event Date Extraction\"\n        }\n    ],\n    \"task_links\": [\n        {\"source\": \"Load 'example.wav' audio file\", \"target\": \"Apply audio enhancement to 'example.wav'\"},\n        {\"source\": \"Load 'example.jpg' image file\", \"target\": \"Apply conversation-based image editing to 'example.jpg'\"},\n        {\"source\": \"Apply conversation-based image editing to 'example.jpg'\", \"target\": \"Apply image enhancement to the edited image\"},\n        {\"source\": \"Apply image enhancement to the edited image\", \"target\": \"Generate a descriptive label for the enhanced image\"},\n        {\"source\": \"Generate a descriptive label for the"
"```json\n{\n  \"task_steps\": [\n    \"Load 'example.wav' audio file and perform Automatic Speech Recognition to extract text.\",\n    \"Load 'example.jpg' image file.\",\n    \"Perform Audio-to-Image editing based on the recognized text.\",\n    \"Perform Object Detection on the edited image.\",\n    \"Extract labels for detected objects.\",\n    \"Generate summary of detected objects\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Automatic Speech Recognition\"\n    },\n    {\n      \"task_name\": \"Image Editing\"\n    },\n    {\n      \"task_name\": \"Object Detection\"\n    },\n    {\n      \"task_name\": \"Text Generation\"\n    },\n    {\n      \"task_name\": \"Tabular Classification\"\n    },\n    {\n      \"task_name\": \"Text Summarization\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Image Editing\"},\n    {\"source\": \"Image Editing\", \"target\": \"Object Detection\"},\n    {\"source\": \"Object Detection\", \"target\": \"Tabular Classification\"},\n    {\"source\": \"Tabular Classification\", \"target\": \"Text Generation\"},\n    {\"source\": \"Text Generation\", \"target\": \"Text Summarization\"}\n  ]\n}\n```\n\nExplanation:\n\nBased on the user request, the following tasks are required to be performed:\n\n1. Automatic Speech Recognition: To extract text from the audio file 'example.wav'.\n2. Image Editing: To edit the image 'example.jpg'"
"```json\n{\n  \"task_steps\": [\n    {\n      \"step_description\": \"Load and preprocess the input image (example.jpg) for image-to-image translation.\",\n      \"task_name\": \"Image-to-Image\"\n    },\n    {\n      \"step_description\": \"Transform the input image to match a certain target image domain using image-to-image translation.\",\n      \"task_name\": \"Image-to-Image\"\n    },\n    {\n      \"step_description\": \"Load and preprocess the transformed image for depth estimation.\",\n      \"task_name\": \"Depth Estimation\"\n    },\n    {\n      \"step_description\": \"Predict the depth of objects within the transformed image using depth estimation.\",\n      \"task_name\": \"Depth Estimation\"\n    },\n    {\n      \"step_description\": \"Load and preprocess the image containing the table for tabular classification.\",\n      \"task_name\": \"Tabular Classification\"\n    },\n    {\n      \"step_description\": \"Classify the table contained in the image using tabular classification.\",\n      \"task_name\": \"Tabular Classification\"\n    },\n    {\n      \"step_description\": \"Generate a conversational response based on the table classification result.\",\n      \"task_name\": \"Conversational\"\n    },\n    {\n      \"step_description\": \"Compare the generated conversational response with the reference text using text similarity.\",\n      \"task_name\": \"Text Similarity\"\n    }\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image-to-Image\"\n    },\n    {\n      \"task_name\": \"Depth Estimation\"\n    },\n    {\n      \""
"{\"task_steps\": [\n  \"Load the example.jpg image into the system.\",\n  \"Perform Object Detection on the loaded image to identify and extract the objects present.\",\n  \"Calculate the area of each identified object.\",\n  \"Determine the object with the largest area.\",\n  \"Extract the label of the most dominating object.\",\n  \"Generate the answer: 'The most dominating object in the image is [object label]'.\"\n],\n\"task_nodes\": [\n  \"Image Classification: Object Detection\",\n  \"Text-to-None: Extract object labels\",\n  \"Text-to-None: Calculate object areas\",\n  \"Text-to-None: Determine most dominating object\",\n  \"Text-to-Text: Generate answer\"\n],\n\"task_links\": [\n  {\"source\": \"Image Classification: Object Detection\", \"target\": \"Text-to-None: Extract object labels\"},\n  {\"source\": \"Text-to-None: Extract object labels\", \"target\": \"Text-to-None: Calculate object areas\"},\n  {\"source\": \"Text-to-None: Calculate object areas\", \"target\": \"Text-to-None: Determine most dominating object\"},\n  {\"source\": \"Text-to-None: Determine most dominating object\", \"target\": \"Text-to-Text: Generate answer\"}\n]\n}\n\n# EXPLANATION #:\n# The user request involves answering a question about the most dominating object in an image and comparing the question with the generated answer.\n# To fulfill this request, we need to perform Object Detection on the image to identify and extract the objects present.\n# Then, we calculate the area of each identified object and determine the object with the largest area.\n# Finally"
"```json\n{\n  \"task_steps\": [\n    \"Load 'example.wav' audio file\",\n    \"Perform Automatic Speech Recognition (ASR) on the audio file to extract text\",\n    \"Classify the content of the text using Text Classification\",\n    \"Generate a conversation about the classified text using Conversational AI\",\n    \"Paraphrase the conversation using Text Paraphrasing\",\n    \"Load 'example.jpg' image file\",\n    \"Perform Image Classification on the image\",\n    \"Generate a question related to the image and its classification\",\n    \"Use Text-to-Question Answering model to answer the question using the paraphrased conversation as context\"\n  ],\n  \"task_nodes\": [\n    \"Automatic Speech Recognition\",\n    \"Text Classification\",\n    \"Conversational AI\",\n    \"Text Paraphrasing\",\n    \"Image Classification\",\n    \"Text-to-Question Answering\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text Classification\"},\n    {\"source\": \"Text Classification\", \"target\": \"Conversational AI\"},\n    {\"source\": \"Conversational AI\", \"target\": \"Text Paraphrasing\"},\n    {\"source\": \"Image Classification\", \"target\": \"Text-to-Question Answering\"},\n    {\"source\": \"Text Paraphrasing\", \"target\": \"Text-to-Question Answering\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load the example.jpg image file.\",\n    \"Perform Object Detection on the loaded image to identify objects present.\",\n    \"Extract the object names and their respective bounding boxes from the Object Detection output.\",\n    \"For each object, perform Image-to-Text task to generate a textual description of the object.\",\n    \"Store the generated textual descriptions in a list.\",\n    \"Combine the textual descriptions into a coherent audio description using Text-to-Speech task.\"\n  ],\n  \"task_nodes\": [\n    \"Object Detection\",\n    \"Image-to-Text (for each object)\",\n    \"Text-to-Speech\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Object Detection\", \"target\": \"Image-to-Text (for each object)\"},\n    {\"source\": \"Image-to-Text (for each object)\", \"target\": \"Text-to-Speech\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load 'example.jpg' image into memory\",\n    \"Apply image-to-image transformation to 'example.jpg' to match desired style\",\n    \"Perform object detection on transformed image to identify objects\",\n    \"For each identified object, perform image classification to obtain object labels\",\n    \"Convert each object label to speech using text-to-speech API\",\n    \"Record and transcribe the speech output using automatic speech recognition API\",\n    \"Store the transcribed text for each object label\",\n    \"Generate a new description based on the identified objects and their labels\",\n    \"Compare the generated description's similarity to 'The beautiful scenery in the park has several trees, a bench, and people walking by.' using sentence similarity API\"\n  ],\n  \"task_nodes\": [\n    \"Image-to-Image\",\n    \"Object Detection\",\n    \"Image Classification\",\n    \"Text-to-Speech\",\n    \"Automatic Speech Recognition\",\n    \"Text Generation\",\n    \"Sentence Similarity\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image-to-Image\", \"target\": \"Object Detection\"},\n    {\"source\": \"Object Detection\", \"target\": \"Image Classification\"},\n    {\"source\": \"Image Classification\", \"target\": \"Text-to-Speech\"},\n    {\"source\": \"Text-to-Speech\", \"target\": \"Automatic Speech Recognition\"},\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text Generation\"},\n    {\"source\": \"Text Generation\", \"target\": \"Sentence Similarity\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load the 'example.jpg' image.\",\n    \"Perform Image Classification on the loaded image to identify its class.\",\n    \"Based on the identified class, generate a text description.\",\n    \"Use Text-to-Video API to generate a video based on the text description.\",\n    \"Save the generated video with a unique name.\"\n  ],\n  \"task_nodes\": [\n    \"Image Classification\",\n    \"Text-to-Video\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification\", \"target\": \"Text-to-Video\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load 'example.jpg' image into memory.\",\n    \"Perform table text extraction using OCR (Optical Character Recognition) technology.\",\n    \"Save extracted text as a plain text file.\",\n    \"Load 'example_target.jpg' image into memory.\",\n    \"Perform image-to-text conversion on 'example_target.jpg' to extract its textual representation.\",\n    \"Compare the extracted text from the table image and the target image using Text Similarity task.\",\n    \"If text similarity score is above a certain threshold, proceed with the next step, else return an error.\",\n    \"Generate a new image based on the extracted text using Text-to-Image task.\",\n    \"Load the generated image into memory.\",\n    \"Perform image style transfer on the generated image to match the style of 'example_target.jpg' using Image-to-Image task.\",\n    \"Save the transformed image.\",\n    \"Perform Image Classification task on the transformed image to classify it as a table.\"\n  ],\n  \"task_nodes\": [\n    \"Image Classification\",\n    \"Text-to-Image\",\n    \"Image-to-Image\",\n    \"Text Similarity\",\n    \"OCR (Optical Character Recognition)\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification\", \"target\": \"OCR (Optical Character Recognition)\"},\n    {\"source\": \"OCR (Optical Character Recognition)\", \"target\": \"Text-to-Image\"},\n    {\"source\": \"Text-to-Image\", \"target\": \"Image-to-Image\"},\n    {\"source\": \"Image-to-Image\", \"target\": \"Text Similarity\"},\n   "
"```json\n{\n  \"task_steps\": [\n    \"Load 'example.wav' audio file\",\n    \"Perform Automatic Speech Recognition (ASR) on the audio file to extract command text\",\n    \"Translate command text to French using Translation API\",\n    \"Load 'example.jpg' image file\",\n    \"Perform Text-to-Image generation to create an image based on the translated command text\",\n    \"Perform Image Editing on the generated image using the translated command text\",\n    \"Perform Depth Estimation on the edited image using Depth Estimation API\",\n    \"Perform Image-to-Image comparison between the depth-estimated image and the target domain images using Image Similarity API\",\n    \"Retrieve question about the transformed image from user\",\n    \"Perform Visual Question Answering on the depth-estimated image to answer the user's question\",\n    \"Load given document text\",\n    \"Perform Document Question Answering on the document text to retrieve answer\"\n  ],\n  \"task_nodes\": [\n    \"Automatic Speech Recognition\",\n    \"Translation\",\n    \"Text-to-Image Generation\",\n    \"Image Editing\",\n    \"Depth Estimation\",\n    \"Image Similarity\",\n    \"Visual Question Answering\",\n    \"Document Question Answering\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Translation\"},\n    {\"source\": \"Translation\", \"target\": \"Text-to-Image Generation\"},\n    {\"source\": \"Text-to-Image Generation\", \"target\": \"Image Editing\"},\n    {\"source\": \"Image Editing\", \"target\": \"Depth Estimation\"},\n    {\"source\":"
"{\n  \"task_steps\": [\n    \"Step 1: Text-to-Speech - Convert the text 'The quick brown fox jumps over the lazy dog' to speech using a Text-to-Speech API.\",\n    \"Step 2: Automatic Speech Recognition - Transcribe the speech back to text using an Automatic Speech Recognition API.\",\n    \"Step 3: Text Editing - Generate a new version of the text based on the user's request.\",\n    \"Step 4: Translation - Translate the new text to French using a Translation API.\",\n    \"Step 5: Summarization - Summarize the original text 'The quick brown fox jumps over the lazy dog'.\",\n    \"Step 6: Question Answering - Answer the question 'What is the main idea of the text?' based on the image 'example.jpg'.\",\n    \"Step 7: Text-to-Video - Generate a video illustrating the answer to the question 'What is the main idea of the text?'.\"\n  ],\n  \"task_nodes\": [\n    \"Text-to-Speech\",\n    \"Automatic Speech Recognition\",\n    \"Text Editing\",\n    \"Translation\",\n    \"Summarization\",\n    \"Question Answering\",\n    \"Text-to-Video\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Text-to-Speech\", \"target\": \"Automatic Speech Recognition\"},\n    {\"source\": \"Text Editing\", \"target\": \"Translation\"},\n    {\"source\": \"Text Editing\", \"target\": \"Summarization\"},\n    {\"source\": \"Summarization\", \"target\": \"Question Answering\"},\n    {\"source\": \"Question Answ"
"{\n  \"task_steps\": [\n    \"Read the news article to understand the main points.\",\n    \"Identify the key points and facts from the article.\",\n    \"Use a summarization model to generate a brief summary of the article.\",\n    \"Review and edit the summary to ensure accuracy and clarity.\",\n    \"Use a question generation model to create potential discussion questions related to the article.\",\n    \"Review and refine the discussion questions to ensure they are clear, open-ended, and thought-provoking.\",\n    \"Prepare to discuss the article and its implications with your friends using the summary and discussion questions.\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Text Summarization\"\n    },\n    {\n      \"task_name\": \"Question Generation\"\n    }\n  ],\n  \"task_links\": [\n    {\n      \"source\": \"Text Understanding\",\n      \"target\": \"Text Summarization\"\n    },\n    {\n      \"source\": \"Text Summarization\",\n      \"target\": \"Question Generation\"\n    }\n  ]\n}\n\n# EXPLANATION #:\n# The user request is to understand a news article about climate change and prepare to discuss it with friends.\n# To accomplish this, we will first read and understand the main points of the article.\n# Next, we will identify the key points and facts from the article.\n# Then, we will use a text summarization model to generate a brief summary of the article.\n# We will review and edit the summary to ensure accuracy and clarity.\n# After that, we will use a question generation model to create potential discussion questions related to the article.\n# We will review and refine the discussion questions to ensure they are clear, open-ended, and thought-provoking."
"```json\n{\n  \"task_steps\": [\n    \"Load example.wav audio file for speech recognition\",\n    \"Perform Automatic Speech Recognition (ASR) on example.wav to extract text description\",\n    \"Load example.jpg image for image processing\",\n    \"Perform Image-to-Text conversion to extract initial text description from image\",\n    \"Compare text descriptions from speech recognition and image processing to identify differences\",\n    \"Generate text instructions based on differences for image editing\",\n    \"Perform Image Editing based on text instructions\",\n    \"Save edited image as output.jpg\",\n    \"Load output.jpg image for depth estimation\",\n    \"Perform Depth Estimation on output.jpg image\"\n  ],\n  \"task_nodes\": [\n    \"Automatic Speech Recognition\",\n    \"Image-to-Text conversion\",\n    \"Text Comparison\",\n    \"Image Editing\",\n    \"Depth Estimation\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text Comparison\"},\n    {\"source\": \"Image-to-Text conversion\", \"target\": \"Text Comparison\"},\n    {\"source\": \"Text Comparison\", \"target\": \"Image Editing\"},\n    {\"source\": \"Image Editing\", \"target\": \"Depth Estimation\"}\n  ]\n}\n```"
"{\n  \"task_steps\": [\n    \"Load image 'example.jpg' for table processing\",\n    \"Identify and extract yellow columns from the table image\",\n    \"Change column colors from yellow to blue\",\n    \"Load target image 'target_example.png' for style transfer\",\n    \"Apply style transfer to the modified table image to make it similar to target image\",\n    \"Perform table content classification using a suitable model\",\n    \"Translate the classification result into French using a translation model\",\n    \"Generate speech audio from the translated text using a text-to-speech model\",\n    \"Recognize a command from the speech audio using an automatic speech recognition model\",\n    \"Generate a video based on the recognized command\"\n  ],\n  \"task_nodes\": [\n    \"Image Classification (Object Detection and Tabular Classification)\",\n    \"Text-to-Image (Change column colors)\",\n    \"Image-to-Image (Style transfer)\",\n    \"Translation (Text to Speech and Text to French)\",\n    \"Text-to-Speech\",\n    \"Automatic Speech Recognition\",\n    \"Text Generation (Video creation based on command)\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification\", \"target\": \"Text-to-Image\"},\n    {\"source\": \"Text-to-Image\", \"target\": \"Image-to-Image\"},\n    {\"source\": \"Image-to-Image\", \"target\": \"Translation\"},\n    {\"source\": \"Translation\", \"target\": \"Text-to-Speech\"},\n    {\"source\": \"Text-to-Speech\", \"target\": \"Automatic Speech Recognition\"},\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text Generation\"}\n "
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Load and preprocess the audio file 'example.wav' for speech recognition.\",\n            \"task_name\": \"Automatic Speech Recognition\"\n        },\n        {\n            \"step_description\": \"Extract keywords from the transcribed speech.\",\n            \"task_name\": \"Text Preprocessing\"\n        },\n        {\n            \"step_description\": \"Generate a conversation based on the extracted keywords.\",\n            \"task_name\": \"Text Generation\"\n        },\n        {\n            \"step_description\": \"Load and preprocess the document image 'example.jpg' for text extraction.\",\n            \"task_name\": \"Text-to-Image\"\n        },\n        {\n            \"step_description\": \"Extract specific entities from the conversation and the document text.\",\n            \"task_name\": \"Named Entity Recognition\"\n        },\n        {\n            \"step_description\": \"Answer a question related to the identified entities.\",\n            \"task_name\": \"Question Answering\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Automatic Speech Recognition\",\n        \"Text Preprocessing\",\n        \"Text Generation\",\n        \"Text-to-Image\",\n        \"Named Entity Recognition\",\n        \"Question Answering\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text Preprocessing\"},\n        {\"source\": \"Text Preprocessing\", \"target\": \"Text Generation\"},\n        {\"source\": \"Text Generation\", \"target\": \"Text-to-Image\"},\n        {\"source\": \"Text-to-Image\", \"target\": \"Named Entity Recognition\"},\n        {\""
"{\n  \"task_steps\": [\n    \"Load the example.jpg image into the system.\",\n    \"Perform Object Detection task to identify the main objects in the image.\",\n    \"Extract the information about the main object from the Object Detection results.\",\n    \"Generate a conversational response describing the main object using the extracted information.\"\n  ],\n  \"task_nodes\": [\n    \"Image Classification\",\n    \"Object Detection\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification\", \"target\": \"Object Detection\"}\n  ]\n}\n\n# EXPLANATION #:\n# The user request can be fulfilled by performing Object Detection task to identify the main object in the example.jpg image,\n# and then generating a conversational response describing the main object using the extracted information.\n# To load the image into the system, we can use Image Classification task which also supports image loading functionality.\n# Therefore, we can chain these two tasks together to achieve the user's request.\n# The task steps are described in detail in the \"task_steps\" array, and the tasks to be executed in sequence are listed in the \"task_nodes\" array.\n# The dependencies among task nodes are reflected in the \"task_links\" array, where the Object Detection task depends on the Image Classification task."
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Load the audio file 'example.wav' for emotion and speaker's preference analysis.\",\n            \"task_name\": \"Automatic Speech Recognition\"\n        },\n        {\n            \"step_description\": \"Extract emotions and speaker's preferences from the transcribed text.\",\n            \"task_name\": \"Text Analysis\"\n        },\n        {\n            \"step_description\": \"Load the image 'example.jpg' for modification.\",\n            \"task_name\": \"Image Classification\"\n        },\n        {\n            \"step_description\": \"Determine the current emotion and speaker's preference based on the extracted information.\",\n            \"task_name\": \"Decision Making\"\n        },\n        {\n            \"step_description\": \"Select an appropriate image enhancement technique based on the determined emotion and speaker's preference.\",\n            \"task_name\": \"Image Editing\"\n        },\n        {\n            \"step_description\": \"Apply the selected image enhancement technique to the image 'example.jpg'.\",\n            \"task_name\": \"Image Editing\"\n        },\n        {\n            \"step_description\": \"Save the modified image with a new name.\",\n            \"task_name\": \"File Manipulation\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Automatic Speech Recognition\",\n        \"Text Analysis\",\n        \"Image Classification\",\n        \"Decision Making\",\n        \"Image Editing\",\n        \"File Manipulation\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text Analysis\"},\n        {\"source\": \"Text Analysis\", \"target\": \"Decision Making"
"{\n  \"task_steps\": [\n    \"Step 1: Text-to-Speech conversion of input text 'Rainy clouds are forming in the sky.' using Text-to-Speech API.\",\n    \"Step 2: Save the generated audio file.\",\n    \"Step 3: Use Audio Enhancement API to improve the audio quality of the saved file.\",\n    \"Step 4: Perform Automatic Speech Recognition on the enhanced audio file to transcribe it back to text.\",\n    \"Step 5: Use the transcribed text 'The weather in the image is rainy.' to search for a more relevant image using Image Search API.\",\n    \"Step 6: Save the downloaded image with the new name.\",\n    \"Step 7: Use Visual Question Answering API to determine the answer to the question 'What is the weather like in the image?' based on the new image.\",\n    \"Step 8: Generate a video using the answer and Text-to-Speech API to create a narration of the answer.\"\n  ],\n  \"task_nodes\": [\n    \"Text-to-Speech\",\n    \"Audio Enhancement\",\n    \"Automatic Speech Recognition\",\n    \"Image Search\",\n    \"Visual Question Answering\",\n    \"Text-to-Speech (for video generation)\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Text-to-Speech\", \"target\": \"Save audio file\"},\n    {\"source\": \"Save audio file\", \"target\": \"Audio Enhancement\"},\n    {\"source\": \"Audio Enhancement\", \"target\": \"Automatic Speech Recognition\"},\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Use transcribed text for Image"
"```json\n{\n  \"task_steps\": [\n    \"Generate an image from text description using Text-to-Image task\",\n    \"Segment the generated image using Image Segmentation task\",\n    \"Edit the segmented image to match the description ('A red apple on a blue background') using Image Editing task\",\n    \"Estimate depth in the edited image using Depth Estimation task\",\n    \"Detect objects in the depth-estimated image using Object Detection task\",\n    \"Generate an audio file with spoken labels of detected objects using Text-to-Speech task\"\n  ],\n  \"task_nodes\": [\n    \"Text-to-Image\",\n    \"Image Segmentation\",\n    \"Image Editing\",\n    \"Depth Estimation\",\n    \"Object Detection\",\n    \"Text-to-Speech\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Text-to-Image\", \"target\": \"Image Segmentation\"},\n    {\"source\": \"Image Segmentation\", \"target\": \"Image Editing\"},\n    {\"source\": \"Image Editing\", \"target\": \"Depth Estimation\"},\n    {\"source\": \"Depth Estimation\", \"target\": \"Object Detection\"},\n    {\"source\": \"Object Detection\", \"target\": \"Text-to-Speech\"}\n  ]\n}\n```"
"{\n  \"task_steps\": [\n    \"Load 'example.jpg' into memory\",\n    \"Identify the red car object in the image\",\n    \"Change the color of the red car object to blue\",\n    \"Save the modified image with a new name\",\n    \"Load the saved image back into memory\",\n    \"Perform object detection on the loaded image\",\n    \"Extract the detected objects' information\",\n    \"Summarize the extracted information\",\n    \"Classify the important tokens in the summary\",\n    \"Translate the summary into French\",\n    \"Answer the question 'Quelle est la couleur de la voiture?' based on the translated summary and modified image\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image Classification\",\n      \"input\": {\n        \"image_path\": \"example.jpg\",\n        \"object_name\": \"red car\"\n      },\n      \"output\": {\n        \"modified_image_path\": \"output_image.jpg\"\n      }\n    },\n    {\n      \"task_name\": \"Object Detection\",\n      \"input\": {\n        \"image_path\": \"output_image.jpg\"\n      },\n      \"output\": {\n        \"detected_objects\": []\n      }\n    },\n    {\n      \"task_name\": \"Text Summarization\",\n      \"input\": {\n        \"object_information\": \"output_object_info\"\n      },\n      \"output\": {\n        \"summary\": \"\"\n      }\n    },\n    {\n      \"task_name\": \"Token Classification\",\n      \"input\": {\n        \"summary\": \"\"\n      },\n      \"output\": {\n        \"classified_tokens\":"
"```json\n{\n  \"task_steps\": [\n    \"Load the example.jpg image\",\n    \"Invoke Image-to-Image task node to transform the example.jpg image to match the style of the target image\",\n    \"Invoke Image Segmentation task node to segment the transformed image\",\n    \"Invoke Text-to-Image task node to generate a new image with all objects green based on the segmented image and the text 'Make all objects green'\",\n    \"Invoke Image Classification task node to classify the generated green image and assign it a label\",\n    \"Invoke Text Generation task node to generate a new text based on the image classification label\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image-to-Image\"\n    },\n    {\n      \"task_name\": \"Image Segmentation\"\n    },\n    {\n      \"task_name\": \"Text-to-Image\"\n    },\n    {\n      \"task_name\": \"Image Classification\"\n    },\n    {\n      \"task_name\": \"Text Generation\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Image-to-Image\", \"target\": \"Image Segmentation\"},\n    {\"source\": \"Image Segmentation\", \"target\": \"Text-to-Image\"},\n    {\"source\": \"Text-to-Image\", \"target\": \"Image Classification\"},\n    {\"source\": \"Image Classification\", \"target\": \"Text Generation\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load 'example.jpg' image into memory.\",\n    \"Perform Image Preprocessing.\",\n    \"Run Image Segmentation task to segment the image into separate objects.\",\n    \"Run Depth Estimation task to estimate the depth of objects in the image.\",\n    \"Run Object Detection task to identify and label the detected objects.\",\n    \"Preprocess the Object Detection labels for comparison.\",\n    \"Run Text Preprocessing task on 'example sentence'.\",\n    \"Run Text-to-Vector task to convert 'example sentence' and Object Detection labels into vectors.\",\n    \"Run Sentence Similarity task to compare the similarity between the vectors.\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image Segmentation\"\n    },\n    {\n      \"task_name\": \"Depth Estimation\"\n    },\n    {\n      \"task_name\": \"Object Detection\"\n    },\n    {\n      \"task_name\": \"Text Preprocessing\"\n    },\n    {\n      \"task_name\": \"Text-to-Vector\"\n    },\n    {\n      \"task_name\": \"Sentence Similarity\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Loading\", \"target\": \"Image Preprocessing\"},\n    {\"source\": \"Image Preprocessing\", \"target\": \"Image Segmentation\"},\n    {\"source\": \"Image Preprocessing\", \"target\": \"Depth Estimation\"},\n    {\"source\": \"Image Preprocessing\", \"target\": \"Object Detection\"},\n    {\"source\": \"Object Detection\", \"target\": \"Object Label Preprocessing\"},\n    {\"source\": \"Text Preprocessing\", \"target\": \"Text-to"
"```json\n{\n  \"task_steps\": [\n    \"Load the image 'example.jpg' and extract text using OCR (Optical Character Recognition) technology.\",\n    \"Perform Text-to-Speech conversion to generate an initial audio file.\",\n    \"Apply Audio-to-Audio enhancement techniques to improve the audio quality.\"\n  ],\n  \"task_nodes\": [\n    \"Text-to-Speech\",\n    \"Image Classification (to confirm the presence of text in the image)\",\n    \"Object Detection (to locate the text in the image)\",\n    \"Optical Character Recognition (to extract text from the image)\",\n    \"Audio-to-Audio\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification\", \"target\": \"Object Detection\"},\n    {\"source\": \"Object Detection\", \"target\": \"Optical Character Recognition\"},\n    {\"source\": \"Optical Character Recognition\", \"target\": \"Text-to-Speech\"},\n    {\"source\": \"Text-to-Speech\", \"target\": \"Audio-to-Audio\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load the image 'example.jpg' and extract the table region using Image Segmentation.\",\n    \"Perform Image-to-Text conversion on the table region to extract the text data.\",\n    \"Apply Text Preprocessing to the extracted text data for further processing.\",\n    \"Perform Text Classification on the preprocessed text data to classify the table.\",\n    \"Generate a new image with the edited table style using Image Editing. Set the background color to blue and increase the brightness as per the user request.\",\n    \"Perform Text-to-Speech conversion on the classified text to generate an audio file.\"\n  ],\n  \"task_nodes\": [\n    \"Image Segmentation\",\n    \"Image-to-Text\",\n    \"Text Preprocessing\",\n    \"Text Classification\",\n    \"Image Editing\",\n    \"Text-to-Speech\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Segmentation\", \"target\": \"Image-to-Text\"},\n    {\"source\": \"Image-to-Text\", \"target\": \"Text Preprocessing\"},\n    {\"source\": \"Text Preprocessing\", \"target\": \"Text Classification\"},\n    {\"source\": \"Text Classification\", \"target\": \"Image Editing\"},\n    {\"source\": \"Image Editing\", \"target\": \"Text-to-Speech\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load the image 'example.jpg' using an Image-to-Text API to extract text from the image.\",\n    \"Perform Text-to-Speech conversion of the extracted text for better understanding and verification.\",\n    \"Use a Text-to-Speech API to listen to the converted speech and ensure accuracy of the extracted text.\",\n    \"Perform Named Entity Recognition (NER) on the extracted text to identify dates, individuals, and places.\",\n    \"Use a Tabular Classification API to validate and correct any incorrectly identified named entities.\",\n    \"Use a Machine Translation API to translate the identified named entities from English to French.\",\n    \"Use a Text-to-Speech API to listen to the translated text for verification and accuracy.\",\n    \"Save the translated named entities in a text file for future reference.\"\n  ],\n  \"task_nodes\": [\n    \"Image-to-Text\",\n    \"Text-to-Speech (for verification)\",\n    \"Named Entity Recognition\",\n    \"Tabular Classification\",\n    \"Machine Translation\",\n    \"Text-to-Speech (for verification and accuracy)\",\n    \"Save Translated Named Entities\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image-to-Text\", \"target\": \"Text-to-Speech (for verification)\"},\n    {\"source\": \"Text-to-Speech (for verification)\", \"target\": \"Named Entity Recognition\"},\n    {\"source\": \"Named Entity Recognition\", \"target\": \"Tabular Classification\"},\n    {\"source\": \"Tabular Classification\", \"target\": \"Machine Translation\"},\n    {\"source\": \"Machine Translation\", \"target\": \"Text-to-"
"{\n  \"task_steps\": [\n    \"Load 'example.wav' for audio processing\",\n    \"Apply audio enhancement techniques to improve the quality of 'example.wav'\",\n    \"Classify the enhanced audio to determine the speaker's emotion using an Emotion Recognition model\",\n    \"Load 'example.jpg' for image processing\",\n    \"Edit the color of the object in 'example.jpg' based on the emotion label\",\n    \"Determine the primary color of the object after editing using an Object Detection and Color Extraction model\",\n    \"Generate a text description of the primary color\",\n    \"Load 'example.mp4' for video processing\",\n    \"Create a video of the text description using the given 'example.mp4'\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Audio Enhancement and Emotion Recognition\"\n    },\n    {\n      \"task_name\": \"Image Processing and Object Detection with Color Extraction\"\n    },\n    {\n      \"task_name\": \"Text Generation\"\n    },\n    {\n      \"task_name\": \"Video Processing\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Load 'example.wav' for audio processing\", \"target\": \"Apply audio enhancement techniques to improve the quality of 'example.wav'\"},\n    {\"source\": \"Apply audio enhancement techniques to improve the quality of 'example.wav'\", \"target\": \"Classify the enhanced audio to determine the speaker's emotion using an Emotion Recognition model\"},\n    {\"source\": \"Load 'example.jpg' for image processing\", \"target\": \"Edit the color of the object in 'example.jpg' based on the emotion label\"},"
"```json\n{\n  \"task_steps\": [\n    \"Load the text description: 'A beautiful beach with blue water and white sand'.\",\n    \"Perform Text-to-Image generation using the description.\",\n    \"Save the generated image as 'beach_image.jpg'.\",\n    \"Load 'beach_image.jpg' for image editing.\",\n    \"Change the color of the water to green using Image Editing.\",\n    \"Save the edited image as 'green_beach_image.jpg'.\",\n    \"Perform Text-to-Speech to confirm the color of the water in the final image.\",\n    \"Load 'green_beach_image.jpg' for question answering.\",\n    \"Perform Question Answering to determine the color of the water in the final image.\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Text-to-Image\"\n    },\n    {\n      \"task_name\": \"Image Editing\"\n    },\n    {\n      \"task_name\": \"Text-to-Speech\"\n    },\n    {\n      \"task_name\": \"Question Answering\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Text-to-Image\", \"target\": \"Image Editing\"},\n    {\"source\": \"Image Editing\", \"target\": \"Text-to-Speech\"},\n    {\"source\": \"Text-to-Speech\", \"target\": \"Question Answering\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load document image using Image-to-Text API to extract text from the image and store it in a variable.\",\n    \"Use Document Question Answering API to extract answer from the document text and the given question.\",\n    \"Use Text-to-Video API to generate a video that visually describes the answer.\"\n  ],\n  \"task_nodes\": [\n    \"Image-to-Text\",\n    \"Document Question Answering\",\n    \"Text-to-Video\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image-to-Text\", \"target\": \"Document Question Answering\"},\n    {\"source\": \"Document Question Answering\", \"target\": \"Text-to-Video\"}\n  ]\n}\n```"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Perform image classification to identify the image as a table image.\",\n            \"task_name\": \"Image Classification\"\n        },\n        {\n            \"step_description\": \"Perform table layout analysis and extract relevant data from the table.\",\n            \"task_name\": \"Tabular Classification\"\n        },\n        {\n            \"step_description\": \"Classify the table into a relevant category based on the extracted data.\",\n            \"task_name\": \"Tabular Classification\"\n        },\n        {\n            \"step_description\": \"Extract the quarter 3 data from the table.\",\n            \"task_name\": \"Text Extraction\"\n        },\n        {\n            \"step_description\": \"Perform text summarization to identify the total revenue in quarter 3.\",\n            \"task_name\": \"Text Summarization\"\n        },\n        {\n            \"step_description\": \"Answer the question: 'What was the total revenue in Q3?'\",\n            \"task_name\": \"Question Answering\"\n        },\n        {\n            \"step_description\": \"Identify any specific entities (such as dates and individuals) in the answer.\",\n            \"task_name\": \"Named Entity Recognition\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Image Classification\",\n        \"Tabular Classification\",\n        \"Text Extraction\",\n        \"Text Summarization\",\n        \"Question Answering\",\n        \"Named Entity Recognition\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Image Classification\", \"target\": \"Tabular Classification\"},\n        {\"source\": \"Tabular Classification\", \"target\": \"Text"
"```json\n{\n  \"task_steps\": [\n    \"Load the input image 'example.jpg'.\",\n    \"Perform object detection on the input image to identify and extract all objects.\",\n    \"For each object identified, generate a new image with that object as the focus using image-to-image model.\",\n    \"Classify each generated image using an image classification model.\",\n    \"Edit the original image based on the classified information.\",\n    \"Perform text-to-speech conversion on the answer to the question 'How many red objects are in the image?'\",\n    \"Determine the number of red objects in the original image using an image segmentation model and question answering system.\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Object Detection\"\n    },\n    {\n      \"task_name\": \"Image Generation\"\n    },\n    {\n      \"task_name\": \"Image Classification\"\n    },\n    {\n      \"task_name\": \"Image Editing\"\n    },\n    {\n      \"task_name\": \"Question Answering\"\n    },\n    {\n      \"task_name\": \"Text-to-Speech\"\n    },\n    {\n      \"task_name\": \"Image Segmentation\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Object Detection\", \"target\": \"Image Generation\"},\n    {\"source\": \"Image Generation\", \"target\": \"Image Classification\"},\n    {\"source\": \"Image Generation\", \"target\": \"Image Editing\"},\n    {\"source\": \"Image Classification\", \"target\": \"Text-to-Speech\"},\n    {\"source\": \"Image Segmentation\", \"target\": \"Question Answering\"}\n  ]\n}"
"{\n  \"task_steps\": [\n    {\n      \"step_description\": \"Perform document question answering to extract the answer to the given question 'What is the capital of France?' from the provided document 'example.pdf'.\"\n    },\n    {\n      \"step_description\": \"Generate a conversational response based on the extracted answer.\"\n    },\n    {\n      \"step_description\": \"Refine the conversational response to ensure it is clear, concise, and polite.\"\n    },\n    {\n      \"step_description\": \"Invoke text-to-speech API to convert the refined conversational response into an audio format.\"\n    },\n    {\n      \"step_description\": \"Invoke automatic speech recognition API to convert the generated audio into text format.\"\n    },\n    {\n      \"step_description\": \"Invoke translation API to translate the text into Spanish.\"\n    },\n    {\n      \"step_description\": \"Generate a conversational response in Spanish based on the translated text.\"\n    }\n  ],\n  \"task_nodes\": [\n    \"Document Question Answering\",\n    \"Text-to-Speech\",\n    \"Automatic Speech Recognition\",\n    \"Translation\"\n  ],\n  \"task_links\": [\n    {\n      \"source\": \"Document Question Answering\",\n      \"target\": \"Text-to-Speech\"\n    },\n    {\n      \"source\": \"Text-to-Speech\",\n      \"target\": \"Automatic Speech Recognition\"\n    },\n    {\n      \"source\": \"Automatic Speech Recognition\",\n      \"target\": \"Translation\"\n    },\n    {\n      \"source\": \"Translation\",\n      \"target\": \"Conversational Response Generation (Spanish)\""
"```json\n{\n  \"task_steps\": [\n    \"Read the input text 'The quick brown fox jumps over the lazy dog.' and save it as a variable.\",\n    \"Read the input image 'example.jpg' and save it as a variable.\",\n    \"Use Text-to-Speech API to convert the input text to speech and save the audio file.\",\n    \"Use Automatic Speech Recognition API to transcribe the audio file and extract the speech text.\",\n    \"Use Audio Classification API to classify the speech text and save the classification result.\",\n    \"Use Summarization API to summarize the classification result and save the summary.\",\n    \"Use Conversational API to generate a conversational response based on the summary.\",\n    \"Use Text Editing API to edit the input image based on the conversational response.\",\n    \"Use Object Detection API to detect objects in the edited image and save the detection results.\",\n    \"Use Sentence Similarity API to find the similarity between the conversational response and the summary.\",\n    \"Compare the similarity score with a threshold value. If the score is above the threshold, consider the task completed. Else, repeat the conversational response generation step with a different approach.\"\n  ],\n  \"task_nodes\": [\n    \"Text-to-Speech\",\n    \"Automatic Speech Recognition\",\n    \"Audio Classification\",\n    \"Summarization\",\n    \"Conversational\",\n    \"Text Editing\",\n    \"Object Detection\",\n    \"Sentence Similarity\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Text-to-Speech\", \"target\": \"Automatic Speech Recognition\"},\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \""
"```json\n{\n  \"task_steps\": [\n    \"Load image 'example.png' and perform OCR to extract text from table.\",\n    \"Perform Tabular Classification on the extracted text to identify and classify each column and row.\",\n    \"Summarize the content of the table by extracting key information and generating a concise summary.\",\n    \"Load image 'example.jpg' and perform Image Classification to understand the context of the second image.\",\n    \"Perform Text-to-Image or Text-to-Video generation to visually represent the summarized table content.\",\n    \"Perform Object Detection on the second image to identify and extract key objects or regions.\",\n    \"Analyze the relationship between the summarized table information and the identified objects or regions in the second image.\",\n    \"Generate a response to the user's question: 'What are the key information in the table?' based on the analysis.\"\n  ],\n  \"task_nodes\": [\n    \"Tabular Classification\",\n    \"Summarization\",\n    \"Image Classification\",\n    \"Text-to-Image or Text-to-Video Generation\",\n    \"Object Detection\",\n    \"Question Answering\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Loading and OCR\", \"target\": \"Tabular Classification\"},\n    {\"source\": \"Tabular Classification\", \"target\": \"Summarization\"},\n    {\"source\": \"Image Loading\", \"target\": \"Image Classification\"},\n    {\"source\": \"Image Classification\", \"target\": \"Object Detection\"},\n    {\"source\": \"Summarization\", \"target\": \"Question Answering\"}\n  ]\n}\n```\n\nNote: The \"Image Loading and OCR\" task is not explicitly mentioned"
"{\n  \"task_steps\": [\n    \"Load the image 'example.jpg' for analysis.\",\n    \"Perform image-to-label task to identify the main colors in the image.\",\n    \"Extract the identified colors as the short answer to the user's question.\",\n    \"Edit the image by changing the dominant color to blue using an image editing API.\",\n    \"Perform image-to-label task again to identify the main colors in the edited image.\",\n    \"Generate a text description of the edited image based on the identified colors.\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image Classification\",\n      \"input\": {\n        \"image_path\": \"example.jpg\"\n      },\n      \"output\": {\n        \"colors\": []\n      }\n    },\n    {\n      \"task_name\": \"Text Generation\",\n      \"input\": {\n        \"colors\": []\n      },\n      \"output\": {}\n    },\n    {\n      \"task_name\": \"Image Editing\",\n      \"input\": {\n        \"image_path\": \"example.jpg\",\n        \"dominant_color\": \"blue\"\n      },\n      \"output\": {}\n    },\n    {\n      \"task_name\": \"Image Classification\",\n      \"input\": {\n        \"image_path\": \"{edited_image_path}\"\n      },\n      \"output\": {\n        \"colors\": []\n      }\n    },\n    {\n      \"task_name\": \"Text Generation\",\n      \"input\": {\n        \"colors\": []\n      },\n      \"output\": {\n        \"text_description\": \"\"\n      }\n    }\n  ],\n  \"task_links\": [\n    {\"source\":"
"{\n  \"task_steps\": [\n    \"Load the image 'example.jpg' for analysis\",\n    \"Perform Image Classification to identify the image content\",\n    \"Extract the description 'The picture depicts an important milestone in the history of space exploration'\",\n    \"Perform Text-to-Speech to generate an audio file of the description\",\n    \"Perform Question Answering to determine the significance of the event in the image based on the description\"\n  ],\n  \"task_nodes\": [\n    \"Image Classification\",\n    \"Text-to-Speech\",\n    \"Question Answering\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification\", \"target\": \"Question Answering\"},\n    {\"source\": \"Text-to-Speech\", \"target\": \"Question Answering\"},\n    {\"source\": \"Question Answering\", \"target\": \"Output\"}\n  ]\n}\n\n# Explanation #:\n# The user request involves finding the answer to a question and generating an audio file of the answer.\n# To accomplish this, we will first perform Image Classification to identify the content of the image.\n# Next, we will extract the given description 'The picture depicts an important milestone in the history of space exploration'.\n# We will then use Text-to-Speech to generate an audio file of the description.\n# Finally, we will perform Question Answering to determine the significance of the event in the image based on the description.\n# The task steps and task nodes are aligned, and the task links reflect the dependencies among the tasks."
"```json\n{\n  \"task_steps\": [\n    \"Load 'example.jpg' image\",\n    \"Apply red color filter to the tree in the image\",\n    \"Save the modified image as 'red_tree.jpg'\",\n    \"Classify 'red_tree.jpg' image using Image Classification API\",\n    \"Store the classification result\",\n    \"Initiate a conversation with the following prompt: 'Look at this image. Can you describe what you see?'\",\n    \"Parse the user's response to identify the color of the tree\",\n    \"Generate text based on the conversation, including the identified color\",\n    \"Display the generated text to the user\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image Editing\",\n      \"input\": [\"example.jpg\"],\n      \"output\": [\"red_tree.jpg\"]\n    },\n    {\n      \"task_name\": \"Image Classification\",\n      \"input\": [\"red_tree.jpg\"]\n    },\n    {\n      \"task_name\": \"Question Answering\",\n      \"input\": [\"red_tree.jpg\", \"What color is the tree now?\"],\n      \"output\": [\"color_answer\"]\n    },\n    {\n      \"task_name\": \"Text Generation\",\n      \"input\": [\"color_answer\"],\n      \"output\": [\"generated_text\"]\n    },\n    {\n      \"task_name\": \"Conversational\",\n      \"input\": [\"red_tree.jpg\"],\n      \"output\": [\"user_response\"]\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Editing\", \"target\": \"Image Classification\"},\n    {\"source\": \"Image Classification\", \"target\": \""
"{\n    \"task_steps\": [\n        \"Load the image 'example.jpg' for further processing.\",\n        \"Perform image-to-text conversion to extract text data from the table image.\",\n        \"Perform tabular classification on the extracted text data to identify the table's structure and content.\",\n        \"Generate a conversational response based on the identified table content.\",\n        \"Identify the question 'What is the most common item in the table?' from the user's request.\",\n        \"Extract the answer to the question from the conversational response.\",\n        \"Perform text-to-speech conversion to generate an audible response in English.\",\n        \"Perform automatic speech recognition to transcribe the English response.\",\n        \"Perform text translation to convert the English text to French.\",\n        \"Output the translated text as the final response.\"\n    ],\n    \"task_nodes\": [\n        \"Image-to-Text\",\n        \"Tabular Classification\",\n        \"Conversational\",\n        \"Question Answering\",\n        \"Text-to-Speech\",\n        \"Automatic Speech Recognition\",\n        \"Text Translation\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Image-to-Text\", \"target\": \"Tabular Classification\"},\n        {\"source\": \"Tabular Classification\", \"target\": \"Conversational\"},\n        {\"source\": \"Conversational\", \"target\": \"Question Answering\"},\n        {\"source\": \"Question Answering\", \"target\": \"Text-to-Speech\"},\n        {\"source\": \"Text-to-Speech\", \"target\": \"Automatic Speech Recognition\"},\n        {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text Translation\"},\n        {\"source\":"
"```json\n{\n  \"task_steps\": [\n    \"Load the audio file 'example.wav' for Automatic Speech Recognition.\",\n    \"Perform Automatic Speech Recognition to extract the instructions from the audio file.\",\n    \"Load the image file 'example.jpg' for Object Detection.\",\n    \"Perform Object Detection on the image to identify the object mentioned in the instructions.\",\n    \"Output the object name and its location in the image.\"\n  ],\n  \"task_nodes\": [\n    \"Automatic Speech Recognition\",\n    \"Object Detection\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Object Detection\"}\n  ]\n}\n```"
"{\n  \"task_steps\": [\n    \"Load the input image and audio file.\",\n    \"Transcribe the audio file to text using Automatic Speech Recognition.\",\n    \"Parse the text to extract the image modification instructions.\",\n    \"Perform the image modification using Image Editing.\",\n    \"Load the modified image.\",\n    \"Perform Object Detection to identify the edited object in the image.\",\n    \"Extract the RGB values of the pixels in the identified object using Image Classification.\",\n    \"Determine the dominant color by analyzing the RGB values.\",\n    \"Generate the answer: 'The main color of the edited object in the image is [dominant color]'\"\n  ],\n  \"task_nodes\": [\n    \"Automatic Speech Recognition\",\n    \"Text Parsing\",\n    \"Image Editing\",\n    \"Image Classification\",\n    \"Object Detection\",\n    \"Color Analysis\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Load the input image and audio file.\", \"target\": \"Transcribe the audio file to text using Automatic Speech Recognition.\"},\n    {\"source\": \"Transcribe the audio file to text using Automatic Speech Recognition.\", \"target\": \"Parse the text to extract the image modification instructions.\"},\n    {\"source\": \"Parse the text to extract the image modification instructions.\", \"target\": \"Perform the image modification using Image Editing.\"},\n    {\"source\": \"Perform the image modification using Image Editing.\", \"target\": \"Load the modified image.\"},\n    {\"source\": \"Load the modified image.\", \"target\": \"Perform Object Detection to identify the edited object in the image.\"},\n    {\"source\": \"Perform Object Detection to identify the edited object in the image.\","
"```json\n{\n  \"task_steps\": [\n    \"Step 1: User uploads 'example.wav' to the Automatic Speech Recognition (ASR) API.\",\n    \"Step 2: ASR API transcribes the audio clip into text.\",\n    \"Step 3: Text-to-Emotion API analyzes the transcribed text and detects the user's emotion.\",\n    \"Step 4: Based on the detected emotion, Text-to-Image API generates an appropriate image.\",\n    \"Step 5: The generated image is returned to the user.\"\n  ],\n  \"task_nodes\": [\n    \"Automatic Speech Recognition\",\n    \"Text-to-Emotion\",\n    \"Text-to-Image\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text-to-Emotion\"},\n    {\"source\": \"Text-to-Emotion\", \"target\": \"Text-to-Image\"}\n  ]\n}\n```"
"{\n  \"task_steps\": [\n    \"Load 'example.wav' audio file\",\n    \"Perform Automatic Speech Recognition (ASR) on 'example.wav' to extract text\",\n    \"Perform Emotion Detection on the transcribed text from ASR\",\n    \"Perform Command Detection on the transcribed text from ASR\",\n    \"Load 'example.jpg' image file\",\n    \"Perform Object Detection on 'example.jpg' to identify subjects and objects\",\n    \"Perform Image-to-Text conversion to extract text from 'example.jpg'\",\n    \"Perform Text Similarity analysis between the text from image and reference text\",\n    \"Perform Text Summarization on the reference text and the results from text similarity analysis\",\n    \"Perform Translation of the summary text to the desired language\",\n    \"Perform Text-to-Speech conversion of the translated summary text\",\n    \"Load 'example.mp4' video file\",\n    \"Perform Text-to-Video conversion to create a video representation of the translated summary text\"\n  ],\n  \"task_nodes\": [\n    \"Automatic Speech Recognition\",\n    \"Emotion Detection\",\n    \"Command Detection\",\n    \"Object Detection\",\n    \"Image-to-Text conversion\",\n    \"Text Similarity analysis\",\n    \"Text Summarization\",\n    \"Translation\",\n    \"Text-to-Speech conversion\",\n    \"Text-to-Video conversion\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Load 'example.wav' audio file\", \"target\": \"Perform Automatic Speech Recognition\"},\n    {\"source\": \"Perform Automatic Speech Recognition\", \"target"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Perform image-to-text extraction to obtain text from the table image.\",\n            \"task_name\": \"Image-to-Text\"\n        },\n        {\n            \"step_description\": \"Perform text summarization to obtain a concise version of the extracted text.\",\n            \"task_name\": \"Text Summarization\"\n        },\n        {\n            \"step_description\": \"Identify the column 'A' in the summarized text.\",\n            \"task_name\": \"Question Answering\"\n        },\n        {\n            \"step_description\": \"Extract the values of column 'A' from the original text.\",\n            \"task_name\": \"Text Extraction\"\n        },\n        {\n            \"step_description\": \"Calculate the average value of the extracted values for column 'A'.\",\n            \"task_name\": \"Statistical Analysis\"\n        }\n    ],\n    \"task_nodes\": [\n        {\n            \"task_name\": \"Image-to-Text\"\n        },\n        {\n            \"task_name\": \"Text Summarization\"\n        },\n        {\n            \"task_name\": \"Question Answering\"\n        },\n        {\n            \"task_name\": \"Text Extraction\"\n        },\n        {\n            \"task_name\": \"Statistical Analysis\"\n        }\n    ],\n    \"task_links\": [\n        {\"source\": \"Image-to-Text\", \"target\": \"Text Summarization\"},\n        {\"source\": \"Text Summarization\", \"target\": \"Question Answering\"},\n        {\"source\": \"Question Answering\", \"target\": \"Text Extraction\"},\n       "
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Perform text summarization on the given input text.\",\n            \"task_name\": \"Summarization\"\n        },\n        {\n            \"step_description\": \"Edit the image 'example.jpg' to match the summarized description.\",\n            \"task_name\": \"Image-to-Text, Text-to-Image\"\n        },\n        {\n            \"step_description\": \"Perform object detection and segmentation on the edited image to identify and isolate the balls.\",\n            \"task_name\": \"Object Detection, Image Segmentation\"\n        },\n        {\n            \"step_description\": \"Estimate the depth of the objects in the edited image.\",\n            \"task_name\": \"Depth Estimation\"\n        },\n        {\n            \"step_description\": \"Determine which ball is closer to the viewer based on the depth estimation.\",\n            \"task_name\": \"Question Answering\"\n        },\n        {\n            \"step_description\": \"Compare the answer to the reference answer.\",\n            \"task_name\": \"Question Answering\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Summarization\",\n        \"Image-to-Text\",\n        \"Text-to-Image\",\n        \"Object Detection\",\n        \"Image Segmentation\",\n        \"Depth Estimation\",\n        \"Question Answering\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Summarization\", \"target\": \"Image-to-Text\"},\n        {\"source\": \"Image-to-Text\", \"target\": \"Text-to-Image\"},\n        {\"source\": \"Text-to-Image\", \"target\": \"Object Detection\"},"
"```json\n{\n  \"task_steps\": [\n    \"Load image 'example.jpg'\",\n    \"Perform image-to-text extraction on the image using OCR model for table recognition\",\n    \"Parse and clean the extracted text\",\n    \"Perform text summarization on the parsed and cleaned text using summarization model\",\n    \"Generate new text based on the summary using text generation model\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image-to-Text\"\n    },\n    {\n      \"task_name\": \"Text Parsing and Cleaning\"\n    },\n    {\n      \"task_name\": \"Text Summarization\"\n    },\n    {\n      \"task_name\": \"Text Generation\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Image-to-Text\", \"target\": \"Text Parsing and Cleaning\"},\n    {\"source\": \"Text Parsing and Cleaning\", \"target\": \"Text Summarization\"},\n    {\"source\": \"Text Summarization\", \"target\": \"Text Generation\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load the image 'example.jpg' and perform image preprocessing to enhance the table region.\",\n    \"Perform object detection on the image to identify and extract the table region.\",\n    \"Perform text extraction from the table region to obtain the raw text data.\",\n    \"Perform tabular classification on the extracted text data to identify the table columns and rows.\",\n    \"Generate a narrative summary of the table data using summarization techniques.\",\n    \"Convert the narrative summary to text-to-speech format to generate an audio summary.\"\n  ],\n  \"task_nodes\": [\n    \"Image Classification: Image-to-Tabular\",\n    \"Text Extraction: Image-to-Text\",\n    \"Tabular Classification: Tabular\",\n    \"Summarization: Text\",\n    \"Text-to-Speech: Text-to-Speech\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification: Image-to-Tabular\", \"target\": \"Text Extraction: Image-to-Text\"},\n    {\"source\": \"Text Extraction: Image-to-Text\", \"target\": \"Tabular Classification: Tabular\"},\n    {\"source\": \"Tabular Classification: Tabular\", \"target\": \"Summarization: Text\"},\n    {\"source\": \"Summarization: Text\", \"target\": \"Text-to-Speech: Text-to-Speech\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load 'example.wav' audio file\",\n    \"Transcribe the audio using Automatic Speech Recognition (ASR)\",\n    \"Summarize the transcribed text using Summarization\",\n    \"Generate conversational response related to the summary using Conversational\",\n    \"Load 'example.jpg' image file\",\n    \"Edit the image based on the conversational response using Image Editing\",\n    \"Extract text from the edited image using Text-to-Text or Optical Character Recognition (OCR)\"\n  ],\n  \"task_nodes\": [\n    \"Automatic Speech Recognition (ASR)\",\n    \"Summarization\",\n    \"Conversational\",\n    \"Image Editing\",\n    \"Text-to-Text or Optical Character Recognition (OCR)\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Automatic Speech Recognition (ASR)\", \"target\": \"Summarization\"},\n    {\"source\": \"Summarization\", \"target\": \"Conversational\"},\n    {\"source\": \"Conversational\", \"target\": \"Image Editing\"},\n    {\"source\": \"Image Editing\", \"target\": \"Text-to-Text or Optical Character Recognition (OCR)\"}\n  ]\n}\n```\n\nThis JSON format represents the task steps, task nodes, and task links required to fulfill the user's request. The user's request involves transcribing an audio file, summarizing the transcription, generating a conversational response related to the summary, editing the image based on the response, and extracting text from the edited image. The task steps are aligned with the task nodes, and the number of task steps is the same as the"
"```json\n{\n  \"task_steps\": [\n    \"Load the image 'example.jpg' and extract the table region using image segmentation.\",\n    \"Perform table classification on the extracted table region.\",\n    \"Based on the classification result, generate a corresponding image using text-to-image.\",\n    \"Detect objects within the generated image using object detection.\",\n    \"Translate the object labels into Spanish using translation.\"\n  ],\n  \"task_nodes\": [\n    \"Image Segmentation: Table Detection\",\n    \"Tabular Classification\",\n    \"Text-to-Image: Table Classification to Image\",\n    \"Object Detection\",\n    \"Translation: Object Labels to Spanish\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Segmentation: Table Detection\", \"target\": \"Tabular Classification\"},\n    {\"source\": \"Tabular Classification\", \"target\": \"Text-to-Image: Table Classification to Image\"},\n    {\"source\": \"Text-to-Image: Table Classification to Image\", \"target\": \"Object Detection\"},\n    {\"source\": \"Object Detection\", \"target\": \"Translation: Object Labels to Spanish\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load example.jpg image\",\n    \"Perform table classification on example.jpg using Tabular Classification\",\n    \"Extract content from classified table using Text Extraction\",\n    \"Generate new image based on extracted content using Text-to-Image\",\n    \"Perform depth estimation on new image using Depth Estimation\",\n    \"Determine most significant object from depth estimation using Object Detection and Question Answering\",\n    \"Modify background of original image based on most significant object using Image Editing\",\n    \"Answer question 'What changes were made?' using Text Generation and Document Question Answering\",\n    \"Initiate conversation about the process using Conversational\"\n  ],\n  \"task_nodes\": [\n    \"Tabular Classification\",\n    \"Text Extraction\",\n    \"Text-to-Image\",\n    \"Depth Estimation\",\n    \"Object Detection\",\n    \"Question Answering\",\n    \"Image Editing\",\n    \"Text Generation\",\n    \"Document Question Answering\",\n    \"Conversational\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification\", \"target\": \"Tabular Classification\"},\n    {\"source\": \"Tabular Classification\", \"target\": \"Text Extraction\"},\n    {\"source\": \"Text Extraction\", \"target\": \"Text-to-Image\"},\n    {\"source\": \"Text-to-Image\", \"target\": \"Depth Estimation\"},\n    {\"source\": \"Depth Estimation\", \"target\": \"Object Detection\"},\n    {\"source\": \"Object Detection\", \"target\": \"Question Answering\"},\n    {\"source\": \"Question Answering\", \"target\": \"Image Editing\"},\n    {\"source"
"```json\n{\n  \"task_steps\": [\n    \"Load document image 'example.jpg'\",\n    \"Perform Optical Character Recognition (OCR) on the document image to extract text data\",\n    \"Perform Text-based Information Extraction to identify event location, date, and organizer from the extracted text\",\n    \"Perform Text Translation from English to French using a translation API\",\n    \"Perform Text-based Information Extraction again to identify specific entities (locations, dates, and organizers) in the translated text\",\n    \"Perform Text-to-Speech to convert recognized entities into speech\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Text-based Information Extraction\",\n      \"input\": \"Document image with extracted text data\",\n      \"output\": \"Identified event location, date, and organizer\"\n    },\n    {\n      \"task_name\": \"Text Translation\",\n      \"input\": \"Identified event location, date, and organizer in English\",\n      \"output\": \"Identified event location, date, and organizer in French\"\n    },\n    {\n      \"task_name\": \"Text-based Information Extraction\",\n      \"input\": \"Identified event location, date, and organizer in French\",\n      \"output\": \"Identified entities (locations, dates, and organizers) in French text\"\n    },\n    {\n      \"task_name\": \"Text-to-Speech\",\n      \"input\": \"Identified entities (locations, dates, and organizers) in French text\",\n      \"output\": \"Speech output of recognized entities\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Text"
"```json\n{\n  \"task_steps\": [\n    \"Load the audio file 'example.wav'\",\n    \"Perform audio-to-text transcription on the audio file using Automatic Speech Recognition\",\n    \"Parse the transcription output to extract instructions for image editing\",\n    \"Perform image editing on the image 'example.jpg' using Image Editing\",\n    \"Load the edited image\",\n    \"Perform Object Detection on the edited image to identify objects and their locations\",\n    \"Extract the primary object's location from the Object Detection output\",\n    \"Crop the image to include only the primary object\",\n    \"Perform Image Classification on the cropped image to determine the object type\",\n    \"Perform Color Detection on the cropped image to determine the object color\",\n    \"Translate the type and color of the primary object into French using Text-to-Speech and Text-to-Translation\"\n  ],\n  \"task_nodes\": [\n    \"Automatic Speech Recognition\",\n    \"Image Editing\",\n    \"Object Detection\",\n    \"Image Classification\",\n    \"Color Detection\",\n    \"Text-to-Speech\",\n    \"Text-to-Translation\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Load the audio file 'example.wav'\", \"target\": \"Perform audio-to-text transcription on the audio file using Automatic Speech Recognition\"},\n    {\"source\": \"Perform audio-to-text transcription on the audio file using Automatic Speech Recognition\", \"target\": \"Parse the transcription output to extract instructions for image editing\"},\n    {\"source\": \"Parse the transcription output to extract instructions for image editing\", \"target\": \"Per"
"```json\n{\n  \"task_steps\": [\n    \"Load the Spanish image 'example.jpg'\",\n    \"Perform Optical Character Recognition (OCR) to extract text from the image\",\n    \"Perform Text-to-Language translation from Spanish to English\",\n    \"Perform Text Summarization to identify the main topic discussed in the document\",\n    \"Perform Text-to-Speech conversion to generate an audio file in English\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image-to-Text\"\n    },\n    {\n      \"task_name\": \"Translation\"\n    },\n    {\n      \"task_name\": \"Summarization\"\n    },\n    {\n      \"task_name\": \"Text-to-Speech\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Image-to-Text\", \"target\": \"Translation\"},\n    {\"source\": \"Translation\", \"target\": \"Summarization\"},\n    {\"source\": \"Summarization\", \"target\": \"Text-to-Speech\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Read and understand the user's text: 'In the tranquil valley, a proud lion lays beside a graceful deer and a wise owl perches on a majestic tree'.\",\n    \"Perform text-to-image generation to create an image based on the user's text.\",\n    \"Perform text-to-speech to read out the user's text for better understanding and imagery.\",\n    \"Perform image-to-text to extract labels for each element in the image.\",\n    \"Perform text summarization to create a brief description of the image.\",\n    \"Perform image segmentation to label and separate different elements in the image.\",\n    \"Perform object detection to identify and label the animals (lion, deer) and other objects (majestic tree) in the image.\",\n    \"Perform image classification to classify the overall image based on its content.\",\n    \"Perform text-to-video to create a short video of the text-to-image generation process.\",\n    \"Perform visual question answering to answer any questions related to the image and its labels.\"\n  ],\n  \"task_nodes\": [\n    \"Text-to-Image\",\n    \"Text-to-Speech\",\n    \"Image-to-Text\",\n    \"Text Summarization\",\n    \"Image Segmentation\",\n    \"Object Detection\",\n    \"Image Classification\",\n    \"Text-to-Video\",\n    \"Visual Question Answering\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Text-to-Image\", \"target\": \"Image-to-Text\"},\n    {\"source\": \"Text-to-Image\", \"target\": \"Text-to-Speech\"},\n"
"```json\n{\n  \"task_steps\": [\n    \"Read the text file 'animal_facts.txt' to extract facts about different animals.\",\n    \"Search for the fact related to 'giraffes' in the extracted data.\",\n    \"Generate an image of a 'giraffe' using an Image-to-Text model.\",\n    \"Use an Image Classification model to confirm the generated image is of a 'giraffe'.\",\n    \"Once the image is confirmed as a 'giraffe', extract the fact about giraffes from the text data.\",\n    \"Generate a video based on the extracted fact about giraffes using a Text-to-Video model.\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Text Reading\"\n    },\n    {\n      \"task_name\": \"Fact Extraction\"\n    },\n    {\n      \"task_name\": \"Image Generation\"\n    },\n    {\n      \"task_name\": \"Image Classification\"\n    },\n    {\n      \"task_name\": \"Fact Verification\"\n    },\n    {\n      \"task_name\": \"Video Generation\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Text Reading\", \"target\": \"Fact Extraction\"},\n    {\"source\": \"Fact Extraction\", \"target\": \"Image Generation\"},\n    {\"source\": \"Image Generation\", \"target\": \"Image Classification\"},\n    {\"source\": \"Image Classification\", \"target\": \"Fact Verification\"},\n    {\"source\": \"Fact Verification\", \"target\": \"Video Generation\"}\n  ]\n}\n```"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Load the text document 'example.txt' and perform text summarization using Text Summarization task.\"\n        },\n        {\n            \"step_description\": \"Save the summarized text as 'summarized_text.txt' for further use.\"\n        },\n        {\n            \"step_description\": \"Invoke Text-to-Image task to generate an image based on the summarized text.\"\n        },\n        {\n            \"step_description\": \"Save the generated image as 'summary_image.jpg' for further use.\"\n        },\n        {\n            \"step_description\": \"Invoke Question Answering task to determine the main topic from the original text document.\"\n        },\n        {\n            \"step_description\": \"Save the answer as 'main_topic.txt' for further use.\"\n        }\n    ],\n    \"task_nodes\": [\n        {\n            \"task_name\": \"Text Summarization\"\n        },\n        {\n            \"task_name\": \"Question Answering\"\n        }\n    ],\n    \"task_links\": [\n        {\n            \"source\": \"Text Summarization\",\n            \"target\": \"Question Answering\"\n        }\n    ]\n}\n\n# Explanation #\nThe user request involves summarizing a text document, generating an image from the summarized content, and answering a question about the main topic. To fulfill this request, we will perform the following tasks in sequence:\n\n1. Text Summarization: This task will be used to summarize the content of the text document.\n2. Save summarized text: The summarized text will be saved as 'summarized_text.txt' for further use.\n3. Text-"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Load and preprocess the audio file 'example.wav' for audio enhancement.\"\n        },\n        {\n            \"step_description\": \"Invoke 'Automatic Speech Recognition' task node to transcribe the audio content.\"\n        },\n        {\n            \"step_description\": \"Invoke 'Audio Classification' task node to classify the audio content and determine the emotion of the speaker.\"\n        },\n        {\n            \"step_description\": \"Invoke 'Text-to-Speech' task node to generate enhanced audio based on the transcribed text and the detected emotion.\"\n        },\n        {\n            \"step_description\": \"Load and preprocess the image file 'example.jpg' for facial expression modification.\"\n        },\n        {\n            \"step_description\": \"Invoke 'Emotion Detection' task node to analyze the emotion of the person in the image.\"\n        },\n        {\n            \"step_description\": \"Invoke 'Image-to-Text' task node to generate a textual description of the person's facial expression based on the detected emotion.\"\n        },\n        {\n            \"step_description\": \"Invoke 'Text-to-Image' task node to modify the person's facial expression in the image to match the detected emotion.\"\n        },\n        {\n            \"step_description\": \"Save and output the enhanced audio and modified image.\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Automatic Speech Recognition\",\n        \"Audio Classification\",\n        \"Text-to-Speech\",\n        \"Emotion Detection\",\n        \"Image-to-Text\",\n        \"Text-to-Image\"\n    ],\n    \"task_links\": [\n       "
"{\n  \"task_steps\": [\n    \"Load the image 'example.jpg' using an Image-to-Process API\",\n    \"Perform Image Preprocessing to enhance document readability using an Image Editing API\",\n    \"Perform Image Segmentation to separate text regions from background using an Image Segmentation API\",\n    \"Perform Depth Estimation to analyze the depth of objects within the image using a Depth Estimation API\",\n    \"Extract text from the segmented regions using an Optical Character Recognition (OCR) API\",\n    \"Perform Text Preprocessing to clean and normalize the extracted text\",\n    \"Perform Text Summarization to extract the main topics from the document text using a Summarization API\",\n    \"Return the main topic as the answer to the user's question\"\n  ],\n  \"task_nodes\": [\n    \"Image-to-Process\",\n    \"Image Editing\",\n    \"Image Segmentation\",\n    \"Depth Estimation\",\n    \"Optical Character Recognition (OCR)\",\n    \"Text Preprocessing\",\n    \"Summarization\",\n    \"Question Answering\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image-to-Process\", \"target\": \"Image Editing\"},\n    {\"source\": \"Image Editing\", \"target\": \"Image Segmentation\"},\n    {\"source\": \"Image Segmentation\", \"target\": \"Depth Estimation\"},\n    {\"source\": \"Depth Estimation\", \"target\": \"Optical Character Recognition (OCR)\"},\n    {\"source\": \"Optical Character Recognition (OCR)\", \"target\": \"Text Preprocessing\"},\n    {\"source\": \"Text Preprocessing\", \"target\": \"Summarization\"},\n    {\"source\": \""
"{\n  \"task_steps\": [\n    \"Load 'example.wav' audio file\",\n    \"Apply audio enhancement techniques to improve audio quality\",\n    \"Separate individual speakers using Speaker Diarization\",\n    \"Transcribe enhanced audio to text using Automatic Speech Recognition\",\n    \"Save enhanced audio and transcribed text to separate files\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Audio Editing\",\n      \"task_description\": \"Apply audio enhancement techniques to improve audio quality\"\n    },\n    {\n      \"task_name\": \"Speaker Diarization\",\n      \"task_description\": \"Separate individual speakers in the enhanced audio\"\n    },\n    {\n      \"task_name\": \"Automatic Speech Recognition\",\n      \"task_description\": \"Transcribe the enhanced audio to text\"\n    },\n    {\n      \"task_name\": \"Text-to-File\",\n      \"task_description\": \"Save transcribed text to a file\"\n    },\n    {\n      \"task_name\": \"Audio-to-File\",\n      \"task_description\": \"Save enhanced audio to a file\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Audio Editing\", \"target\": \"Speaker Diarization\"},\n    {\"source\": \"Speaker Diarization\", \"target\": \"Automatic Speech Recognition\"},\n    {\"source\": \"Audio Editing\", \"target\": \"Audio-to-File\"},\n    {\"source\": \"Speaker Diarization\", \"target\": \"Audio-to-File\"},\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text-to-File\"}\n  ]"
"{\n  \"task_steps\": [\n    \"Load the image 'example.jpg' for further processing.\",\n    \"Perform Object Detection on the loaded image to identify the table and its boundaries.\",\n    \"Extract the table from the image using Image Segmentation.\",\n    \"Perform Image-to-Text conversion to extract the textual information from the table.\",\n    \"Perform Text Preprocessing to clean and format the extracted text.\",\n    \"Perform Tabular Classification to identify the columns and their corresponding product attributes and ratings.\",\n    \"Identify the column indexes for product type and rating.\",\n    \"Extract the product type and rating values for the product with the highest rating.\",\n    \"Change the background color of the table image to red using Image Editing.\",\n    \"Perform Text-to-Speech to verbally communicate the product type with the highest rating.\",\n    \"Perform Country Detection on the extracted text to identify the country of origin.\"\n  ],\n  \"task_nodes\": [\n    \"Object Detection\",\n    \"Image Segmentation\",\n    \"Text-to-Text\",\n    \"Text Preprocessing\",\n    \"Tabular Classification\",\n    \"Image Editing\",\n    \"Text-to-Speech\",\n    \"Country Detection\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Load Image\", \"target\": \"Object Detection\"},\n    {\"source\": \"Object Detection\", \"target\": \"Image Segmentation\"},\n    {\"source\": \"Image Segmentation\", \"target\": \"Text-to-Text\"},\n    {\"source\": \"Text-to-Text\", \"target\": \"Text Preprocessing\"},\n    {\"source\": \"Text Preprocessing\", \"target\": \"Tabular Classification\"},\n    {\"source\": \"Tabular Class"
"```json\n{\n  \"task_steps\": [\n    \"Load the image 'example.jpg'\",\n    \"Perform Image Classification to identify objects in the image\",\n    \"Perform Object Detection to locate and identify specific instances of objects in the image\",\n    \"Perform Depth Estimation to estimate the depth of each object in the image\",\n    \"Perform Image Segmentation based on depth estimates to separate objects from the background\",\n    \"Answer the question: 'Which object is closest to the camera?' by identifying the object with the shallowest depth estimate\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image Classification\"\n    },\n    {\n      \"task_name\": \"Object Detection\"\n    },\n    {\n      \"task_name\": \"Depth Estimation\"\n    },\n    {\n      \"task_name\": \"Image Segmentation\"\n    },\n    {\n      \"task_name\": \"Question Answering\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification\", \"target\": \"Object Detection\"},\n    {\"source\": \"Object Detection\", \"target\": \"Depth Estimation\"},\n    {\"source\": \"Depth Estimation\", \"target\": \"Image Segmentation\"},\n    {\"source\": \"Image Segmentation\", \"target\": \"Question Answering\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    {\n      \"step_description\": \"Load the image 'example.jpg' for image processing.\"\n    },\n    {\n      \"step_description\": \"Apply night-time scene transformation to the image.\"\n    },\n    {\n      \"step_description\": \"Detect and segment buildings in the transformed image.\"\n    },\n    {\n      \"step_description\": \"Change the color of the detected buildings to blue.\"\n    },\n    {\n      \"step_description\": \"Extract table data from the image using tabular classification.\"\n    },\n    {\n      \"step_description\": \"Generate a conversational response about the table's content.\"\n    },\n    {\n      \"step_description\": \"Create a video from the conversational response.\"\n    }\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image Classification\",\n      \"input\": \"example.jpg\",\n      \"output\": \"transformed_example.jpg\"\n    },\n    {\n      \"task_name\": \"Image Segmentation\",\n      \"input\": \"transformed_example.jpg\",\n      \"output\": \"segmented_example.jpg\"\n    },\n    {\n      \"task_name\": \"Object Detection\",\n      \"input\": \"segmented_example.jpg\",\n      \"output\": \"buildings_example.jpg\"\n    },\n    {\n      \"task_name\": \"Image Editing\",\n      \"input\": \"buildings_example.jpg\",\n      \"output\": \"blue_buildings_example.jpg\"\n    },\n    {\n      \"task_name\": \"Tabular Classification\",\n      \"input\": \"blue_buildings_example"
"```json\n{\n  \"task_steps\": [\n    \"Load the image 'example.jpg' for image processing.\",\n    \"Perform object detection on the loaded image to identify the object present.\",\n    \"Extract the identified object name from the output of object detection.\",\n    \"Invoke Text-to-Speech API to generate an audio clip describing the identified object in English.\",\n    \"Record the generated audio clip.\",\n    \"Invoke Automatic Speech Recognition API to transcribe the recorded audio clip back into text.\",\n    \"Invoke Machine Translation API to translate the transcribed text into Spanish.\"\n  ],\n  \"task_nodes\": [\n    \"Image Classification or Object Detection\",\n    \"Text-to-Speech\",\n    \"Automatic Speech Recognition\",\n    \"Machine Translation\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification or Object Detection\", \"target\": \"Text-to-Speech\"},\n    {\"source\": \"Text-to-Speech\", \"target\": \"Automatic Speech Recognition\"},\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Machine Translation\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load 'example.jpg' image and extract tabular content using Image-to-Text task.\",\n    \"Classify the tabular content using Tabular Classification task.\",\n    \"Estimate the depth of objects in the image using Depth Estimation task.\",\n    \"Create a text representation of the classified tabular content.\",\n    \"Generate a video representation of the classified tabular content using Text-to-Video task.\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image-to-Text\"\n    },\n    {\n      \"task_name\": \"Tabular Classification\"\n    },\n    {\n      \"task_name\": \"Depth Estimation\"\n    },\n    {\n      \"task_name\": \"Text-to-Video\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Image-to-Text\", \"target\": \"Tabular Classification\"},\n    {\"source\": \"Tabular Classification\", \"target\": \"Depth Estimation\"},\n    {\"source\": \"Tabular Classification\", \"target\": \"Text-to-Video\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load the example.jpg image\",\n    \"Perform image-to-text extraction to get text from the image\",\n    \"Save the extracted text for future use\",\n    \"Perform object detection on the example.jpg image to identify the object to be inverted\",\n    \"Extract the bounding box coordinates of the identified object\",\n    \"Modify the color of the object by inverting it using image editing\",\n    \"Save the edited image with the inverted object\",\n    \"Perform image segmentation to divide the edited image into segments\",\n    \"Save each segment as a separate image\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Text-to-Image\"\n    },\n    {\n      \"task_name\": \"Object Detection\"\n    },\n    {\n      \"task_name\": \"Image Editing\"\n    },\n    {\n      \"task_name\": \"Image Segmentation\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Text-to-Image\", \"target\": \"Object Detection\"},\n    {\"source\": \"Object Detection\", \"target\": \"Image Editing\"},\n    {\"source\": \"Image Editing\", \"target\": \"Image Segmentation\"}\n  ]\n}\n```\n\nThis JSON format represents the task steps, task nodes, and task links required to extract text from an image, modify the image by inverting color of an identified object, and divide the edited image into segments. The task nodes are \"Text-to-Image\", \"Object Detection\", and \"Image Segmentation\", and the task steps are aligned with the tasks in the order they should be executed. The task links reflect the"
"{\n  \"task_steps\": [\n    \"Load image 'example.jpg' and perform preprocessing for table extraction.\",\n    \"Perform Object Detection to locate table region in the image.\",\n    \"Perform Tabular Classification to classify the table data.\",\n    \"Perform Depth Estimation to estimate depth of the table and its surroundings.\",\n    \"Convert the tabular classification result into text format.\",\n    \"Perform Text-to-Speech to convert the text into an audio format.\",\n    \"Apply audio processing to the audio output.\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image Classification\",\n      \"task_description\": \"Perform Object Detection to locate table region in the image.\"\n    },\n    {\n      \"task_name\": \"Tabular Classification\",\n      \"task_description\": \"Classify the table data.\"\n    },\n    {\n      \"task_name\": \"Depth Estimation\",\n      \"task_description\": \"Estimate depth of the table and its surroundings.\"\n    },\n    {\n      \"task_name\": \"Text-to-Speech\",\n      \"task_description\": \"Convert the text into an audio format.\"\n    },\n    {\n      \"task_name\": \"Text Preprocessing\",\n      \"task_description\": \"Convert the tabular classification result into text format.\"\n    },\n    {\n      \"task_name\": \"Audio Processing\",\n      \"task_description\": \"Apply audio processing to the audio output.\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification\", \"target\": \"Tabular Classification\"},\n    {\"source\": \"Tabular Classification\", \"target\": \"Text Preprocessing\"},\n   "
"```json\n{\n  \"task_steps\": [\n    \"Load the example.jpg image into memory.\",\n    \"Perform object detection on the image to identify all objects present.\",\n    \"Filter the detected objects to identify red cars.\",\n    \"Count the number of red cars identified.\",\n    \"Generate a natural sounding speech audio file with the answer using Text-to-Speech.\",\n    \"Enhance the audio quality using Audio Editing.\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image Classification\",\n      \"task_description\": \"Perform object detection on the image to identify all objects present.\"\n    },\n    {\n      \"task_name\": \"Tabular Classification\",\n      \"task_description\": \"Filter the detected objects to identify red cars.\"\n    },\n    {\n      \"task_name\": \"Text-to-Speech\",\n      \"task_description\": \"Generate a natural sounding speech audio file with the answer.\"\n    },\n    {\n      \"task_name\": \"Audio Editing\",\n      \"task_description\": \"Enhance the audio quality.\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification\", \"target\": \"Tabular Classification\"},\n    {\"source\": \"Tabular Classification\", \"target\": \"Text-to-Speech\"},\n    {\"source\": \"Text-to-Speech\", \"target\": \"Audio Editing\"}\n  ]\n}\n```"
"{\"task_steps\": [\n\"Read and understand the given text input: 'A dog is happily playing with a ball near a tree in a sunny park'.\",\n\"Perform text summarization to extract the key elements of the scene.\",\n\"Generate a summarized description based on the key elements.\",\n\"Output the final summarized description.\"\n],\n\"task_nodes\": [\n\"Text Summarization\",\n\"Text Generation\"\n],\n\"task_links\": [\n{\"source\": \"Text Summarization\", \"target\": \"Text Generation\"}\n]\n}\n\n\"Final summarized description\": A dog plays happily with a ball near a tree in a sunny park."
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Perform image classification to identify the main object or scene in the image.\",\n            \"task_name\": \"Image Classification\"\n        },\n        {\n            \"step_description\": \"Use object detection to identify and locate specific objects within the image.\",\n            \"task_name\": \"Object Detection\"\n        },\n        {\n            \"step_description\": \"Generate a summary or description of the image based on the identified objects.\",\n            \"task_name\": \"Text Generation\"\n        },\n        {\n            \"step_description\": \"Initiate a conversational model to discuss the image and its identified objects.\",\n            \"task_name\": \"Conversational\"\n        },\n        {\n            \"step_description\": \"Transcribe the conversational text into written format.\",\n            \"task_name\": \"Text-to-Speech\"\n            \"Text-to-Text\":\n            {\n                \"source\": \"Conversational\",\n                \"target\": \"Text\"\n            }\n        }\n    ],\n    \"task_nodes\": [\n        \"Image Classification\",\n        \"Object Detection\",\n        \"Text Generation\",\n        \"Conversational\",\n        \"Text-to-Speech\"\n    ],\n    \"task_links\": [\n        {\n            \"source\": \"Image Classification\",\n            \"target\": \"Object Detection\"\n        },\n        {\n            \"source\": \"Object Detection\",\n            \"target\": \"Text Generation\"\n        },\n        {\n            \"source\": \"Text Generation\",\n            \"target\": \"Conversational\"\n        },\n        {\n            \"source\": \"Conversational\",\n            \"target\": \"Text-"
"```json\n{\n  \"task_steps\": [\n    \"Load image 'example.jpg' for object detection.\",\n    \"Invoke Image Classification API to identify the room type from the image.\",\n    \"Invoke Object Detection API to identify and label the furniture objects in the room.\",\n    \"Invoke Text-to-Speech API to read out the identified furniture objects.\",\n    \"Invoke Question Answering API to answer the question 'What furniture is in the room?' based on the identified furniture objects.\",\n    \"Invoke Text Generation API to generate a summary of the answer.\",\n    \"Invoke Text-to-Video API to generate a video with the summary of the answer.\",\n    \"Save the generated video with a name 'room_summary.mp4'\"\n  ],\n  \"task_nodes\": [\n    \"Image Classification\",\n    \"Object Detection\",\n    \"Question Answering\",\n    \"Text-to-Speech\",\n    \"Text Generation\",\n    \"Text-to-Video\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification\", \"target\": \"Object Detection\"},\n    {\"source\": \"Object Detection\", \"target\": \"Question Answering\"},\n    {\"source\": \"Question Answering\", \"target\": \"Text-to-Speech\"},\n    {\"source\": \"Text-to-Speech\", \"target\": \"Text Generation\"},\n    {\"source\": \"Text Generation\", \"target\": \"Text-to-Video\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load the audio file 'example.wav'\",\n    \"Perform Automatic Speech Recognition (ASR) to extract text from the audio file\",\n    \"Use Text-to-Question Answering model to extract the question 'When will the event take place?' from the extracted text\",\n    \"Use Date Extraction model to extract the date information from the text\",\n    \"Return the extracted date as the answer\"\n  ],\n  \"task_nodes\": [\n    \"Automatic Speech Recognition\",\n    \"Text-to-Question Answering\",\n    \"Date Extraction\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text-to-Question Answering\"},\n    {\"source\": \"Text-to-Question Answering\", \"target\": \"Date Extraction\"}\n  ]\n}\n```"
"{\n  \"task_steps\": [\n    \"Load the image 'example.jpg' using Image-to-Memory API\",\n    \"Perform Object Detection on the loaded image using Object Detection API\",\n    \"For each apple object detected, change its color to red using Image Editing API\",\n    \"For each banana object detected, change its color to yellow using Image Editing API\",\n    \"Save the edited image using Image-to-Memory to 'edited_example.jpg'\",\n    \"Load the saved edited image 'edited_example.jpg' using Image-to-Memory API\",\n    \"Perform Depth Estimation on the loaded image using Depth Estimation API\",\n    \"Save the depth estimation result as 'depth_edited_example.jpg'\"\n  ],\n  \"task_nodes\": [\n    \"Image-to-Memory (Load 'example.jpg')\",\n    \"Object Detection\",\n    \"Image Editing (Change color of apples to red)\",\n    \"Image Editing (Change color of bananas to yellow)\",\n    \"Image-to-Memory (Save edited image as 'edited_example.jpg')\",\n    \"Depth Estimation\",\n    \"Image-to-Memory (Load saved edited image 'edited_example.jpg')\",\n    \"Save Depth Estimation result as 'depth_edited_example.jpg'\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image-to-Memory (Load 'example.jpg')\", \"target\": \"Object Detection\"},\n    {\"source\": \"Object Detection\", \"target\": \"Image Editing (Change color of apples to red)\"},\n    {\"source\": \"Object Detection\", \"target\": \"Image Editing (Change color of bananas to yellow)\"},\n"
"{\n    \"task_steps\": [\n        \"Step 1: Text-to-Image: Generate an image based on the given text description 'A beautiful landscape with mountains, river, and trees'.\",\n        \"Step 2: Image Classification: Classify the generated image to ensure it matches the given text description.\",\n        \"Step 3: Image Segmentation: Segment the image into different objects (mountains, river, trees) for further processing.\",\n        \"Step 4: Depth Estimation: Estimate the depth of objects in the image using Computer Vision techniques.\",\n        \"Step 5: Object Detection: Identify the most prominent object (e.g., mountain, river, or tree) in the image based on its size and visual importance.\",\n        \"Step 6: Text-to-Speech: Convert the summarized answer into spoken language for easier understanding.\",\n        \"Step 7: Summarization: Generate a summarized answer to the question 'What is the most prominent feature in the image?' based on the identified object.\",\n        \"Step 8: Question Answering: Answer the question 'What is the most prominent feature in the image?' using the summarized answer.\"\n    ],\n    \"task_nodes\": [\n        \"Text-to-Image\",\n        \"Image Classification\",\n        \"Image Segmentation\",\n        \"Depth Estimation\",\n        \"Object Detection\",\n        \"Question Answering\",\n        \"Text-to-Speech\",\n        \"Summarization\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Text-to-Image\", \"target\": \"Image Classification\"},\n        {\"source\": \"Image Classification\", \"target\": \"Image Segmentation\"},\n        {\"source\": \"Image Segmentation\", \"target\": \"Depth"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Tokenize the input text 'I love nature' into words and convert each word into its corresponding text representation in a list.\"\n        },\n        {\n            \"step_description\": \"Perform Text-to-Speech (TTS) conversion on the list of words to generate an audio file.\"\n        },\n        {\n            \"step_description\": \"Save the generated audio file for further processing.\"\n        },\n        {\n            \"step_description\": \"Perform Automatic Speech Recognition (ASR) on the saved audio file to extract text from the audio.\"\n        },\n        {\n            \"step_description\": \"Perform Text Classification on the extracted text to determine the audio's content category.\"\n        },\n        {\n            \"step_description\": \"Based on the audio classification result, select an appropriate Image-to-Text model to generate a text description of an image.\"\n        },\n        {\n            \"step_description\": \"Perform Text-to-Image conversion on the text description to generate an image.\"\n        },\n        {\n            \"step_description\": \"Save the generated image for the final output.\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Text-to-Speech\",\n        \"Automatic Speech Recognition\",\n        \"Text Classification\",\n        \"Image-to-Text\",\n        \"Text-to-Image\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Text-to-Speech\", \"target\": \"Automatic Speech Recognition\"},\n        {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text Classification\"},\n        {\"source\": \"Text Classification\", \"target"
"{\n  \"task_steps\": [\n    \"Load the Spanish audio file 'example.wav'\",\n    \"Perform Automatic Speech Recognition (ASR) on the Spanish audio file to extract text\",\n    \"Perform Spanish to English Translation on the extracted text\",\n    \"Save the translated text as 'translated_text.txt'\",\n    \"Load the question: 'What is the main topic of the translated text?'\",\n    \"Perform Question Answering on the translated text to extract the main topic\",\n    \"Save the main topic as 'main_topic.txt'\",\n    \"Load the document image 'example.jpg'\",\n    \"Perform Text-to-Image or Optical Character Recognition (OCR) on the document image to extract text\",\n    \"Load the main topic from 'main_topic.txt'\",\n    \"Perform Document Question Answering on the extracted text to find information related to the main topic\"\n  ],\n  \"task_nodes\": [\n    \"Automatic Speech Recognition\",\n    \"Spanish to English Translation\",\n    \"Question Answering\",\n    \"Text-to-Image or Optical Character Recognition\",\n    \"Document Question Answering\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Load the Spanish audio file 'example.wav'\", \"target\": \"Perform Automatic Speech Recognition\"},\n    {\"source\": \"Perform Automatic Speech Recognition\", \"target\": \"Perform Spanish to English Translation\"},\n    {\"source\": \"Perform Spanish to English Translation\", \"target\": \"Save the translated text as 'translated_text.txt'\"},\n    {\"source\": \"Load the question: 'What is the main topic of the translated text?'\","
"```json\n{\n  \"task_steps\": [\n    \"Load the example.jpg image into the memory.\",\n    \"Perform image preprocessing to prepare the image for further analysis.\",\n    \"Apply image segmentation to identify individual objects in the image.\",\n    \"Estimate the depth of each object in the image using depth estimation.\",\n    \"Determine the closest object to the camera based on the depth estimation results.\",\n    \"Generate text description about the closest object using text generation.\",\n    \"Analyze the text description to extract relevant information about the closest object.\"\n  ],\n  \"task_nodes\": [\n    \"Image Segmentation\",\n    \"Depth Estimation\",\n    \"Text Generation\",\n    \"Text Analysis\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification\", \"target\": \"Image Segmentation\"},\n    {\"source\": \"Image Segmentation\", \"target\": \"Depth Estimation\"},\n    {\"source\": \"Depth Estimation\", \"target\": \"Text Generation\"},\n    {\"source\": \"Text Generation\", \"target\": \"Text Analysis\"}\n  ]\n}\n```\n\nNote: I assumed \"Image Classification\" as a prerequisite step to \"Image Segmentation\" based on the given user request, but it is not explicitly mentioned in the task list. If \"Image Classification\" is not required, then the task steps and task links should be adjusted accordingly."
"```json\n{\n  \"task_steps\": [\n    \"Load the audio file 'example.wav' for speech recognition.\",\n    \"Perform automatic speech recognition on the audio file to extract the user's instructions.\",\n    \"Load the image file 'example.jpg' for image processing.\",\n    \"Perform image segmentation on the image to identify and separate the objects.\",\n    \"Perform object detection on the segmented image to identify the objects and their locations.\",\n    \"Apply the user's instructions to modify the detected objects in the image.\",\n    \"Create a new image 'example_modified.jpg' with the modified objects.\",\n    \"Create a new video 'example.mp4' by combining the original image 'example.jpg' and the modified image 'example_modified.jpg'\",\n    \"Save the video 'example.mp4'\"\n  ],\n  \"task_nodes\": [\n    \"Automatic Speech Recognition\",\n    \"Image Segmentation\",\n    \"Object Detection\",\n    \"Text-to-Image\",\n    \"Image Processing\",\n    \"Video Creation\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Image Segmentation\"},\n    {\"source\": \"Image Segmentation\", \"target\": \"Object Detection\"},\n    {\"source\": \"Object Detection\", \"target\": \"Text-to-Image\"},\n    {\"source\": \"Text-to-Image\", \"target\": \"Image Processing\"},\n    {\"source\": \"Image Processing\", \"target\": \"Video Creation\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load the image 'example.jpg'\",\n    \"Perform image segmentation to identify and extract individual segments from the image\",\n    \"For each segment, perform object detection to identify the class of the segment\",\n    \"For each class name identified in step 3, perform entity recognition to identify any entities (dates, individuals, places)\",\n    \"Store the class name and identified entities for each segment in a data structure for further processing\",\n    \"Perform text summarization to generate a brief description of the overall context of the image based on the class names and identified entities\",\n    \"Perform question answering using the stored data structure and the generated summary to answer the questions: 'Where is the location of the main object?' and 'What is the overall context of the image?'\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image Segmentation\"\n    },\n    {\n      \"task_name\": \"Object Detection\"\n    },\n    {\n      \"task_name\": \"Entity Recognition\"\n    },\n    {\n      \"task_name\": \"Text Summarization\"\n    },\n    {\n      \"task_name\": \"Question Answering\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Segmentation\", \"target\": \"Object Detection\"},\n    {\"source\": \"Object Detection\", \"target\": \"Entity Recognition\"},\n    {\"source\": \"Object Detection\", \"target\": \"Text Summarization\"},\n    {\"source\": \"Object Detection\", \"target\": \"Question Answering\"},\n    {\"source\": \"Entity Recognition\", \"target\": \"Text Summarization\"},\n    {\"source\": \"Entity Rec"
"```json\n{\n  \"task_steps\": [\n    \"Load and preprocess the conversation prompt 'What are the benefits of exercising regularly?'\",\n    \"Invoke Text-to-Speech API to generate an audio response from the conversation prompt\",\n    \"Invoke Conversational API to generate a conversational response based on the text input and the preprocessed conversation prompt\",\n    \"Invoke Summarization API to summarize the conversational response\",\n    \"Invoke Text-to-Image API to generate an image of a person engaging in exercise\",\n    \"Load and preprocess the image 'example.jpg'\",\n    \"Invoke Image Editing API to replace the person in the image with the person engaging in exercise generated from the Text-to-Image API\"\n  ],\n  \"task_nodes\": [\n    \"Text-to-Speech\",\n    \"Conversational\",\n    \"Summarization\",\n    \"Text-to-Image\",\n    \"Image Editing\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Text-to-Speech\", \"target\": \"Conversational\"},\n    {\"source\": \"Conversational\", \"target\": \"Summarization\"},\n    {\"source\": \"Summarization\", \"target\": \"Text-to-Image\"},\n    {\"source\": \"Text-to-Image\", \"target\": \"Image Editing\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load 'example.wav' audio file\",\n    \"Perform audio source separation to isolate individual voices\",\n    \"Transcribe the separated audio into text using Automatic Speech Recognition\",\n    \"Enhance the transcribed text using Text-to-Speech\",\n    \"Perform Audio Classification on the enhanced speech\",\n    \"Perform Token Classification on the audio classification results\",\n    \"Generate conversational response based on token classification results\",\n    \"Create an image representing the conversational response using Text-to-Image\",\n    \"Extract text from the generated image using Optical Character Recognition\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Audio Source Separation\"\n    },\n    {\n      \"task_name\": \"Automatic Speech Recognition\"\n    },\n    {\n      \"task_name\": \"Text-to-Speech\"\n    },\n    {\n      \"task_name\": \"Audio Classification\"\n    },\n    {\n      \"task_name\": \"Token Classification\"\n    },\n    {\n      \"task_name\": \"Conversational Response Generation\"\n    },\n    {\n      \"task_name\": \"Text-to-Image\"\n    },\n    {\n      \"task_name\": \"Optical Character Recognition\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Audio Source Separation\", \"target\": \"Automatic Speech Recognition\"},\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text-to-Speech\"},\n    {\"source\": \"Text-to-Speech\", \"target\": \"Audio"
"```json\n{\n  \"task_steps\": [\n    \"Load the image 'example.jpg'\",\n    \"Perform image editing: Change color of car to blue and background to grayscale using Image Editing task\",\n    \"Save the edited image\",\n    \"Load the saved image for scene analysis using Document Question Answering task\",\n    \"Extract tabular information from the scene using Tabular Classification task\",\n    \"Compare the extracted tabular information to the given text 'The car is now blue on a grayscale background' using Text Comparison task\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image Editing\"\n    },\n    {\n      \"task_name\": \"Document Question Answering\"\n    },\n    {\n      \"task_name\": \"Tabular Classification\"\n    },\n    {\n      \"task_name\": \"Text Comparison\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Editing\", \"target\": \"Document Question Answering\"},\n    {\"source\": \"Document Question Answering\", \"target\": \"Tabular Classification\"},\n    {\"source\": \"Document Question Answering\", \"target\": \"Text Comparison\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load and preprocess document image (example.jpg)\",\n    \"Perform Image-to-Text OCR to extract text from document image\",\n    \"Perform Text Summarization to extract key points from the document text\",\n    \"Perform Question Answering to identify the answer to the question 'What are the main advantages described in the document?' from the summarized text\",\n    \"Perform Text-to-Speech to convert the answer into speech\",\n    \"Perform Text Analysis to determine the emotion conveyed by the answer\"\n  ],\n  \"task_nodes\": [\n    \"Image Classification (for document image identification and preprocessing)\",\n    \"Text-to-Text Model (for OCR and Text Summarization)\",\n    \"Question Answering Model (for extracting answer from summarized text)\",\n    \"Text-to-Speech Model (for converting answer into speech)\",\n    \"Text Analysis Model (for emotion detection)\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification\", \"target\": \"Text-to-Text Model\"},\n    {\"source\": \"Text-to-Text Model\", \"target\": \"Question Answering Model\"},\n    {\"source\": \"Question Answering Model\", \"target\": \"Text-to-Speech Model\"},\n    {\"source\": \"Text-to-Text Model\", \"target\": \"Text Analysis Model\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load the example.jpg image into memory.\",\n    \"Apply image editing techniques to enhance the image, making it clearer and brighter.\",\n    \"Perform image classification to estimate the depth of objects in the image.\",\n    \"Use object detection to identify and label the objects in the enhanced image.\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image Editing\"\n    },\n    {\n      \"task_name\": \"Depth Estimation\"\n    },\n    {\n      \"task_name\": \"Object Detection\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Editing\", \"target\": \"Depth Estimation\"},\n    {\"source\": \"Depth Estimation\", \"target\": \"Object Detection\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load 'example.wav' audio file\",\n    \"Apply audio denoising to remove noise from the audio file\",\n    \"Perform speech separation to extract individual speaker's audio\",\n    \"Perform automatic speech recognition (ASR) to transcribe the command from the separated audio\",\n    \"Apply Optical Character Recognition (OCR) to extract text from the generated image\",\n    \"Perform text-to-speech synthesis to generate speech from the extracted text\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Audio Denoising\"\n    },\n    {\n      \"task_name\": \"Speech Separation\"\n    },\n    {\n      \"task_name\": \"Automatic Speech Recognition (ASR)\"\n    },\n    {\n      \"task_name\": \"Image Generation\"\n    },\n    {\n      \"task_name\": \"Text Extraction (OCR)\"\n    },\n    {\n      \"task_name\": \"Text-to-Speech Synthesis\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Audio Denoising\", \"target\": \"Speech Separation\"},\n    {\"source\": \"Speech Separation\", \"target\": \"Automatic Speech Recognition (ASR)\"},\n    {\"source\": \"Automatic Speech Recognition (ASR)\", \"target\": \"Image Generation\"},\n    {\"source\": \"Image Generation\", \"target\": \"Text Extraction (OCR)\"},\n    {\"source\": \"Text Extraction (OCR)\", \"target\": \"Text-to-Speech Synthesis\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load 'example.jpg' image\",\n    \"Perform image segmentation on 'example.jpg' to obtain segmented image\",\n    \"Apply image transformation on segmented image to obtain new image\",\n    \"Perform text extraction on transformed image to obtain extracted text\",\n    \"Generate new image based on extracted text\",\n    \"Perform question answering on generated image to determine main object\",\n    \"Perform translation of question answering result into French\",\n    \"Perform token classification on translated answer\",\n    \"Perform question answering on classified tokens to determine named entity\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image Segmentation\"\n    },\n    {\n      \"task_name\": \"Image Transformation\"\n    },\n    {\n      \"task_name\": \"Text Extraction\"\n    },\n    {\n      \"task_name\": \"Text-to-Image Generation\"\n    },\n    {\n      \"task_name\": \"Question Answering\"\n    },\n    {\n      \"task_name\": \"Translation\"\n    },\n    {\n      \"task_name\": \"Token Classification\"\n    },\n    {\n      \"task_name\": \"Document Question Answering\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Segmentation\", \"target\": \"Image Transformation\"},\n    {\"source\": \"Image Transformation\", \"target\": \"Text Extraction\"},\n    {\"source\": \"Text Extraction\", \"target\": \"Text-to-Image Generation\"},\n    {\"source\": \"Text-to-Image Generation\", \"target\": \"Question Answering\"},\n    {\"source\": \""
"```json\n{\n  \"task_steps\": [\n    \"Load 'example.jpg' image into memory.\",\n    \"Apply color modification to the image: change red objects to blue.\",\n    \"Save the modified image with a new name, e.g., 'modified_example.jpg'.\",\n    \"Load the saved modified image 'modified_example.jpg' for depth estimation.\",\n    \"Perform depth estimation on the loaded modified image.\",\n    \"Extract textual output from the depth estimation result.\",\n    \"Classify the table image based on the extracted textual output.\",\n    \"Generate speech from the textual output of table classification.\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image Editing\",\n      \"input\": [\"example.jpg\"],\n      \"output\": [\"modified_example.jpg\"]\n    },\n    {\n      \"task_name\": \"Depth Estimation\",\n      \"input\": [\"modified_example.jpg\"],\n      \"output\": [\"depth_estimation_output\"]\n    },\n    {\n      \"task_name\": \"Text Extraction\",\n      \"input\": [\"depth_estimation_output\"],\n      \"output\": [\"textual_output\"]\n    },\n    {\n      \"task_name\": \"Tabular Classification\",\n      \"input\": [\"textual_output\"],\n      \"output\": [\"classification_output\"]\n    },\n    {\n      \"task_name\": \"Text-to-Speech\",\n      \"input\": [\"classification_output\"],\n      \"output\": [\"speech_output\"]\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Editing\", \"target\": \"Depth Estimation\"},\n    {\"source\": \"Depth Estimation"
"```json\n{\n  \"task_steps\": [\n    \"Load and preprocess the table image (example.jpg)\",\n    \"Perform table image classification using Image Classification task\",\n    \"Based on the classification result, invoke Image-to-Image task to generate a related image\",\n    \"Perform Question Answering task on the generated image to determine the main theme\",\n    \"Invoke Text-to-Speech task to read out the question answering result\"\n  ],\n  \"task_nodes\": [\n    \"Image Classification\",\n    \"Image-to-Image\",\n    \"Question Answering\",\n    \"Text-to-Speech\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification\", \"target\": \"Image-to-Image\"},\n    {\"source\": \"Image-to-Image\", \"target\": \"Question Answering\"},\n    {\"source\": \"Question Answering\", \"target\": \"Text-to-Speech\"}\n  ]\n}\n```"
"{\n  \"task_steps\": [\n    \"Load image 'example.jpg'\",\n    \"Perform Object Detection on the loaded image to identify and extract bounding boxes of all objects in the image\",\n    \"Determine the height of each object by using Image Segmentation and Depth Estimation to calculate the height of the bounding boxes\",\n    \"Find the object with the maximum height among all detected objects\",\n    \"Extract the name of the object with the maximum height from the Object Detection results\",\n    \"Translate the object name from English to French using Translation API\",\n    \"Generate a new image with the translated text using Text-to-Image API\"\n  ],\n  \"task_nodes\": [\n    \"Object Detection\",\n    \"Image Segmentation\",\n    \"Depth Estimation\",\n    \"Translation\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification\", \"target\": \"Object Detection\"},\n    {\"source\": \"Object Detection\", \"target\": \"Image Segmentation\"},\n    {\"source\": \"Image Segmentation\", \"target\": \"Depth Estimation\"},\n    {\"source\": \"Depth Estimation\", \"target\": \"Object Detection\"},\n    {\"source\": \"Object Detection\", \"target\": \"Translation\"},\n    {\"source\": \"Translation\", \"target\": \"Text-to-Image\"},\n    {\"source\": \"Text-to-Image\", \"target\": \"Image Generation\"}\n  ]\n}\n\nNote: Since Image Classification was not explicitly mentioned in the user request, I assumed it as a prerequisite for Object Detection. Therefore, I added a task link from Image Classification to Object Detection. If Image Classification is not required, this link can be removed."
"```json\n{\n  \"task_steps\": [\n    \"Load the image 'example.jpg'\",\n    \"Apply image editing to change the color of the table to blue\",\n    \"Segment the image to extract tabular data\",\n    \"Classify the tabular data\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image Classification\",\n      \"input\": {\n        \"image_path\": \"example.jpg\"\n      },\n      \"output\": {\n        \"edited_image\": \"\"\n      }\n    },\n    {\n      \"task_name\": \"Image Segmentation\",\n      \"input\": {\n        \"image_path\": \"\",\n        \"edited_image\": \"${Image_Classification.output.edited_image}\"\n      },\n      \"output\": {\n        \"segmented_image\": \"\",\n        \"tabular_data\": []\n      }\n    },\n    {\n      \"task_name\": \"Tabular Classification\",\n      \"input\": {\n        \"tabular_data\": \"${Image_Segmentation.output.tabular_data}\"\n      },\n      \"output\": {\n        \"classified_data\": \"\"\n      }\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification\", \"target\": \"Image Segmentation\"},\n    {\"source\": \"Image Segmentation\", \"target\": \"Tabular Classification\"}\n  ]\n}\n```\n\nThis JSON format represents the task steps, task nodes, and task links required to fulfill the user's request. The user's request is to change the color of the table in an image, segment the image, and classify the tabular data. The task steps are defined in the \""
"```json\n{\n  \"task_steps\": [\n    \"Load the example.wav audio file\",\n    \"Perform Automatic Speech Recognition (ASR) on the audio file to extract text\",\n    \"Load the example.txt file\",\n    \"Perform Text-to-Question Answering on the extracted text and the text in example.txt to find the question about Iron Man\",\n    \"Perform Question Answering on the question to identify the actor who played Iron Man in the Marvel movies\",\n    \"Generate a conversational response using the identified actor's name\"\n  ],\n  \"task_nodes\": [\n    \"Automatic Speech Recognition\",\n    \"Text-to-Question Answering\",\n    \"Question Answering\",\n    \"Text Generation\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text-to-Question Answering\"},\n    {\"source\": \"Text-to-Question Answering\", \"target\": \"Question Answering\"},\n    {\"source\": \"Question Answering\", \"target\": \"Text Generation\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load the document image 'example.jpg'\",\n    \"Perform Optical Character Recognition (OCR) to extract text from the image\",\n    \"Perform Document Question Answering (DQA) to identify the main topic of the document from the extracted text\",\n    \"Generate a related sentence based on the main topic using Text Generation\",\n    \"Perform Sentence Similarity analysis to compare the original question and the newly generated sentence\"\n  ],\n  \"task_nodes\": [\n    \"Image-to-Text\",\n    \"Document Question Answering\",\n    \"Text Generation\",\n    \"Sentence Similarity\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image-to-Text\", \"target\": \"Document Question Answering\"},\n    {\"source\": \"Document Question Answering\", \"target\": \"Text Generation\"},\n    {\"source\": \"Text Generation\", \"target\": \"Sentence Similarity\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load image 'example1.jpg' for text enhancement.\",\n    \"Apply text enhancement techniques to improve the clarity of the text in 'example1.jpg'.\",\n    \"Extract text from the enhanced image using Optical Character Recognition (OCR).\",\n    \"Store the extracted text in a variable.\",\n    \"Load image 'example2.jpg' for vegetarian question answering.\",\n    \"Perform vegetarian question answering on the image 'example2.jpg' to determine if the dish is vegetarian.\",\n    \"Store the vegetarian answer in a variable.\",\n    \"Generate an audio file of the vegetarian answer using Text-to-Speech.\",\n    \"Apply Audio-to-Audio techniques to enhance the audio quality.\",\n    \"Perform Automatic Speech Recognition on the enhanced audio file to transcribe it into text.\",\n    \"Store the transcribed text in a variable.\",\n    \"Output the extracted text and the transcribed text.\"\n  ],\n  \"task_nodes\": [\n    \"Text Enhancement and OCR\",\n    \"Vegetarian Question Answering\",\n    \"Text-to-Speech\",\n    \"Audio Enhancement\",\n    \"Automatic Speech Recognition\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Text Enhancement and OCR\", \"target\": \"Vegetarian Question Answering\"},\n    {\"source\": \"Vegetarian Question Answering\", \"target\": \"Text-to-Speech\"},\n    {\"source\": \"Text-to-Speech\", \"target\": \"Audio Enhancement\"},\n    {\"source\": \"Audio Enhancement\", \"target\": \"Automatic Speech Recognition\"}"
"```json\n{\n  \"task_steps\": [\n    \"Load image from example.jpg\",\n    \"Perform image preprocessing for depth estimation\",\n    \"Invoke Image Depth Estimation API to predict depth of objects in the image\",\n    \"Perform image transformation\",\n    \"Invoke Image Transformation API to apply desired image transformations\",\n    \"Invoke Image Segmentation API to segment the image into meaningful parts\",\n    \"Invoke Object Detection API to classify the segmented parts and identify primary object\",\n    \"Extract the primary object's classification result\",\n    \"Store the primary object's classification result for comparison\",\n    \"Compare the primary object's classification result with the given text 'a car'\"\n  ],\n  \"task_nodes\": [\n    \"Image Classification\",\n    \"Image Segmentation\",\n    \"Depth Estimation\",\n    \"Image Transformation\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification\", \"target\": \"Question Answering\"},\n    {\"source\": \"Depth Estimation\", \"target\": \"Image Segmentation\"},\n    {\"source\": \"Image Segmentation\", \"target\": \"Object Detection\"},\n    {\"source\": \"Object Detection\", \"target\": \"Question Answering\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load the example.jpg image\",\n    \"Perform object detection on the image to identify and locate objects\",\n    \"Classify each object using object detection results\",\n    \"Perform depth estimation on each object using the image\",\n    \"Generate a text description of the objects, their depth, and classification\",\n    \"Convert the text description into a script for text-to-speech\",\n    \"Generate an empty video with the desired length\",\n    \"For each object in the image, create a visual representation using image-to-video\",\n    \"Overlay the text description and visual representation of each object onto the video\",\n    \"Add the text-to-speech audio to the video\"\n  ],\n  \"task_nodes\": [\n    \"Image Classification\",\n    \"Object Detection\",\n    \"Depth Estimation\",\n    \"Text Generation\",\n    \"Text-to-Speech\",\n    \"Image-to-Video\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Object Detection\", \"target\": \"Classification\"},\n    {\"source\": \"Object Detection\", \"target\": \"Depth Estimation\"},\n    {\"source\": \"Text Generation\", \"target\": \"Text-to-Speech\"},\n    {\"source\": \"Image-to-Video\", \"target\": \"Object Detection\"},\n    {\"source\": \"Text-to-Speech\", \"target\": \"Image-to-Video\"}\n  ]\n}\n```\n\nThis JSON format represents the task steps, task nodes, and task links required to generate a video from an image that visually describes the objects present in the image, their depth, and their classification. The task steps are described in a clear and concise manner, and the task nodes are"
"{\n  \"task_steps\": [\n    \"Load example.jpg image\",\n    \"Perform object detection on the loaded image to identify cars\",\n    \"Extract color information from the identified car object\",\n    \"Generate an image based on the extracted color information\",\n    \"Classify the text in the generated image using token classification\",\n    \"Perform question answering on the token-classified text to retrieve the car model\",\n    \"Edit the example.jpg image based on the retrieved car model\",\n    \"Perform depth estimation on the edited image\",\n    \"Perform document question answering on a document to retrieve the total amount due\",\n    \"Compare the depth estimation image with the edited image to ensure accuracy\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image Classification\",\n      \"input\": [\"example.jpg\"],\n      \"output\": [\"car_object_info\"]\n    },\n    {\n      \"task_name\": \"Text-to-Image\",\n      \"input\": [\"car_color\"],\n      \"output\": [\"color_image\"]\n    },\n    {\n      \"task_name\": \"Text Classification\",\n      \"input\": [\"color_image_text\"],\n      \"output\": [\"token-classified_text\"]\n    },\n    {\n      \"task_name\": \"Question Answering\",\n      \"input\": [\"token-classified_text\"],\n      \"output\": [\"car_model\"]\n    },\n    {\n      \"task_name\": \"Image Editing\",\n      \"input\": [\"example.jpg\", \"car_model\"],\n      \"output\": [\"edited_image\"]\n    },\n    {\n      \"task_name\": \"Depth Estimation\",\n      \"input\": [\"edited_"
"```json\n{\n  \"task_steps\": [\n    \"Load 'example.wav' audio file\",\n    \"Perform Automatic Speech Recognition to extract text from audio\",\n    \"Perform Text-to-Speech to confirm correctness of extracted text\",\n    \"Perform Text Classification to identify content type\",\n    \"Invoke Translation API to translate text into French\",\n    \"Perform Named Entity Recognition on translated text\",\n    \"Generate summary of named entities and translated text\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Automatic Speech Recognition\"\n    },\n    {\n      \"task_name\": \"Text Classification\"\n    },\n    {\n      \"task_name\": \"Translation\"\n    },\n    {\n      \"task_name\": \"Named Entity Recognition\"\n    },\n    {\n      \"task_name\": \"Text-to-Speech\"\n    },\n    {\n      \"task_name\": \"Summarization\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text Classification\"},\n    {\"source\": \"Text Classification\", \"target\": \"Translation\"},\n    {\"source\": \"Translation\", \"target\": \"Named Entity Recognition\"},\n    {\"source\": \"Named Entity Recognition\", \"target\": \"Summarization\"}\n  ]\n}\n```"
"{\n  \"task_steps\": [\n    \"Parse user input to extract required tasks and data.\",\n    \"Initialize an empty list to store the table data.\",\n    \"Create three empty dictionaries to store data for apples, oranges, and bananas.\",\n    \"Iterate through each fruit in the user input and add it to the table data list.\",\n    \"For each fruit in the table data list, create a new task node for 'Text-to-Table' to convert the user request into a table.\",\n    \"Invoke 'Text-to-Table' API with the fruit name as input.\",\n    \"Store the output of 'Text-to-Table' API in the corresponding fruit dictionary.\",\n    \"After all fruits have been processed, create a new task node for 'Table-to-Image' to convert the table data into an image.\",\n    \"Invoke 'Table-to-Image' API with the table data list as input.\",\n    \"Store the output of 'Table-to-Image' API as the final image.\",\n    \"Create a new task node for 'Image Classification' to determine the most popular fruit based on the image.\",\n    \"Invoke 'Image Classification' API with the image as input.\",\n    \"Parse the output of 'Image Classification' API to extract the name of the most popular fruit.\",\n    \"Print or return the name of the most popular fruit.\"\n  ],\n  \"task_nodes\": [\n    \"Text-to-Table (Apple)\",\n    \"Text-to-Table (Orange)\",\n    \"Text-to-Table (Banana)\",\n    \"Table-to-Image\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Text-to-Table (Apple)\", \"target\": \"Table-to-Image\"},\n    {\"source"
"{\n  \"task_steps\": [\n    \"Load 'example.jpg' image\",\n    \"Apply blue background color to the image\",\n    \"Estimate depth of objects in the modified image\",\n    \"Classify the modified image based on the depth estimation\",\n    \"Generate 'example.mp4' video based on the image label\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image Editing\",\n      \"input\": {\n        \"image_path\": \"example.jpg\",\n        \"background_color\": \"blue\"\n      },\n      \"output\": {\n        \"modified_image_path\": \"output_modified_image.jpg\"\n      }\n    },\n    {\n      \"task_name\": \"Depth Estimation\",\n      \"input\": {\n        \"image_path\": \"{output_modified_image.jpg}\"\n      },\n      \"output\": {\n        \"depth_map_path\": \"output_depth_map.png\"\n      }\n    },\n    {\n      \"task_name\": \"Tabular Classification\",\n      \"input\": {\n        \"depth_map_path\": \"output_depth_map.png\"\n      },\n      \"output\": {\n        \"label\": \"output_label\"\n      }\n    },\n    {\n      \"task_name\": \"Text-to-Video\",\n      \"input\": {\n        \"label\": \"output_label\"\n      },\n      \"output\": {\n        \"video_path\": \"example.mp4\"\n      }\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Editing\", \"target\": \"Depth Estimation\"},\n    {\"source\": \"Depth Estimation\", \"target\":"
"```json\n{\n  \"task_steps\": [\n    \"Load the image file 'example.jpg'.\",\n    \"Perform Object Detection to identify and locate objects in the image.\",\n    \"For each detected object, perform Depth Estimation to determine the distance of the object from the camera.\",\n    \"Extract descriptions of each object using Text-to-Speech for audible output and Text Generation for written output.\"\n  ],\n  \"task_nodes\": [\n    \"Object Detection\",\n    \"Depth Estimation for each detected object\",\n    \"Text-to-Speech for each description\",\n    \"Text Generation for each description\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Object Detection\", \"target\": \"Depth Estimation for each detected object\"},\n    {\"source\": \"Depth Estimation for each detected object\", \"target\": \"Text-to-Speech for each description\"},\n    {\"source\": \"Depth Estimation for each detected object\", \"target\": \"Text Generation for each description\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load the audio file 'example.wav'\",\n    \"Perform Automatic Speech Recognition (ASR) on the audio file to extract text from the command\",\n    \"Perform Text-to-Question Annotation to generate a question from the extracted command\",\n    \"Invoke Document Question Answering (DQA) model to extract relevant information from the document image 'example.jpg' based on the generated question\",\n    \"Perform Text-to-Speech (TTS) to confirm the retrieved information from the DQA model\",\n    \"Load the initial image 'example.png'\",\n    \"Perform Image-to-Text (ITT) to extract textual information from the image\",\n    \"Compare the textual information extracted from the image with the retrieved information from the DQA model using Text Similarity\",\n    \"If the textual information matches, perform Image Editing based on the retrieved information\"\n  ],\n  \"task_nodes\": [\n    \"Automatic Speech Recognition\",\n    \"Text-to-Question Annotation\",\n    \"Document Question Answering\",\n    \"Text-to-Speech\",\n    \"Image-to-Text\",\n    \"Text Similarity\",\n    \"Image Editing\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text-to-Question Annotation\"},\n    {\"source\": \"Text-to-Question Annotation\", \"target\": \"Document Question Answering\"},\n    {\"source\": \"Document Question Answering\", \"target\": \"Text-to-Speech\"},\n    {\"source\": \"Image-to-Text\", \"target\": \"Text Similarity\"},\n"
"```json\n{\n  \"task_steps\": [\n    \"Load example.jpg into memory\",\n    \"Invoke Image Editing API with example.jpg and example.wav as inputs\",\n    \"Save edited image as new_example.jpg\",\n    \"Load new_example.jpg into memory\",\n    \"Invoke Text-to-Image API to generate depth estimation image\",\n    \"Save depth estimation image as depth_example.jpg\",\n    \"Invoke Object Detection API with depth_example.jpg as input\",\n    \"Save object detection results as output.json\"\n  ],\n  \"task_nodes\": [\n    \"Image Editing\",\n    \"Text-to-Image\",\n    \"Object Detection\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Editing\", \"target\": \"Text-to-Image\"},\n    {\"source\": \"Text-to-Image\", \"target\": \"Object Detection\"}\n  ]\n}\n```\n\nThis JSON format represents the task steps, task nodes, and task links required to fulfill the user's request. The user's request was to edit an example image based on audio instructions, generate a depth estimation image of the edited image, and then detect and label objects in the depth estimation image. The task steps are aligned with the task nodes, and the task links reflect the dependencies among the tasks. The tasks selected are Image Editing, Text-to-Image, and Object Detection, which are all present in the TASK LIST."
"```json\n{\n  \"task_steps\": [\n    \"Load 'example.jpg' image\",\n    \"Apply image enhancement techniques to 'example.jpg'\",\n    \"Extract text from 'example.jpg'\",\n    \"Generate conversation around the extracted text\",\n    \"Translate the conversation to another language\",\n    \"Create a text script for the video based on the translated conversation\",\n    \"Generate a video from the text script and the enhanced image\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image Classification/Image-to-Text\",\n      \"input\": {\"image_path\": \"example.jpg\"},\n      \"output\": {\"text\": \"\"}\n    },\n    {\n      \"task_name\": \"Text Generation\",\n      \"input\": {\"text\": \"\"},\n      \"output\": {\"conversation\": \"\"}\n    },\n    {\n      \"task_name\": \"Translation\",\n      \"input\": {\"text\": \"\"},\n      \"output\": {\"translated_text\": \"\"}\n    },\n    {\n      \"task_name\": \"Text-to-Video\",\n      \"input\": {\n        \"text\": \"\",\n        \"enhanced_image\": \"\"\n      },\n      \"output\": {\"video\": \"\"}\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification/Image-to-Text\", \"target\": \"Text Generation\"},\n    {\"source\": \"Text Generation\", \"target\": \"Translation\"},\n    {\"source\": \"Translation\", \"target\": \"Text-to-Video\"},\n    {\"source\": \"Image Classification/Image-to-Text\", \"target\": \"Image Enhancement\"}\n  ]\n}\n```\n\nThis JSON format represents the task"
