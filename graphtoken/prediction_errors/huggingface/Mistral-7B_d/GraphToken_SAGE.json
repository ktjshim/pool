"```json\n{\n  \"task_steps\": [\n    \"Load the audio file 'example.wav'\",\n    \"Apply audio enhancement to the loaded audio file using 'Audio Editing' task\",\n    \"Transcribe the enhanced audio using 'Automatic Speech Recognition' task\",\n    \"Load the image file 'example.jpg'\",\n    \"Classify the place in the image using 'Image Classification' task\",\n    \"Extract the question 'What is the most notable feature of this place?' from the transcribed speech using 'Question Answering' task\",\n    \"Classify the tokens of the question answer using 'Token Classification' task\",\n    \"Generate a conversational response based on the classified tokens using 'Text Generation' and 'Conversational' tasks\"\n  ],\n  \"task_nodes\": [\n    \"Audio Editing\",\n    \"Automatic Speech Recognition\",\n    \"Image Classification\",\n    \"Question Answering\",\n    \"Token Classification\",\n    \"Text Generation\",\n    \"Conversational\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Audio Editing\", \"target\": \"Automatic Speech Recognition\"},\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Question Answering\"},\n    {\"source\": \"Question Answering\", \"target\": \"Token Classification\"},\n    {\"source\": \"Token Classification\", \"target\": \"Text Generation\"},\n    {\"source\": \"Text Generation\", \"target\": \"Conversational\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load the audio file 'example.wav' for emotion and speaker recognition.\",\n    \"Invoke the 'Automatic Speech Recognition' API to transcribe the audio file into text.\",\n    \"Invoke the 'Audio Classification' API to recognize the emotion from the audio file.\",\n    \"Invoke the 'Speaker Recognition' API to identify the speaker from the audio file.\",\n    \"Generate a text description based on the recognized emotion and speaker.\",\n    \"Invoke the 'Text-to-Image' API to create an image based on the generated text description.\",\n    \"Invoke the 'Image Editing' API to edit the 'example.jpg' image using the generated text description.\",\n    \"Invoke the 'Text-to-Speech' API to generate an audio file from the text description.\",\n    \"Invoke the 'Image-to-Text' API to extract text from the edited image.\"\n  ],\n  \"task_nodes\": [\n    \"Automatic Speech Recognition\",\n    \"Audio Classification\",\n    \"Speaker Recognition\",\n    \"Text Generation\",\n    \"Text-to-Image\",\n    \"Image Editing\",\n    \"Text-to-Speech\",\n    \"Image-to-Text\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text Generation\"},\n    {\"source\": \"Audio Classification\", \"target\": \"Text Generation\"},\n    {\"source\": \"Speaker Recognition\", \"target\": \"Text Generation\"},\n    {\"source\": \"Text Generation\", \"target\": \"Text-to-Image\"},\n    {\"source\": \"Text Generation\", \"target\": \"Text-to-Speech\"},\n    {\"source\": \""
"{\n  \"task_steps\": [\n    \"Load 'example.jpg' image\",\n    \"Perform Image Preprocessing\",\n    \"Execute Image Depth Estimation\",\n    \"Execute Object Detection\",\n    \"Identify the largest object from the detected objects\",\n    \"Perform Text-to-Speech to describe the largest object\",\n    \"Execute Visual Question Answering with question 'What is the largest object in the image?'\",\n    \"Execute Text Summarization on the VQA answer\",\n    \"Execute Document Question Answering on the summarized text with question 'What is the name of the largest object?'\",\n    \"Execute Text-to-Speech to read the DQA answer\",\n    \"Execute Token Classification on the DQA answer\"\n  ],\n  \"task_nodes\": [\n    \"Image Classification: Depth Estimation\",\n    \"Object Detection: Instance Segmentation\",\n    \"Text-to-Speech: Description Generation\",\n    \"Question Answering: Visual Question Answering\",\n    \"Text Summarization: Sentence Summarization\",\n    \"Question Answering: Document Question Answering\",\n    \"Text-to-Speech: Answer Generation\",\n    \"Text Classification: Token Classification\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Load 'example.jpg' image\", \"target\": \"Image Classification: Depth Estimation\"},\n    {\"source\": \"Image Classification: Depth Estimation\", \"target\": \"Object Detection: Instance Segmentation\"},\n    {\"source\": \"Object Detection: Instance Segmentation\", \"target\": \"Text-to-Speech: Description Generation\"},\n    {\"source\": \"Text-to-Speech: Description Generation\", \""
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Load and preprocess the example.jpg image for text extraction\",\n            \"task_name\": \"Image-to-Text\"\n        },\n        {\n            \"step_description\": \"Extract text from the image using the output of Image-to-Text task\",\n            \"task_name\": \"Text Extraction\"\n        },\n        {\n            \"step_description\": \"Generate simplified text based on the extracted text\",\n            \"task_name\": \"Text Summarization\"\n        },\n        {\n            \"step_description\": \"Edit the example.jpg image based on the summarized text\",\n            \"task_name\": \"Image Editing\"\n        },\n        {\n            \"step_description\": \"Generate a question about the main subject of the edited image\",\n            \"task_name\": \"Question Generation\"\n        },\n        {\n            \"step_description\": \"Determine the main subject of the final image based on the question and edited image\",\n            \"task_name\": \"Document Question Answering\"\n        }\n    ],\n    \"task_nodes\": [\n        {\n            \"task_name\": \"Image-to-Text\"\n        },\n        {\n            \"task_name\": \"Text Extraction\"\n        },\n        {\n            \"task_name\": \"Text Summarization\"\n        },\n        {\n            \"task_name\": \"Image Editing\"\n        },\n        {\n            \"task_name\": \"Question Generation\"\n        },\n        {\n            \"task_name\": \"Document Question Answering\"\n        }\n    ],\n    \"task_links\": [\n        {\n            \"source\": \"Image-to-"
"```json\n{\n  \"task_steps\": [\n    \"Load image 'example.jpg' and extract text descriptions using OCR.\",\n    \"Perform text token classification using 'Text Classification' task.\",\n    \"Identify objects present in the image using 'Object Detection' task.\",\n    \"Classify the detected objects using 'Image Classification' task.\",\n    \"Edit the image based on the classified tokens using 'Image Editing' task.\",\n    \"Perform tabular classification on the edited image using 'Tabular Classification' task.\",\n    \"Summarize the results of all the tasks using 'Summarization' task.\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Text Classification\"\n    },\n    {\n      \"task_name\": \"Object Detection\"\n    },\n    {\n      \"task_name\": \"Image Classification\"\n    },\n    {\n      \"task_name\": \"Image Editing\"\n    },\n    {\n      \"task_name\": \"Tabular Classification\"\n    },\n    {\n      \"task_name\": \"Summarization\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Load image and extract text descriptions\", \"target\": \"Text Classification\"},\n    {\"source\": \"Text Classification\", \"target\": \"Object Detection\"},\n    {\"source\": \"Object Detection\", \"target\": \"Image Classification\"},\n    {\"source\": \"Image Classification\", \"target\": \"Image Editing\"},\n    {\"source\": \"Image Editing\", \"target\": \"Tabular Classification\"},\n    {\"source\": \"Tabular Classification\", \"target\": \"Summarization\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load the document image 'example.jpg'\",\n    \"Perform Image-to-Text task to extract text from the document image\",\n    \"Speak the given text 'What is the fastest land animal?' using Text-to-Speech task\",\n    \"Perform Audio-to-Audio task to enhance the audio quality\",\n    \"Perform Automatic Speech Recognition task to transcribe the enhanced audio back into text\",\n    \"Perform Question Answering task using the extracted text from the document image and the transcribed text to answer the question 'What is the fastest land animal?'\"\n  ],\n  \"task_nodes\": [\n    \"Text-to-Image\",\n    \"Text-to-Speech\",\n    \"Audio-to-Audio\",\n    \"Automatic Speech Recognition\",\n    \"Question Answering\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Text-to-Image\", \"target\": \"Text-to-Speech\"},\n    {\"source\": \"Text-to-Speech\", \"target\": \"Audio-to-Audio\"},\n    {\"source\": \"Audio-to-Audio\", \"target\": \"Automatic Speech Recognition\"},\n    {\"source\": \"Text-to-Image\", \"target\": \"Question Answering\"},\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Question Answering\"}\n  ]\n}\n```\n\nThis JSON format represents the task steps, task nodes, and task links required to fulfill the user's request. The text is first converted into speech using Text-to-Speech, the audio is then enhanced using Audio-to-Audio, and the transcribed text is obtained using Automatic Speech"
"```json\n{\n  \"task_steps\": [\n    \"Load the example.jpg image into memory.\",\n    \"Perform object segmentation on the image to identify and extract individual objects.\",\n    \"For each object, perform depth estimation to determine its distance from the camera.\",\n    \"Classify each object based on its segmented pixels and depth estimation using tabular classification.\",\n    \"Store the results of object segmentation, depth estimation, and tabular classification in a structured format.\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image Segmentation\"\n    },\n    {\n      \"task_name\": \"Depth Estimation\"\n    },\n    {\n      \"task_name\": \"Tabular Classification\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Segmentation\", \"target\": \"Depth Estimation\"},\n    {\"source\": \"Depth Estimation\", \"target\": \"Tabular Classification\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load image 'example.jpg' for tabular classification.\",\n    \"Perform tabular classification on the loaded image.\",\n    \"Extract text from the classified table.\",\n    \"Load target image 'target_example.jpg' for image comparison.\",\n    \"Perform image-to-text conversion on the target image.\",\n    \"Compare the extracted text with the text from the source image.\",\n    \"If the text is identical, proceed with image editing.\",\n    \"Load the source image for image editing.\",\n    \"Change color of table header to blue.\",\n    \"Save the edited image.\",\n    \"Load both the source and target images for image-to-image translation.\",\n    \"Perform image-to-image translation to adjust the characteristics of the source image to match the target image.\",\n    \"Save the translated image.\"\n  ],\n  \"task_nodes\": [\n    \"Tabular Classification\",\n    \"Text Extraction\",\n    \"Image Comparison\",\n    \"Image-to-Text Conversion\",\n    \"Text Comparison\",\n    \"Image Editing\",\n    \"Image-to-Image Translation\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Tabular Classification\", \"target\": \"Text Extraction\"},\n    {\"source\": \"Text Extraction\", \"target\": \"Image Comparison\"},\n    {\"source\": \"Image Comparison\", \"target\": \"Text Comparison\"},\n    {\"source\": \"Text Comparison\", \"target\": \"Image Editing\"},\n    {\"source\": \"Image Editing\", \"target\": \"Image-to-Image Translation\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load image example.jpg\",\n    \"Perform object segmentation on the image\",\n    \"Extract text from the image using text recognition\",\n    \"Perform text-to-speech conversion on the extracted text\",\n    \"Record the speech output\",\n    \"Perform automatic speech recognition on the recorded speech\",\n    \"Compare the original text description with the transcribed text using text similarity measurement\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Object Segmentation\"\n    },\n    {\n      \"task_name\": \"Text Recognition\"\n    },\n    {\n      \"task_name\": \"Text-to-Speech\"\n    },\n    {\n      \"task_name\": \"Speech Recognition\"\n    },\n    {\n      \"task_name\": \"Text Similarity Measurement\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Object Segmentation\", \"target\": \"Text Recognition\"},\n    {\"source\": \"Text Recognition\", \"target\": \"Text-to-Speech\"},\n    {\"source\": \"Text-to-Speech\", \"target\": \"Speech Recognition\"},\n    {\"source\": \"Speech Recognition\", \"target\": \"Text Similarity Measurement\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load 'example.jpg' image\",\n    \"Perform image segmentation to extract text-containing areas\",\n    \"For each text-containing area:\",\n      {\n        \"Extract text using OCR\",\n        \"Translate text into English using Translation\",\n        \"Perform Text-to-Entity Extraction on translated text\"\n      }\n  ],\n  \"task_nodes\": [\n    \"Image Segmentation\",\n    \"Object Detection (for text-containing areas)\",\n    \"Text-to-Speech (optional for audio output)\",\n    \"Text Extraction using OCR\",\n    \"Translation\",\n    \"Text-to-Entity Extraction\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Segmentation\", \"target\": \"Object Detection\"},\n    {\"source\": \"Object Detection\", \"target\": \"Text Extraction using OCR\"},\n    {\"source\": \"Text Extraction using OCR\", \"target\": \"Translation\"},\n    {\"source\": \"Translation\", \"target\": \"Text-to-Entity Extraction\"}\n  ]\n}\n```\n\nThis JSON format represents the task steps, task nodes, and task links required to fulfill the user's request. The image segmentation task is used to extract text-containing areas from the image. Object detection is then used to identify these areas. Text is extracted from each area using Optical Character Recognition (OCR). The extracted text is then translated into English using a translation API. Finally, text-to-entity extraction is performed on the translated text to identify specific entities such as dates, individuals, and places. The task steps are strictly aligned with the task nodes, and the number of task steps"
"{\n  \"task_steps\": [\n    \"Load the 'example.jpg' image into memory.\",\n    \"Perform Object Detection on the loaded image to identify the car in the image.\",\n    \"Extract the location and size of the car from the Object Detection output.\",\n    \"Create a copy of the original image and paste a blue car image over the identified car location and size in the copied image.\",\n    \"Perform Image Editing on the edited image to blend the blue car image with the background.\",\n    \"Generate a text description for the edited image with a blue car.\",\n    \"Save the edited image and text description to the desired output directories.\"\n  ],\n  \"task_nodes\": [\n    \"Object Detection\",\n    \"Image Editing\",\n    \"Text Generation\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification\", \"target\": \"Object Detection\"},\n    {\"source\": \"Object Detection\", \"target\": \"Image Editing\"},\n    {\"source\": \"Image Editing\", \"target\": \"Text Generation\"}\n  ]\n}\n\n# EXPLANATION #:\n# The user request can be solved by following these steps:\n# 1. Use Object Detection to identify the car in the image.\n# 2. Use Image Editing to replace the car in the image with a blue car.\n# 3. Use Text Generation to create a new text description for the edited image.\n# The dependencies among these tasks are as follows:\n# Object Detection -> Image Editing -> Text Generation.\n# Therefore, the task links reflect this dependency order.\n# Image Classification is a prerequisite for Object Detection, but it is not directly related to the user request, so it is not included in the task list."
"```json\n{\n  \"task_steps\": [\n    \"Load the example.wav file into the audio processing system.\",\n    \"Apply audio denoising techniques to enhance the audio quality.\",\n    \"Perform speaker diarization to separate the sources in the audio.\",\n    \"Recognize the speaker using speaker recognition model.\",\n    \"Transcribe the recognized speaker's command using Automatic Speech Recognition (ASR) model.\",\n    \"Understand the command using a Natural Language Understanding (NLU) model.\",\n    \"Translate the command from English to French using a Machine Translation model.\",\n    \"Generate a conversational response using a Text Generation model.\",\n    \"Create a video with the conversational response using a Text-to-Video model.\"\n  ],\n  \"task_nodes\": [\n    \"Audio Editing: Audio-to-Audio (denoising)\",\n    \"Speaker Recognition: Speaker Diarization and Identification\",\n    \"Speech Recognition: Automatic Speech Recognition\",\n    \"Natural Language Processing: Text-to-Meaning (Understanding)\",\n    \"Translation: Machine Translation\",\n    \"Text Generation: Text Generation\",\n    \"Video Generation: Text-to-Video\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Audio Editing\", \"target\": \"Speaker Recognition\"},\n    {\"source\": \"Speaker Recognition\", \"target\": \"Speech Recognition\"},\n    {\"source\": \"Speech Recognition\", \"target\": \"Natural Language Processing\"},\n    {\"source\": \"Natural Language Processing\", \"target\": \"Translation\"},\n    {\"source\": \"Translation\", \"target\": \"Text Generation\"},\n    {\"source\": \""
"```json\n{\n  \"task_steps\": [\n    \"Load the given audio file 'example.wav'.\",\n    \"Perform Automatic Speech Recognition (ASR) to extract text from the audio file.\",\n    \"Generate a depth image from the text description using Text-to-Image.\",\n    \"Load the table within the depth image using Image Segmentation.\",\n    \"Perform Tabular Classification on the table data.\",\n    \"Translate the tabular data using Translation.\",\n    \"Perform Token Classification on the translated text.\",\n    \"Generate a summary from the token classified text using Summarization.\"\n  ],\n  \"task_nodes\": [\n    \"Automatic Speech Recognition\",\n    \"Text-to-Image\",\n    \"Image Segmentation\",\n    \"Tabular Classification\",\n    \"Translation\",\n    \"Token Classification\",\n    \"Summarization\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text-to-Image\"},\n    {\"source\": \"Text-to-Image\", \"target\": \"Image Segmentation\"},\n    {\"source\": \"Image Segmentation\", \"target\": \"Tabular Classification\"},\n    {\"source\": \"Tabular Classification\", \"target\": \"Translation\"},\n    {\"source\": \"Translation\", \"target\": \"Token Classification\"},\n    {\"source\": \"Token Classification\", \"target\": \"Summarization\"}\n  ]\n}\n```"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Perform image-to-text conversion to extract text data from the table in the image.\",\n            \"task_name\": \"Image-to-Text\"\n        },\n        {\n            \"step_description\": \"Perform tabular classification to identify and extract the table data.\",\n            \"task_name\": \"Tabular Classification\"\n        },\n        {\n            \"step_description\": \"Perform text summarization to identify the most common item in the table.\",\n            \"task_name\": \"Summarization\"\n        },\n        {\n            \"step_description\": \"Generate text-to-speech output to narrate the answer.\",\n            \"task_name\": \"Text-to-Speech\"\n        },\n        {\n            \"step_description\": \"Generate a text description of the answer.\",\n            \"task_name\": \"Text Generation\"\n        },\n        {\n            \"step_description\": \"Create a storyboard for the video.\",\n            \"task_name\": \"Text-to-Video\"\n        },\n        {\n            \"step_description\": \"Produce the video using the storyboard and the text-to-speech output.\",\n            \"task_name\": \"Video Generation\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Image-to-Text\",\n        \"Tabular Classification\",\n        \"Summarization\",\n        \"Text-to-Speech\",\n        \"Text Generation\",\n        \"Text-to-Video\",\n        \"Video Generation\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Image-to-Text\", \"target\": \"Tabular Classification\"},\n        {\"source\": \"Tabular Classification"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Perform Automatic Speech Recognition (ASR) on the audio file 'example.wav' to extract the command text.\",\n            \"task_name\": \"Automatic Speech Recognition\"\n        },\n        {\n            \"step_description\": \"Understand the command text and determine the type of image modification required.\",\n            \"task_name\": \"Question Answering\"\n        },\n        {\n            \"step_description\": \"Invoke the appropriate image modification API based on the determined modification type.\",\n            \"task_name\": \"Image Editing\"\n        },\n        {\n            \"step_description\": \"Generate a description of the image modification.\",\n            \"task_name\": \"Text Generation\"\n        },\n        {\n            \"step_description\": \"Perform Text-to-Image generation to create a visual representation of the description.\",\n            \"task_name\": \"Text-to-Image\"\n        },\n        {\n            \"step_description\": \"Save the modified image with a new name.\",\n            \"task_name\": \"File Manipulation\"\n        },\n        {\n            \"step_description\": \"Perform Text-to-Speech synthesis to create an audio file of the command text.\",\n            \"task_name\": \"Text-to-Speech\"\n        },\n        {\n            \"step_description\": \"Save the text transcription and the generated audio file.\",\n            \"task_name\": \"File Manipulation\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Automatic Speech Recognition\",\n        \"Question Answering\",\n        \"Image Editing\",\n        \"Text Generation\",\n        \"Text-to-Image"
"```json\n{\n  \"task_steps\": [\n    \"Load the example.jpg image into memory.\",\n    \"Perform object detection on the image using Object Detection task.\",\n    \"Extract the labels of the detected objects.\",\n    \"Invoke Text-to-Speech task to convert the labels into speech.\",\n    \"Record the speech output.\",\n    \"Invoke Automatic Speech Recognition task to transcribe the recorded speech back into text.\"\n  ],\n  \"task_nodes\": [\n    \"Object Detection\",\n    \"Text-to-Speech\",\n    \"Automatic Speech Recognition\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Object Detection\", \"target\": \"Text-to-Speech\"},\n    {\"source\": \"Text-to-Speech\", \"target\": \"Automatic Speech Recognition\"}\n  ]\n}\n```"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Load the image 'example.jpg' for image processing.\"\n        },\n        {\n            \"step_description\": \"Perform object detection on the image to identify and extract cars.\"\n        },\n        {\n            \"step_description\": \"Remove the cars from the image using image editing techniques.\"\n        },\n        {\n            \"step_description\": \"Perform image-to-image translation to replace cars with trees.\"\n        },\n        {\n            \"step_description\": \"Save the modified image for further analysis.\"\n        },\n        {\n            \"step_description\": \"Load the modified image for text-to-image generation to create a caption describing the number of trees in the image.\"\n        },\n        {\n            \"step_description\": \"Perform text-to-image generation to create a caption describing the number of trees in the modified image.\"\n        },\n        {\n            \"step_description\": \"Perform text-to-speech synthesis to read out the caption.\"\n        },\n        {\n            \"step_description\": \"Perform automatic speech recognition to extract the number of trees from the spoken text.\"\n        },\n        {\n            \"step_description\": \"Return the number of trees identified in the modified image.\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Image Classification\",\n        \"Object Detection\",\n        \"Image Editing\",\n        \"Image-to-Image\",\n        \"Text-to-Image\",\n        \"Text-to-Speech\",\n        \"Automatic Speech Recognition\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Image Classification\", \"target\": \"Object Detection\"},\n"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Perform text-to-event extraction to identify important dates, names, and places from the given passage.\"\n        },\n        {\n            \"step_description\": \"Perform text summarization to generate a concise summary of the given passage.\"\n        },\n        {\n            \"step_description\": \"Invoke a text-to-speech API to read the original passage for better understanding.\"\n        },\n        {\n            \"step_description\": \"Invoke a text-to-French translation API to translate the summarized text into French.\"\n        },\n        {\n            \"step_description\": \"Invoke a text-to-text generation API to generate a new text based on the identified important information.\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Text-to-Event Extraction\",\n        \"Text Summarization\",\n        \"Text-to-Speech\",\n        \"Text-to-French Translation\",\n        \"Text Generation\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Text-to-Event Extraction\", \"target\": \"Text Summarization\"},\n        {\"source\": \"Text Summarization\", \"target\": \"Text-to-Speech\"},\n        {\"source\": \"Text Summarization\", \"target\": \"Text Generation\"},\n        {\"source\": \"Text Summarization\", \"target\": \"Text-to-French Translation\"},\n        {\"source\": \"Text-to-Speech\", \"target\": \"Text Generation\"},\n        {\"source\": \"Text-to-Speech\", \"target\": \"Text-to-French Translation\"},\n        {\"source\": \"Text-to-French Translation\", \"target\": \"Text"
"{\n  \"task_steps\": [\n    \"Load the image 'example.jpg' for image processing.\",\n    \"Perform image enhancement to improve the quality of 'example.jpg'.\",\n    \"Perform image-to-text conversion to extract text data from the enhanced image.\",\n    \"Perform text preprocessing to clean and format the extracted text data.\",\n    \"Perform table classification to identify the table in the text data.\",\n    \"Perform text-based table data extraction to extract the revenue data from the classified table.\",\n    \"Perform text-to-number conversion to extract the numerical revenue data.\",\n    \"Filter the revenue data to extract the data for the year 2021.\",\n    \"Summarize the extracted revenue data to provide the total revenue for the year 2021.\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image Enhancement\"\n    },\n    {\n      \"task_name\": \"Image-to-Text Conversion\"\n    },\n    {\n      \"task_name\": \"Text Preprocessing\"\n    },\n    {\n      \"task_name\": \"Table Classification\"\n    },\n    {\n      \"task_name\": \"Text-based Table Data Extraction\"\n    },\n    {\n      \"task_name\": \"Text-to-Number Conversion\"\n    },\n    {\n      \"task_name\": \"Filter Revenue Data\"\n    },\n    {\n      \"task_name\": \"Summarize Revenue Data\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Enhancement\", \"target\": \"Image-to-Text Conversion\"},\n    {\"source\": \"Image-to-Text Con"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Perform text summarization to extract the key points from the given text.\",\n            \"task_name\": \"Text Summarization\"\n        },\n        {\n            \"step_description\": \"Identify the main keywords in the summarized text.\",\n            \"task_name\": \"Keywords Extraction\"\n        },\n        {\n            \"step_description\": \"Perform image-to-text conversion to extract textual information from the example.jpg image.\",\n            \"task_name\": \"Image-to-Text\"\n        },\n        {\n            \"step_description\": \"Modify the colors of the objects in the extracted text based on the information from the image.\",\n            \"task_name\": \"Text-to-Image\"\n        },\n        {\n            \"step_description\": \"Perform image segmentation to identify and extract the objects in the example.jpg image.\",\n            \"task_name\": \"Image Segmentation\"\n        },\n        {\n            \"step_description\": \"Identify the objects in the segmented image and map them to the corresponding colors in the text.\",\n            \"task_name\": \"Object Detection\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Text Summarization\",\n        \"Keywords Extraction\",\n        \"Image-to-Text\",\n        \"Text-to-Image\",\n        \"Image Segmentation\",\n        \"Object Detection\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Text Summarization\", \"target\": \"Keywords Extraction\"},\n        {\"source\": \"Text Summarization\", \"target\": \"Image-to-Text\"},\n        {\"source\": \"Image-to-"
"```json\n{\n  \"task_steps\": [\n    \"Load and preprocess 'example.jpg' for text extraction.\",\n    \"Perform Optical Character Recognition (OCR) on the preprocessed image to extract text.\",\n    \"Perform Text-to-Document question answering to determine the main topic of the document.\",\n    \"Generate an image based on the main topic using Text-to-Image API.\",\n    \"Segment the generated image using Image Segmentation API.\",\n    \"Extract text from the segmented image using OCR.\"\n  ],\n  \"task_nodes\": [\n    \"Image-to-Text (OCR)\",\n    \"Text-to-Document Question Answering\",\n    \"Text-to-Image\",\n    \"Image Segmentation\",\n    \"OCR (for segmented image)\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image-to-Text (OCR)\", \"target\": \"Text-to-Document Question Answering\"},\n    {\"source\": \"Text-to-Document Question Answering\", \"target\": \"Text-to-Image\"},\n    {\"source\": \"Text-to-Image\", \"target\": \"Image Segmentation\"},\n    {\"source\": \"Image Segmentation\", \"target\": \"OCR (for segmented image)\"},\n    {\"source\": \"Text-to-Document Question Answering\", \"target\": \"Text-to-Image\"},\n    {\"source\": \"OCR (for segmented image)\", \"target\": \"Output\"}\n  ]\n}\n```\n\nThis JSON format represents the task steps, task nodes, and task links required to fulfill the user's request. The task steps are described in detail, and the task nodes represent the APIs that need to be invoked in sequence"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Load the text file 'example.txt' and extract the description or caption for the image to be generated.\",\n            \"task_name\": \"Text-to-Image\"\n        },\n        {\n            \"step_description\": \"Generate an image based on the extracted description or caption.\",\n            \"task_name\": \"Text-to-Image\"\n        },\n        {\n            \"step_description\": \"Load the text file 'example_target.txt' and extract the target category.\",\n            \"task_name\": \"Text-Processing\"\n        },\n        {\n            \"step_description\": \"Perform Image-to-Text task to extract features from the generated image.\",\n            \"task_name\": \"Image-to-Text\"\n        },\n        {\n            \"step_description\": \"Perform Text Similarity task to compare the extracted features from the generated image and the target category.\",\n            \"task_name\": \"Text Similarity\"\n        },\n        {\n            \"step_description\": \"Return the similarity score between the generated image and the target category.\",\n            \"task_name\": \"Result Generation\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Text-to-Image\",\n        \"Text-Processing\",\n        \"Image-to-Text\",\n        \"Text Similarity\",\n        \"Result Generation\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Text-to-Image\", \"target\": \"Image-to-Text\"},\n        {\"source\": \"Text-Processing\", \"target\": \"Text Similarity\"},\n        {\"source\": \"Image-to-Text\", \"target\": \"Text Similarity\"},\n        {\"source\": \"Text-"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"The user has provided an image and a question. The first step is to perform an Image-to-Text task to extract text from the image that may contain the answer to the user's question.\",\n            \"task_name\": \"Image-to-Text\"\n        },\n        {\n            \"step_description\": \"Next, the extracted text will be processed using a Text-to-Question Answering task to identify the answer to the user's question.\",\n            \"task_name\": \"Text-to-Question Answering\"\n        },\n        {\n            \"step_description\": \"Once the answer has been identified, a Text-to-Speech task will be used to generate an audio response for the user.\",\n            \"task_name\": \"Text-to-Speech\"\n        },\n        {\n            \"step_description\": \"Finally, a Conversational task will be used to generate a conversation between the user and the AI assistant to provide the answer and the audio response.\",\n            \"task_name\": \"Conversational\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Image-to-Text\",\n        \"Text-to-Question Answering\",\n        \"Text-to-Speech\",\n        \"Conversational\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Image-to-Text\", \"target\": \"Text-to-Question Answering\"},\n        {\"source\": \"Text-to-Question Answering\", \"target\": \"Text-to-Speech\"},\n        {\"source\": \"Text-to-Question Answering\", \"target\": \"Conversational\"},\n        {\"source\": \"Text-to-Speech\", \""
"```json\n{\n  \"task_steps\": [\n    \"Load the audio file 'example.wav'\",\n    \"Apply audio enhancement techniques to improve the audio quality\",\n    \"Perform Automatic Speech Recognition (ASR) to transcribe the enhanced audio\",\n    \"Classify the transcribed command using Text Classification\",\n    \"Load the document 'instructions.txt'\",\n    \"Use Text-to-Speech to read the document and compare it with the transcribed command\",\n    \"Use Document Question Answering to find the corresponding explanation in the document\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Audio Enhancement\"\n    },\n    {\n      \"task_name\": \"Automatic Speech Recognition\"\n    },\n    {\n      \"task_name\": \"Text Classification\"\n    },\n    {\n      \"task_name\": \"Text-to-Speech\"\n    },\n    {\n      \"task_name\": \"Document Question Answering\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Audio Enhancement\", \"target\": \"Automatic Speech Recognition\"},\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text Classification\"},\n    {\"source\": \"Text Classification\", \"target\": \"Text-to-Speech\"},\n    {\"source\": \"Text-to-Speech\", \"target\": \"Document Question Answering\"}\n  ]\n}\n```"
"{\n    \"task_steps\": [\n        \"Load 'example.wav' audio file\",\n        \"Apply audio enhancement techniques to improve the quality of the audio\",\n        \"Perform Automatic Speech Recognition (ASR) on the enhanced audio to extract text\",\n        \"Analyze the extracted text to identify and extract speaker's emotion\",\n        \"Generate a related text prompt based on the speaker's emotion and the given image 'example.jpg'\",\n        \"Load 'example.jpg' image file\",\n        \"Edit the image based on the generated text prompt\",\n        \"Identify objects in the edited image\",\n        \"Compare the identified objects with the given text 'birthday party'\",\n        \"Determine the similarities between the identified objects and the given text\"\n    ],\n    \"task_nodes\": [\n        {\n            \"task_name\": \"Audio Enhancement\"\n        },\n        {\n            \"task_name\": \"Automatic Speech Recognition\"\n        },\n        {\n            \"task_name\": \"Text Extraction\"\n        },\n        {\n            \"task_name\": \"Emotion Analysis\"\n        },\n        {\n            \"task_name\": \"Text Generation\"\n        },\n        {\n            \"task_name\": \"Image Loading\"\n        },\n        {\n            \"task_name\": \"Image Editing\"\n        },\n        {\n            \"task_name\": \"Object Detection\"\n        },\n        {\n            \"task_name\": \"Text-to-Image Similarity\"\n        }\n    ],\n    \"task_links\": [\n        {\"source\": \"Load 'example.wav' audio file\", \"target\": \"Apply audio enhancement techniques to improve the quality of the audio\"},\n       "
"{\n  \"task_steps\": [\n    \"Load user input text: 'The Eiffel Tower is an iron lattice tower located on the Champ de Mars in Paris, France. It is named after the engineer Gustave Eiffel, whose company designed and built the tower.'\",\n    \"Translate user input text to French using Translation task\",\n    \"Store translated text: 'La Tour Eiffel est une tour en fer \u00e0 mailles situ\u00e9e sur le Champ de Mars \u00e0 Paris, France. Elle est nomm\u00e9e d'apr\u00e8s l'ing\u00e9nieur Gustave Eiffel, dont l'entreprise a con\u00e7u et construit la tour.'\",\n    \"Use Question Answering task to extract answer to question: 'Quel est le nom de l'ing\u00e9nieur qui a con\u00e7u la Tour Eiffel?' from the translated text\",\n    \"Store answer: 'Gustave Eiffel'\",\n    \"Use Text-to-Image task to generate an image based on the answer 'Gustave Eiffel'\",\n    \"Store generated image\",\n    \"Use Tabular Classification task to classify the generated image\",\n    \"Store classification result\",\n    \"Use Sentence Similarity task to check the similarity between the original question and the classification result\"\n  ],\n  \"task_nodes\": [\n    \"Translation\",\n    \"Question Answering\",\n    \"Text-to-Image\",\n    \"Tabular Classification\",\n    \"Sentence Similarity\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Translation\", \"target\": \"Question Answering\"},\n    {\"source\": \"Question Answering\", \"target\": \"Text-to-Image\"},\n    {\"source\": \"Text-to-Image\", \"target\": \"Tabular Classification"
"{\n  \"task_steps\": [\n    \"Load 'example.wav' audio file for audio improvement\",\n    \"Apply audio denoising and equalization to improve audio quality\",\n    \"Save improved audio as 'example_improved.wav'\",\n    \"Load 'example.wav' and 'example_improved.wav' for speech recognition\",\n    \"Perform Automatic Speech Recognition (ASR) on both audio files to generate text transcripts\",\n    \"Compare transcripts to identify and correct any discrepancies\",\n    \"Save final text transcript as 'example_transcript.txt'\",\n    \"Load 'example.jpg' document image for text extraction\",\n    \"Perform Optical Character Recognition (OCR) on document image to extract text\",\n    \"Load 'example_transcript.txt' and extracted text for question answering\",\n    \"Perform Document Question Answering (DQA) to identify and extract answer to question: 'What was the most important event mentioned in the interview?'\",\n    \"Save answer as 'example_answer.txt'\"\n  ],\n  \"task_nodes\": [\n    \"Audio Improvement: Audio Denoising and Equalization\",\n    \"Speech Recognition: Automatic Speech Recognition\",\n    \"Text Extraction: Optical Character Recognition\",\n    \"Question Answering: Document Question Answering\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Audio Improvement: Load audio file\", \"target\": \"Audio Improvement: Audio Denoising and Equalization\"},\n    {\"source\": \"Speech Recognition: Load audio files\", \"target\": \"Speech Recognition: Automatic Speech Recognition\"},\n   "
"```json\n{\n  \"task_steps\": [\n    \"Load the image 'example.jpg'\",\n    \"Perform Object Detection on the image to identify objects and their locations\",\n    \"Use Visual Question Answering to determine what is happening in the image based on the identified objects\",\n    \"Generate a short related text summary of the event using Text Summarization\",\n    \"Convert the text summary to speech using Text-to-Speech\",\n    \"Classify the audio content using Automatic Speech Recognition and Audio Classification\"\n  ],\n  \"task_nodes\": [\n    \"Object Detection\",\n    \"Visual Question Answering\",\n    \"Text Summarization\",\n    \"Text-to-Speech\",\n    \"Automatic Speech Recognition\",\n    \"Audio Classification\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Object Detection\", \"target\": \"Visual Question Answering\"},\n    {\"source\": \"Visual Question Answering\", \"target\": \"Text Summarization\"},\n    {\"source\": \"Text Summarization\", \"target\": \"Text-to-Speech\"},\n    {\"source\": \"Text-to-Speech\", \"target\": \"Automatic Speech Recognition\"},\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Audio Classification\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load the 'example.jpg' image and apply a stylization filter to create a new image.\",\n    \"Extract any text present in the stylized image using Optical Character Recognition (OCR) technology.\",\n    \"Generate a conversational response based on the extracted text using a conversational AI model.\",\n    \"Edit the stylized image according to the generated response.\",\n    \"Estimate the depth of objects in the edited image using a depth estimation model.\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image Editing\",\n      \"input\": {\n        \"image_path\": \"example.jpg\"\n      },\n      \"output\": {\n        \"edited_image_path\": \"\"\n      }\n    },\n    {\n      \"task_name\": \"Text Extraction\",\n      \"input\": {\n        \"image_path\": \"{edited_image_path_from_previous_task}\"\n      },\n      \"output\": {\n        \"extracted_text\": \"\"\n      }\n    },\n    {\n      \"task_name\": \"Text-to-Speech\",\n      \"input\": {\n        \"text\": \"{extracted_text_from_previous_task}\"\n      },\n      \"output\": {\n        \"audio\": \"\"\n      }\n    },\n    {\n      \"task_name\": \"Image Editing\",\n      \"input\": {\n        \"image_path\": \"{edited_image_path_from_first_task}\",\n        \"instructions\": \"{generated_response_from_previous_task}\"\n      },\n      \"output\": {\n        \"edited_image_path\": \"\"\n      }\n   "
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Understand the user's request and extract necessary information: 'What is global warming and how does it affect the Earth?'\"\n        },\n        {\n            \"step_description\": \"Perform Text-to-Video task to create an animated video explaining the concept of global warming.\"\n        },\n        {\n            \"step_description\": \"Perform Text-to-Speech task to generate an audio narration for the video.\"\n        },\n        {\n            \"step_description\": \"Perform Question Answering task to gather information about the causes and effects of global warming.\"\n        },\n        {\n            \"step_description\": \"Perform Text Summarization task to create concise summaries of the gathered information.\"\n        },\n        {\n            \"step_description\": \"Combine the summaries, animations, and narration to create the final video.\"\n        }\n    ],\n    \"task_nodes\": [\n        {\n            \"task_name\": \"Text-to-Video\"\n        },\n        {\n            \"task_name\": \"Text-to-Speech\"\n        },\n        {\n            \"task_name\": \"Question Answering\"\n        },\n        {\n            \"task_name\": \"Text Summarization\"\n        },\n        {\n            \"task_name\": \"Video Editing\"\n        }\n    ],\n    \"task_links\": [\n        {\n            \"source\": \"Question Answering\",\n            \"target\": \"Text Summarization\"\n        },\n        {\n            \"source\": \"Text Summarization\",\n            \"target\": \"Video Editing\"\n        },\n        {\n            \"source\": \"Text"
"```json\n{\n  \"task_steps\": [\n    \"Load the example.wav audio file\",\n    \"Perform Automatic Speech Recognition (ASR) on the audio file to extract text from the speaker's emotion expression\",\n    \"Use Emotion Recognition model for Speaker Emotion Determination\",\n    \"Generate an audio response acknowledging the speaker's emotion using Text-to-Speech (TTS) model\",\n    \"Transcribe the generated audio response using ASR\",\n    \"Perform Question Answering on the document 'What are the benefits of expressing emotions?' using the transcribed text\",\n    \"Generate a video based on the Question Answering result using Text-to-Video model\"\n  ],\n  \"task_nodes\": [\n    \"Automatic Speech Recognition\",\n    \"Emotion Recognition\",\n    \"Text-to-Speech\",\n    \"Question Answering\",\n    \"Text-to-Video\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Emotion Recognition\"},\n    {\"source\": \"Emotion Recognition\", \"target\": \"Text-to-Speech\"},\n    {\"source\": \"Text-to-Speech\", \"target\": \"Automatic Speech Recognition\"},\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Question Answering\"},\n    {\"source\": \"Question Answering\", \"target\": \"Text-to-Video\"}\n  ]\n}\n```"
"{\n    \"task_steps\": [\n        \"Load 'example.jpg' image into memory.\",\n        \"Parse text description: 'Change the color of the car to blue and the background to a cityscape'.\",\n        \"Identify the car and its color in the image using Object Detection and Image Segmentation.\",\n        \"Change the color of the identified car to blue using Image Editing.\",\n        \"Generate a cityscape background using Text-to-Image.\",\n        \"Merge the edited car and the generated cityscape background into a single image using Image Editing.\",\n        \"Estimate the depths of objects in the edited image using Depth Estimation.\",\n        \"Classify the edited image using Image Classification.\",\n        \"Summarize the classification result into a short text using Text Summarization.\",\n        \"Generate a new image based on the summarized text using Text-to-Image.\",\n        \"Adapt the generated image to match the characteristics of the example image using Image Adaptation.\"\n    ],\n    \"task_nodes\": [\n        \"Image Classification\",\n        \"Text Summarization\",\n        \"Text-to-Image\",\n        \"Image Editing\",\n        \"Object Detection\",\n        \"Image Segmentation\",\n        \"Depth Estimation\",\n        \"Image Adaptation\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Image Classification\", \"target\": \"Text Summarization\"},\n        {\"source\": \"Text Summarization\", \"target\": \"Text-to-Image\"},\n        {\"source\": \"Text-to-Image\", \"target\": \"Image Editing\"},\n        {\"source\": \"Image Editing\", \"target\": \"Depth Estimation\"},\n        {\"source\": \"Depth Estimation\", \"target\": \"Image Classification\"},\n        {\""
"{\n  \"task_steps\": [\n    \"Identify the type and size of the coffee stain on the white shirt.\",\n    \"Pre-treat the coffee stain with a suitable stain remover, such as dish soap or a commercial stain remover.\",\n    \"Apply the stain remover to the coffee stain and let it sit for a few minutes.\",\n    \"Rinse the shirt with cold water to remove the stain remover and the coffee stain.\",\n    \"Wash the shirt in the washing machine with cold water and a gentle cycle.\",\n    \"Check if the coffee stain has been completely removed. If not, repeat the process.\",\n    \"Dry the shirt using the lowest heat setting or air dry to prevent setting any remaining stain.\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Text-to-Question\",\n      \"input\": \"How can I remove a coffee stain from my white shirt?\"\n    },\n    {\n      \"task_name\": \"Image Classification\",\n      \"input\": \"image of coffee stain on white shirt\"\n    },\n    {\n      \"task_name\": \"Tabular Classification\",\n      \"input\": \"Output from Image Classification\"\n    },\n    {\n      \"task_name\": \"Text Generation\",\n      \"input\": \"Type and size of the coffee stain\"\n    },\n    {\n      \"task_name\": \"Text-to-Speech\",\n      \"input\": \"Identify the type and size of the coffee stain on the white shirt.\"\n    },\n    {\n      \"task_name\": \"Text-to-Text\",\n      \"input\": \"Pre-treat the coffee stain with a suitable stain remover.\",\n      \"output\": \"Apply a stain remover to the coffee stain.\"\n    },"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Load the English introduction text for the keynote speaker.\"\n        },\n        {\n            \"step_description\": \"Perform Text-to-Speech synthesis to create an audio version of the English text for the opening speech.\"\n        },\n        {\n            \"step_description\": \"Invoke Text Classification API to identify the text genre and ensure it is suitable for the opening speech.\"\n        },\n        {\n            \"step_description\": \"Invoke Translation API to translate the English text into French.\"\n        },\n        {\n            \"step_description\": \"Invoke Question Answering API to extract the keynote speaker's main achievements in ancient language research from the translated text.\"\n        },\n        {\n            \"step_description\": \"Invoke Text Summarization API to create a summarized version of the answer.\"\n        },\n        {\n            \"step_description\": \"Invoke Sentence Similarity API to compare the similarity between the original English text and the summarized version.\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Text-to-Speech\",\n        \"Text Classification\",\n        \"Translation\",\n        \"Question Answering\",\n        \"Text Summarization\",\n        \"Sentence Similarity\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Text-to-Speech\", \"target\": \"Text Classification\"},\n        {\"source\": \"Text Classification\", \"target\": \"Translation\"},\n        {\"source\": \"Translation\", \"target\": \"Question Answering\"},\n        {\"source\": \"Question Answering\", \"target\": \"Text Summarization\"},\n        {\"source\": \"Text Summarization\", \"target\": \"Sentence Similar"
"```json\n{\n  \"task_steps\": [\n    \"Load 'example.jpg' image and perform Object Detection to identify table in the image.\",\n    \"Perform Tabular Classification on the identified table to classify the data.\",\n    \"Extract information about the classified data.\",\n    \"Generate answer to the question 'What is the significance of the data?' based on the extracted information.\",\n    \"Perform Text Classification on the generated answer to ensure its accuracy and relevance.\",\n    \"Perform Machine Translation to translate the answer into French.\"\n  ],\n  \"task_nodes\": [\n    \"Image-to-Object Detection\",\n    \"Tabular Classification\",\n    \"Data Extraction\",\n    \"Question Answering\",\n    \"Text Classification\",\n    \"Text Translation\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image-to-Object Detection\", \"target\": \"Tabular Classification\"},\n    {\"source\": \"Tabular Classification\", \"target\": \"Data Extraction\"},\n    {\"source\": \"Data Extraction\", \"target\": \"Question Answering\"},\n    {\"source\": \"Question Answering\", \"target\": \"Text Classification\"},\n    {\"source\": \"Text Classification\", \"target\": \"Text Translation\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load 'example.jpg' image\",\n    \"Perform Image Classification on 'example.jpg'\",\n    \"Based on the class label, generate a new image\",\n    \"Perform Image-to-Image translation to generate new image\",\n    \"Perform Image Segmentation on the new image\",\n    \"Determine the largest object in the segmented image\",\n    \"Perform Text-to-Speech conversion of the largest object label\",\n    \"Perform Audio Enhancement on the speech output\",\n    \"Perform Audio Classification on the enhanced speech audio\",\n    \"Perform Emotion Detection on the audio classification result\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image Classification\"\n    },\n    {\n      \"task_name\": \"Image-to-Image translation\"\n    },\n    {\n      \"task_name\": \"Image Segmentation\"\n    },\n    {\n      \"task_name\": \"Text-to-Speech\"\n    },\n    {\n      \"task_name\": \"Audio Enhancement\"\n    },\n    {\n      \"task_name\": \"Audio Classification\"\n    },\n    {\n      \"task_name\": \"Emotion Detection\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification\", \"target\": \"Image-to-Image translation\"},\n    {\"source\": \"Image-to-Image translation\", \"target\": \"Image Segmentation\"},\n    {\"source\": \"Image Segmentation\", \"target\": \"Determine largest object\"},\n    {\"source\": \"Determine largest object\", \"target\": \"Text-to-Speech"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Load the example image for further processing.\",\n            \"task_name\": \"Image Classification\"\n        },\n        {\n            \"step_description\": \"Classify the example image to ensure it represents a cityscape.\",\n            \"task_name\": \"Image Classification\"\n        },\n        {\n            \"step_description\": \"Generate a cityscape image with a sunset background using a text-to-image model.\",\n            \"task_name\": \"Text-to-Image\"\n        },\n        {\n            \"step_description\": \"Classify the generated image to ensure it represents a cityscape at sunset.\",\n            \"task_name\": \"Image Classification\"\n        },\n        {\n            \"step_description\": \"Compare the generated image with the example image to ensure similarity.\",\n            \"task_name\": \"Image Similarity\"\n        },\n        {\n            \"step_description\": \"Determine if the generated image represents a cityscape at sunset based on the classification results and image similarity.\",\n            \"task_name\": \"Question Answering\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Image Classification\",\n        \"Text-to-Image\",\n        \"Image Classification\",\n        \"Image Similarity\",\n        \"Question Answering\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Image Classification\", \"target\": \"Text-to-Image\"},\n        {\"source\": \"Text-to-Image\", \"target\": \"Image Classification\"},\n        {\"source\": \"Image Classification\", \"target\": \"Image Similarity\"},\n        {\"source\": \"Image Classification\", \"target\": \"Question Answering\"},\n        {\""
"```json\n{\n  \"task_steps\": [\n    \"Load the image 'example.jpg'\",\n    \"Perform Object Detection on the loaded image to identify main objects\",\n    \"Classify the type of scenery in the image using Image Classification\",\n    \"Translate the scenery classification result from English to French using Translation\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Object Detection\"\n    },\n    {\n      \"task_name\": \"Image Classification\"\n    },\n    {\n      \"task_name\": \"Translation\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Object Detection\", \"target\": \"Image Classification\"},\n    {\"source\": \"Image Classification\", \"target\": \"Translation\"}\n  ]\n}\n```"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Perform document question answering to extract the answer to the question 'What animal has black and white fur and eats bamboo?' from the given document.\"\n        },\n        {\n            \"step_description\": \"Invoke Text-to-Speech API to read out the extracted answer.\"\n        },\n        {\n            \"step_description\": \"Perform image search using the extracted animal name to find an image representing the animal.\"\n        },\n        {\n            \"step_description\": \"Invoke Image-to-Text API to extract a description from the image.\"\n        },\n        {\n            \"step_description\": \"Invoke Text-to-Speech API to read out the description of the image.\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Document Question Answering\",\n        \"Text-to-Speech (for answer)\",\n        \"Image Search\",\n        \"Image-to-Text\",\n        \"Text-to-Speech (for image description)\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Document Question Answering\", \"target\": \"Text-to-Speech (for answer)\"},\n        {\"source\": \"Text-to-Speech (for answer)\", \"target\": \"Image Search\"},\n        {\"source\": \"Image Search\", \"target\": \"Image-to-Text\"},\n        {\"source\": \"Image-to-Text\", \"target\": \"Text-to-Speech (for image description)\"},\n    ]\n}"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Perform image classification to identify the image as containing a table.\",\n            \"task_name\": \"Image Classification\"\n        },\n        {\n            \"step_description\": \"Perform object detection to locate and extract the table from the image.\",\n            \"task_name\": \"Object Detection\"\n        },\n        {\n            \"step_description\": \"Perform tabular classification to extract and understand the data in the table, including the scientific names of the plants.\",\n            \"task_name\": \"Tabular Classification\"\n        },\n        {\n            \"step_description\": \"Generate a text summary of the extracted data.\",\n            \"task_name\": \"Summarization\"\n        },\n        {\n            \"step_description\": \"Convert the text summary into synthesized audio.\",\n            \"task_name\": \"Text-to-Speech\"\n        },\n        {\n            \"step_description\": \"Generate a conversational response to confirm the summary.\",\n            \"task_name\": \"Conversational\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Image Classification\",\n        \"Object Detection\",\n        \"Tabular Classification\",\n        \"Summarization\",\n        \"Text-to-Speech\",\n        \"Conversational\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Image Classification\", \"target\": \"Object Detection\"},\n        {\"source\": \"Object Detection\", \"target\": \"Tabular Classification\"},\n        {\"source\": \"Tabular Classification\", \"target\": \"Summarization\"},\n        {\"source\": \"Summarization\", \"target\": \"Text-to-Speech\"},\n        {\"source\": \"Text"
"{\n  \"task_steps\": [\n    \"Load the image 'example.jpg'\",\n    \"Perform Object Detection to identify the object in the center of the image\",\n    \"Extract the dominant color of the identified object using Image Classification\",\n    \"Store the main color of the object\",\n    \"Load the main color of the object into memory\",\n    \"Use Text-to-Speech to pronounce the main color in English\",\n    \"Use Automatic Speech Recognition to convert the spoken English into text\",\n    \"Use Machine Translation to translate the text into French\",\n    \"Use Text Summarization to generate a concise summary of the translated text\",\n    \"Store the summarized French answer\",\n    \"Use Text-to-Speech to pronounce the summarized French answer\"\n  ],\n  \"task_nodes\": [\n    \"Image Classification\",\n    \"Object Detection\",\n    \"Text-to-Speech (English)\",\n    \"Automatic Speech Recognition\",\n    \"Machine Translation\",\n    \"Text Summarization\",\n    \"Text-to-Speech (French)\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Object Detection\", \"target\": \"Image Classification\"},\n    {\"source\": \"Text-to-Speech (English)\", \"target\": \"Automatic Speech Recognition\"},\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Machine Translation\"},\n    {\"source\": \"Machine Translation\", \"target\": \"Text Summarization\"},\n    {\"source\": \"Text Summarization\", \"target\": \"Text-to-Speech (French)\"},\n  ]\n}"
"```json\n{\n  \"task_steps\": [\n    \"Load the 'example.jpg' image into memory.\",\n    \"Perform object detection on the loaded image using Object Detection task.\",\n    \"Extract the bounding boxes and object labels from the Object Detection task output.\",\n    \"Filter the output to keep only the cars.\",\n    \"Change the color of each car in the image using Image Editing task.\",\n    \"Specify the new color as red.\",\n    \"Perform image classification on the edited image using Image Classification task.\",\n    \"Extract the scene type label from the Image Classification task output.\"\n  ],\n  \"task_nodes\": [\n    \"Object Detection\",\n    \"Image Editing\",\n    \"Image Classification\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification\", \"target\": \"Image Editing\"},\n    {\"source\": \"Image Editing\", \"target\": \"Object Detection\"},\n    {\"source\": \"Object Detection\", \"target\": \"Image Editing\"}\n  ]\n}\n```"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Perform image-to-text conversion to extract text from the French document image.\",\n            \"task_name\": \"Image-to-Text\"\n        },\n        {\n            \"step_description\": \"Perform text-to-language translation to convert the extracted text from French to English.\",\n            \"task_name\": \"Translation\"\n        },\n        {\n            \"step_description\": \"Perform text summarization to extract the key information about people and their appointments.\",\n            \"task_name\": \"Summarization\"\n        },\n        {\n            \"step_description\": \"Perform named entity recognition to identify and extract the names of the people mentioned.\",\n            \"task_name\": \"Token Classification\"\n        },\n        {\n            \"step_description\": \"Perform date extraction to identify and extract the dates of the appointments.\",\n            \"task_name\": \"Question Answering\"\n        },\n        {\n            \"step_description\": \"Generate a summarized answer in English.\",\n            \"task_name\": \"Text Generation\"\n        }\n    ],\n    \"task_nodes\": [\n        {\n            \"task_name\": \"Image-to-Text\"\n        },\n        {\n            \"task_name\": \"Translation\"\n        },\n        {\n            \"task_name\": \"Summarization\"\n        },\n        {\n            \"task_name\": \"Token Classification\"\n        },\n        {\n            \"task_name\": \"Question Answering\"\n        },\n        {\n            \"task_name\": \"Text Generation\"\n        }\n    ],\n    \"task_links\": [\n        {\n            \"source\": \"Image-to-"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Load the document image and perform Optical Character Recognition (OCR) to extract text from it.\",\n            \"task_name\": \"Document Question Answering\"\n        },\n        {\n            \"step_description\": \"Identify and extract answers to given questions from the extracted text.\",\n            \"task_name\": \"Question Answering\"\n        },\n        {\n            \"step_description\": \"Perform Named Entity Recognition (NER) on the identified answers to extract specific entities.\",\n            \"task_name\": \"Text Classification\"\n        },\n        {\n            \"step_description\": \"Load the audio file and perform Automatic Speech Recognition (ASR) to extract text from it.\",\n            \"task_name\": \"Automatic Speech Recognition\"\n        },\n        {\n            \"step_description\": \"Identify and extract answers to given questions from the ASR text.\",\n            \"task_name\": \"Question Answering\"\n        },\n        {\n            \"step_description\": \"Perform Named Entity Recognition (NER) on the identified answers.\",\n            \"task_name\": \"Text Classification\"\n        },\n        {\n            \"step_description\": \"Generate a summary of the extracted answers.\",\n            \"task_name\": \"Text Summarization\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Document Question Answering\",\n        \"Text Classification\",\n        \"Automatic Speech Recognition\",\n        \"Question Answering\",\n        \"Text Classification\",\n        \"Text Summarization\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Document Question Answering\","
"```json\n{\n  \"task_steps\": [\n    \"Load the audio file 'example.wav'\",\n    \"Perform Automatic Speech Recognition (ASR) to transcribe the audio to text\",\n    \"Parse the transcribed text to identify relevant tokens related to image edits\",\n    \"Load the image file 'example.jpg'\",\n    \"Perform Text-to-Image editing based on the identified tokens\"\n  ],\n  \"task_nodes\": [\n    \"Automatic Speech Recognition\",\n    \"Text Parsing\",\n    \"Text-to-Image Editing\",\n    \"Image Loading\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Load the audio file\", \"target\": \"Perform Automatic Speech Recognition\"},\n    {\"source\": \"Perform Automatic Speech Recognition\", \"target\": \"Parse the transcribed text\"},\n    {\"source\": \"Parse the transcribed text\", \"target\": \"Load the image file\"},\n    {\"source\": \"Load the image file\", \"target\": \"Perform Text-to-Image editing\"}\n  ]\n}\n```"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Text-to-Speech: Convert the given text 'The quick brown fox jumps over the lazy dog.' into speech using a Text-to-Speech model.\",\n            \"task_name\": \"Text-to-Speech\"\n        },\n        {\n            \"step_description\": \"Audio Enhancement: Apply audio enhancement techniques to improve the quality of the generated speech.\",\n            \"task_name\": \"Audio Editing\"\n        },\n        {\n            \"step_description\": \"Automatic Speech Recognition: Convert the enhanced speech back into text for comparison.\",\n            \"task_name\": \"Automatic Speech Recognition\"\n        },\n        {\n            \"step_description\": \"Text Comparison: Compare the original text 'The quick brown fox jumps over the lazy dog.' with the transcribed text from the Automatic Speech Recognition step to ensure the message is clear.\",\n            \"task_name\": \"Text Comparison\"\n        },\n        {\n            \"step_description\": \"Audio Classification: Classify the enhanced audio to ensure the quality is satisfactory.\",\n            \"task_name\": \"Audio Classification\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Text-to-Speech\",\n        \"Audio Editing\",\n        \"Automatic Speech Recognition\",\n        \"Text Comparison\",\n        \"Audio Classification\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Text-to-Speech\", \"target\": \"Audio Editing\"},\n        {\"source\": \"Audio Editing\", \"target\": \"Automatic Speech Recognition\"},\n        {\"source\": \"Automatic Speech Recognition"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Load the text document 'text_history.txt' for text data.\",\n            \"task_name\": \"Text Classification\"\n        },\n        {\n            \"step_description\": \"Perform named entity recognition and extract key historical facts related to the Eiffel Tower.\",\n            \"task_name\": \"Named Entity Recognition and Fact Extraction\"\n        },\n        {\n            \"step_description\": \"Load the image 'example.jpg' for image data.\",\n            \"task_name\": \"Image Classification\"\n        },\n        {\n            \"step_description\": \"Perform object detection to identify the Eiffel Tower in the image.\",\n            \"task_name\": \"Object Detection\"\n        },\n        {\n            \"step_description\": \"Compare the extracted historical facts with the image data to understand the connection.\",\n            \"task_name\": \"Text-to-Image Alignment\"\n        },\n        {\n            \"step_description\": \"Load the document image 'example.png' for text data.\",\n            \"task_name\": \"Document Question Answering\"\n        },\n        {\n            \"step_description\": \"Extract a question from the brochure.\",\n            \"task_name\": \"Question Extraction\"\n        },\n        {\n            \"step_description\": \"Answer the question using the text data from the document.\",\n            \"task_name\": \"Document Question Answering\"\n        },\n        {\n            \"step_description\": \"Load the reference answer text 'reference.txt' for comparison.\",\n            \"task_name\": \"Text Loading\"\n        },\n        {\n            \"step_description\": \"Compare the answer from the brochure"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Load 'example.jpg' and perform image-to-domain transformation using an appropriate API.\",\n            \"task_name\": \"Image-to-X Transformation\"\n        },\n        {\n            \"step_description\": \"Segment the transformed image into parts using an image segmentation API.\",\n            \"task_name\": \"Image Segmentation\"\n        },\n        {\n            \"step_description\": \"Extract text from each segmented part using an OCR (Optical Character Recognition) API.\",\n            \"task_name\": \"Text-from-Image Extraction\"\n        },\n        {\n            \"step_description\": \"Generate a new image from the extracted text using a text-to-image generation API.\",\n            \"task_name\": \"Text-to-Image Generation\"\n        },\n        {\n            \"step_description\": \"Load the final generated image and perform object detection to identify the main object.\",\n            \"task_name\": \"Object Detection\"\n        },\n        {\n            \"step_description\": \"Extract the main object's name from the object detection output.\",\n            \"task_name\": \"Question Answering\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Image-to-X Transformation\",\n        \"Image Segmentation\",\n        \"Text-from-Image Extraction\",\n        \"Text-to-Image Generation\",\n        \"Object Detection\",\n        \"Question Answering\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Image-to-X Transformation\", \"target\": \"Image Segmentation\"},\n        {\"source\": \"Image Segmentation\", \"target\": \"Text-from-Image Ex"
"```json\n{\n  \"task_steps\": [\n    {\n      \"step_description\": \"Perform Automatic Speech Recognition (ASR) on the noisy audio file 'example.wav' to extract the conversation text.\"\n    },\n    {\n      \"step_description\": \"Apply Text-to-Speech (TTS) to the extracted conversation text to generate clear speech.\"\n    },\n    {\n      \"step_description\": \"Use Object Detection to identify and locate the object in the conversation from a large database of images.\"\n    },\n    {\n      \"step_description\": \"Extract the object image using Image-to-Text or Image-to-Image techniques to generate a text or image description of the object.\"\n    },\n    {\n      \"step_description\": \"Perform Image Classification on the object image to confirm the identity of the object.\"\n    },\n    {\n      \"step_description\": \"Apply Image Segmentation to isolate the object from the background in the image.\"\n    },\n    {\n      \"step_description\": \"Use Depth Estimation to estimate the depth of the object in the image.\"\n    },\n    {\n      \"step_description\": \"Apply Text Generation to generate a text description of the object's dimensions based on the depth estimation and image segmentation results.\"\n    },\n    {\n      \"step_description\": \"Use Question Answering to extract the general dimensions of the object from the text description.\"\n    }\n  ],\n  \"task_nodes\": [\n    \"Automatic Speech Recognition (ASR)\",\n    \"Text-to-Speech (TTS)\",\n    \"Object Detection\",\n    \"Image-to-Text or Image-to-Image\",\n    \"Image Classification\",\n"
"```json\n{\n  \"task_steps\": [\n    {\n      \"step_description\": \"Perform image-to-text extraction to obtain text from the table in the image 'example.jpg'\"\n    },\n    {\n      \"step_description\": \"Perform tabular classification on the extracted text to identify the table's content and structure\"\n    },\n    {\n      \"step_description\": \"Translate the tabular classification output from French to English using a translation API\"\n    },\n    {\n      \"step_description\": \"Compare the English translation of the tabular classification output with the reference text 'This is an important reference text.' using a text similarity API\"\n    }\n  ],\n  \"task_nodes\": [\n    \"Image-to-Text\",\n    \"Tabular Classification\",\n    \"Translation\",\n    \"Text Similarity\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image-to-Text\", \"target\": \"Tabular Classification\"},\n    {\"source\": \"Tabular Classification\", \"target\": \"Translation\"},\n    {\"source\": \"Translation\", \"target\": \"Text Similarity\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load 'example.wav' audio file\",\n    \"Perform Automatic Speech Recognition (ASR) on the audio file to extract text\",\n    \"Load 'example.jpg' image file for reference\",\n    \"Perform Text-to-Image generation to create an image based on the extracted text\",\n    \"Load the generated image\",\n    \"Perform Image Classification or Object Detection to identify the main subject in the scene\",\n    \"Extract the text from the 'example.jpg' image using Optical Character Recognition (OCR) or Text-to-Speech and Text-to-Text to convert speech to text if necessary\",\n    \"Compare the identified main subject from the image and the text using Text Similarity or Document Question Answering to ensure consistency\",\n    \"Output the result: 'The main subject in the scene is [identified subject]'\"\n  ],\n  \"task_nodes\": [\n    \"Automatic Speech Recognition\",\n    \"Text-to-Image generation\",\n    \"Image Classification or Object Detection\",\n    \"Text Extraction (OCR or Text-to-Speech and Text-to-Text)\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text-to-Image generation\"},\n    {\"source\": \"Text-to-Image generation\", \"target\": \"Image Classification or Object Detection\"},\n    {\"source\": \"Text-to-Image generation\", \"target\": \"Text Extraction\"},\n    {\"source\": \"Text Extraction\", \"target\": \"Question Answering\"}\n  ]\n}\n```\n\nThis JSON format provides the task steps, task nodes,"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Load the example.wav file for audio processing\"\n        },\n        {\n            \"step_description\": \"Apply audio noise reduction to improve the overall audio quality\"\n        },\n        {\n            \"step_description\": \"Perform speaker diarization to separate the voices of individual speakers\"\n        },\n        {\n            \"step_description\": \"Apply text-to-speech (TTS) to generate text summaries of each speaker's statements\"\n        },\n        {\n            \"step_description\": \"Use a text summarization model to generate summaries of each speaker's statements with additional context\"\n        },\n        {\n            \"step_description\": \"Combine the summaries and context to create the final output\"\n        }\n    ],\n    \"task_nodes\": [\n        {\n            \"task_name\": \"Audio Preprocessing\",\n            \"input\": [\"example.wav\"],\n            \"output\": [\"processed_audio.wav\"]\n        },\n        {\n            \"task_name\": \"Audio Noise Reduction\",\n            \"input\": [\"processed_audio.wav\"],\n            \"output\": [\"noise_reduced_audio.wav\"]\n        },\n        {\n            \"task_name\": \"Speaker Diarization\",\n            \"input\": [\"noise_reduced_audio.wav\"],\n            \"output\": [\"diarized_audio.wav\"]\n        },\n        {\n            \"task_name\": \"Text-to-Speech\",\n            \"input\": [\"diarized_audio.wav\"],\n            \"output\": [\"text_summaries.txt\"]\n        },\n        {\n            \"task_"
"```json\n{\n  \"task_steps\": [\n    \"Load image 'example.jpg'\",\n    \"Perform image classification using 'Image Classification' API\",\n    \"Identify table in image using 'Object Detection' API\",\n    \"Perform tabular data extraction using 'Tabular Classification' API\",\n    \"Extract bird species and their wingspan data from extracted table\",\n    \"Filter bird species with wingspan larger than 1 meter\",\n    \"Generate speech audio describing the filtered bird species using 'Text-to-Speech' API\",\n    \"Record and save the generated speech audio\",\n    \"Perform automatic speech recognition using 'Automatic Speech Recognition' API\",\n    \"Transcribe the recognized speech back to written text\",\n    \"Compare the user question ('What species have a wingspan larger than 1 meter?') with the transcribed text using 'Sentence Similarity' API\"\n  ],\n  \"task_nodes\": [\n    \"Image Classification\",\n    \"Object Detection\",\n    \"Tabular Classification\",\n    \"Text-to-Speech\",\n    \"Automatic Speech Recognition\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification\", \"target\": \"Object Detection\"},\n    {\"source\": \"Object Detection\", \"target\": \"Tabular Classification\"},\n    {\"source\": \"Tabular Classification\", \"target\": \"Filter bird species\"},\n    {\"source\": \"Filter bird species\", \"target\": \"Generate speech audio\"},\n    {\"source\": \"Generate speech audio\", \"target\": \"Record and save speech audio\"},\n    {\"source\": \"Record and save speech audio\", \"target\": \"Automatic Speech Recognition\"},\n    {\"source\": \"Automatic Speech Recogn"
"```json\n{\n  \"task_steps\": [\n    \"Load 'example.jpg' image file\",\n    \"Apply image enhancement techniques to improve quality\",\n    \"Perform text extraction from the enhanced image\",\n    \"Convert extracted text into speech using Text-to-Speech API\",\n    \"Perform Automatic Speech Recognition on the generated speech\",\n    \"Classify the recognized speech using Audio Classification API\",\n    \"Translate the classification result into French using Translation API\",\n    \"Generate a video based on the translated text using Text-to-Video API\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image Classification\"\n    },\n    {\n      \"task_name\": \"Text Generation\"\n    },\n    {\n      \"task_name\": \"Text-to-Speech\"\n    },\n    {\n      \"task_name\": \"Automatic Speech Recognition\"\n    },\n    {\n      \"task_name\": \"Audio Classification\"\n    },\n    {\n      \"task_name\": \"Translation\"\n    },\n    {\n      \"task_name\": \"Text-to-Video\"\n    },\n    {\n      \"task_name\": \"Image Editing\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification\", \"target\": \"Text Generation\"},\n    {\"source\": \"Text Generation\", \"target\": \"Text-to-Speech\"},\n    {\"source\": \"Text-to-Speech\", \"target\": \"Automatic Speech Recognition\"},\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Audio Classification\"},\n    {\"source\": \"Audio Classification\", \"target\":"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Transcribe the audio file 'example.wav' using Automatic Speech Recognition (ASR) to get text from the audio.\",\n            \"task_name\": \"Automatic Speech Recognition\"\n        },\n        {\n            \"step_description\": \"Use Question Answering (QA) model to extract answer from the transcribed text based on the given question about 'example.jpg' image.\",\n            \"task_name\": \"Question Answering\"\n        },\n        {\n            \"step_description\": \"Summarize the answer obtained from the previous step using Text Summarization.\",\n            \"task_name\": \"Text Summarization\"\n        },\n        {\n            \"step_description\": \"Generate a new image based on the summary using Text-to-Image model.\",\n            \"task_name\": \"Text-to-Image\"\n        },\n        {\n            \"step_description\": \"Estimate the depth of objects in the generated image using Depth Estimation.\",\n            \"task_name\": \"Depth Estimation\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Automatic Speech Recognition\",\n        \"Question Answering\",\n        \"Text Summarization\",\n        \"Text-to-Image\",\n        \"Depth Estimation\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Automatic Speech Recognition\", \"target\": \"Question Answering\"},\n        {\"source\": \"Question Answering\", \"target\": \"Text Summarization\"},\n        {\"source\": \"Text Summarization\", \"target\": \"Text-to-Image\"},\n        {\"source\": \"Text-to-Image\", \"target"
"```json\n{\n  \"task_steps\": [\n    \"Load the example.wav file into an audio processing library\",\n    \"Apply noise reduction algorithm to improve audio quality\",\n    \"Extract speech signals from the improved audio\",\n    \"Convert speech signals to text using Automatic Speech Recognition (ASR) model\",\n    \"Load a Text-to-Speech (TTS) model with a different voice\",\n    \"Convert the text back to speech\",\n    \"Apply Emotion Detection model to the new audio\"\n  ],\n  \"task_nodes\": [\n    \"Audio Classification: Noise Reduction\",\n    \"Speech Recognition: Automatic Speech Recognition\",\n    \"Text-to-Speech: Text-to-Speech with different voice\",\n    \"Emotion Detection: Emotion Recognition\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Audio Classification: Noise Reduction\", \"target\": \"Speech Recognition: Automatic Speech Recognition\"},\n    {\"source\": \"Speech Recognition: Automatic Speech Recognition\", \"target\": \"Text-to-Speech: Text-to-Speech with different voice\"},\n    {\"source\": \"Text-to-Speech: Text-to-Speech with different voice\", \"target\": \"Emotion Detection: Emotion Recognition\"}\n  ]\n}\n```\n\nThis JSON format represents the task steps, task nodes, and task links required to fulfill the user's request. The task steps are described in plain text, while the task nodes are selected from the given TASK LIST. The task links reflect the dependencies among the tasks, indicating the order in which they should be invoked."
"```json\n{\n  \"task_steps\": [\n    {\n      \"step_description\": \"Load the input text file (example.txt) for further processing\"\n    },\n    {\n      \"step_description\": \"Perform named entity recognition on the input text\"\n    },\n    {\n      \"step_description\": \"Summarize the input text\"\n    },\n    {\n      \"step_description\": \"Generate audio from the summarized text\"\n    },\n    {\n      \"step_description\": \"Perform emotion classification on the generated audio\"\n    },\n    {\n      \"step_description\": \"Perform command classification on the generated audio\"\n    },\n    {\n      \"step_description\": \"Load the input image file (example.jpg) for further processing\"\n    },\n    {\n      \"step_description\": \"Edit the input image based on the result from the audio analysis\"\n    },\n    {\n      \"step_description\": \"Classify the edited image\"\n    },\n    {\n      \"step_description\": \"Calculate the text-image similarity based on the initial text and the edited image's classification\"\n    }\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Text-to-Entities\"\n    },\n    {\n      \"task_name\": \"Text-to-Summary\"\n    },\n    {\n      \"task_name\": \"Text-to-Speech\"\n    },\n    {\n      \"task_name\": \"Audio-to-Emotion\"\n    },\n    {\n      \"task_name\": \"Audio-to-Command\"\n    },\n    {\n      \"task_name\": \"Image-to-Text\"\n    },\n    {"
"```json\n{\n  \"task_steps\": [\n    \"Load image 'example.jpg' for object depth estimation.\",\n    \"Perform image segmentation on 'example.jpg' to identify individual objects.\",\n    \"For each object, perform depth estimation using image data.\",\n    \"Determine the largest object based on the depth estimates.\",\n    \"Load text document 'example.txt' for additional information.\",\n    \"Perform text-to-speech synthesis to provide the final answer.\",\n    \"If necessary, load document image 'example.png' for additional information and perform OCR to extract text.\",\n    \"Combine information from image and text to answer the question 'What is the largest object in the image?'\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image Segmentation\"\n    },\n    {\n      \"task_name\": \"Object Detection\"\n    },\n    {\n      \"task_name\": \"Depth Estimation\"\n    },\n    {\n      \"task_name\": \"Text-to-Speech\"\n    },\n    {\n      \"task_name\": \"Text Classification (Document)\"\n    },\n    {\n      \"task_name\": \"Text Extraction (OCR)\"\n    },\n    {\n      \"task_name\": \"Question Answering (Text)\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Segmentation\", \"target\": \"Object Detection\"},\n    {\"source\": \"Object Detection\", \"target\": \"Depth Estimation\"},\n    {\"source\": \"Text Classification (Document)\", \"target\": \"Text Extraction (OCR)\"},\n    {\"source\": \"Text Extraction (OCR)\", \"target\": \""
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Define the input questions for the chatbot to test.\",\n            \"task_name\": \"Question Generation\"\n        },\n        {\n            \"step_description\": \"Run the chatbot and record its responses for each question.\",\n            \"task_name\": \"Chatbot Response Generation\"\n        },\n        {\n            \"step_description\": \"Extract the answers provided by the chatbot.\",\n            \"task_name\": \"Answer Extraction\"\n        },\n        {\n            \"step_description\": \"Compare the extracted answers with the correct answers.\",\n            \"task_name\": \"Answer Verification\"\n        },\n        {\n            \"step_description\": \"Calculate the similarity between the chatbot's answer and the correct answer.\",\n            \"task_name\": \"Answer Similarity\"\n        },\n        {\n            \"step_description\": \"Evaluate the performance of the chatbot based on the similarity scores.\",\n            \"task_name\": \"Performance Evaluation\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Question Generation\",\n        \"Chatbot Response Generation\",\n        \"Answer Extraction\",\n        \"Answer Verification\",\n        \"Answer Similarity\",\n        \"Performance Evaluation\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Question Generation\", \"target\": \"Chatbot Response Generation\"},\n        {\"source\": \"Chatbot Response Generation\", \"target\": \"Answer Extraction\"},\n        {\"source\": \"Answer Extraction\", \"target\": \"Answer Verification\"},\n        {\"source\": \"Answer Verification\", \"target\": \"Answer Similarity\"},\n        {\"source\": \"An"
"```json\n{\n  \"task_steps\": [\n    \"Load the document image 'example.jpg'\",\n    \"Perform Optical Character Recognition (OCR) to extract text from the document image\",\n    \"Perform Text-to-Document question answering to identify the main cause of the historical event from the extracted text\",\n    \"Generate a conversational response explaining the main cause of the historical event\",\n    \"Perform Named Entity Recognition (NER) on the conversational response to highlight the named entities\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image Classification\",\n      \"input\": \"example.jpg\",\n      \"output\": \"document_type\"\n    },\n    {\n      \"task_name\": \"Text-to-Document\",\n      \"input\": {\n        \"image\": \"example.jpg\",\n        \"document_type\": \"historical_document\"\n      },\n      \"output\": \"document_text\"\n    },\n    {\n      \"task_name\": \"Question Answering\",\n      \"input\": {\n        \"question\": \"What was the main cause of the event?\",\n        \"document_text\": \"<document_text>\"\n      },\n      \"output\": \"answer\"\n    },\n    {\n      \"task_name\": \"Text Generation\",\n      \"input\": {\n        \"question\": \"What was the main cause of the event?\",\n        \"answer\": \"<answer>\"\n      },\n      \"output\": \"conversational_response\"\n    },\n    {\n      \"task_name\": \"Named Entity Recognition\",\n      \"input\": {\n        \"text\": \"<conversational_response>\"\n      },\n      \"output\": \"named_"
"```json\n{\n  \"task_steps\": [\n    \"Load image 'example.jpg' and perform table extraction to obtain city information.\",\n    \"Load image 'example.png' and perform object detection to identify key elements in the image.\",\n    \"Compare the extracted city information from the table with the identified key elements in the image to find a match.\",\n    \"Perform token classification on the identified city name to extract relevant tokens.\",\n    \"Output the classified tokens as the final answer.\"\n  ],\n  \"task_nodes\": [\n    \"Tabular Classification: Table Extraction\",\n    \"Object Detection\",\n    \"Question Answering: City Identification\",\n    \"Token Classification\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Tabular Classification: Table Extraction\", \"target\": \"Object Detection\"},\n    {\"source\": \"Object Detection\", \"target\": \"Question Answering: City Identification\"},\n    {\"source\": \"Question Answering: City Identification\", \"target\": \"Token Classification\"}\n  ]\n}\n```"
"{\n  \"task_steps\": [\n    \"Load the example.jpg image\",\n    \"Perform object detection on the image to identify the main object\",\n    \"Extract the RGB values of the main object's pixels\",\n    \"Determine the dominant color based on the RGB values\",\n    \"Generate a new image with the dominant color as the background\",\n    \"Perform image classification on the generated image\",\n    \"Given a question about the category of the object in the generated image, retrieve the answer\"\n  ],\n  \"task_nodes\": [\n    \"Image Classification\",\n    \"Object Detection\",\n    \"Text-to-Speech\",\n    \"Text Generation\",\n    \"Image-to-Image\",\n    \"Tabular Classification\",\n    \"Question Answering\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Object Detection\", \"target\": \"Image-to-Image\"},\n    {\"source\": \"Image-to-Image\", \"target\": \"Tabular Classification\"},\n    {\"source\": \"Tabular Classification\", \"target\": \"Question Answering\"},\n    {\"source\": \"Object Detection\", \"target\": \"Image Processing\"},\n    {\"source\": \"Image Processing\", \"target\": \"Image-to-Image\"},\n    {\"source\": \"Image-to-Image\", \"target\": \"Image Classification\"},\n    {\"source\": \"Text Generation\", \"target\": \"Question Answering\"}\n  ]\n}\n\n# EXPLANATION #:\n# The user request involves identifying the main color of an object in an image, generating a new image based on that color, classifying the generated image, and answering a question about the category of the object in the generated image.\n# To accomplish this, we first perform object"
"```json\n{\n  \"task_steps\": [\n    {\n      \"step_description\": \"Load the audio file 'example.wav' and perform Automatic Speech Recognition to extract text from the audio.\",\n      \"task_name\": \"Automatic Speech Recognition\"\n    },\n    {\n      \"step_description\": \"Use Text-to-Question model to formulate the question 'What are the main colors in the scene?' from the extracted text.\",\n      \"task_name\": \"Text-to-Question\"\n    },\n    {\n      \"step_description\": \"Perform Question Answering on the given image 'example.jpg' to extract the main colors in the scene.\",\n      \"task_name\": \"Question Answering\"\n    },\n    {\n      \"step_description\": \"Load the edited image 'example_edited.jpg' for depth estimation.\",\n      \"task_name\": \"Image Loading\"\n    },\n    {\n      \"step_description\": \"Perform Image Segmentation on the edited image to identify individual objects.\",\n      \"task_name\": \"Image Segmentation\"\n    },\n    {\n      \"step_description\": \"Use the extracted main colors from the question answering task to identify and label the corresponding objects in the segmented image.\",\n      \"task_name\": \"Object Detection\"\n    },\n    {\n      \"step_description\": \"Perform Depth Estimation on the labeled objects in the segmented image to obtain depth information.\",\n      \"task_name\": \"Depth Estimation\"\n    },\n    {\n      \"step_description\": \"Generate a summary of the answer to the question 'What are the main colors in the scene?' based on the depth information and the main colors extracted from the audio.\",\n     "
"```json\n{\n  \"task_steps\": [\n    \"Load the poor quality audio file 'example.wav'.\",\n    \"Apply audio enhancement techniques to improve the quality of the audio file.\",\n    \"Perform automatic speech recognition to extract the French speech from the enhanced audio file.\",\n    \"Perform emotion recognition on the extracted French speech to identify the speaker's emotional state.\",\n    \"Translate the French speech to English using a translation model.\",\n    \"Generate an audio file with the translated English speech using text-to-speech technology.\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Audio Enhancement\"\n    },\n    {\n      \"task_name\": \"Speech Recognition (French)\"\n    },\n    {\n      \"task_name\": \"Emotion Recognition\"\n    },\n    {\n      \"task_name\": \"Translation (French to English)\"\n    },\n    {\n      \"task_name\": \"Text-to-Speech (English)\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Audio Enhancement\", \"target\": \"Speech Recognition (French)\"},\n    {\"source\": \"Speech Recognition (French)\", \"target\": \"Emotion Recognition\"},\n    {\"source\": \"Emotion Recognition\", \"target\": \"Translation (French to English)\"},\n    {\"source\": \"Translation (French to English)\", \"target\": \"Text-to-Speech (English)\"},\n    {\"source\": \"Text-to-Speech (English)\", \"target\": \"Output\"}\n  ]\n}\n```"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Perform image classification to identify the class of the uploaded image 'example.jpg'.\",\n            \"task_name\": \"Image Classification\"\n        },\n        {\n            \"step_description\": \"Extract the identified class label from the output of the image classification task.\",\n            \"task_name\": \"Extract Class Label\"\n        },\n        {\n            \"step_description\": \"Perform text-to-vector conversion on the given text 'Beautiful mountains and a lake.' to obtain a vector representation.\",\n            \"task_name\": \"Text-to-Vector\"\n        },\n        {\n            \"step_description\": \"Calculate the cosine similarity between the vector representation of the image class label and the vector representation of the given text.\",\n            \"task_name\": \"Sentence Similarity\"\n        },\n        {\n            \"step_description\": \"Return the cosine similarity score as the final result.\",\n            \"task_name\": \"Return Result\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Image Classification\",\n        \"Extract Class Label\",\n        \"Text-to-Vector\",\n        \"Sentence Similarity\",\n        \"Return Result\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Image Classification\", \"target\": \"Extract Class Label\"},\n        {\"source\": \"Text-to-Vector\", \"target\": \"Sentence Similarity\"},\n        {\"source\": \"Extract Class Label\", \"target\": \"Sentence Similarity\"},\n        {\"source\": \"Image Classification\", \"target\": \"Return Result\"},\n        {\"source\": \"Text-to-Vector\", \"target\": \"Return Result\"},\n        {\"source\": \"Extract Class Label"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Load and preprocess the input image (example.jpg) for object detection.\",\n            \"task_name\": \"Image Classification\"\n        },\n        {\n            \"step_description\": \"Run object detection model to identify objects in the image.\",\n            \"task_name\": \"Object Detection\"\n        },\n        {\n            \"step_description\": \"Extract the names of the identified objects.\",\n            \"task_name\": \"Text Generation\"\n        },\n        {\n            \"step_description\": \"Convert the extracted text to speech.\",\n            \"task_name\": \"Text-to-Speech\"\n        },\n        {\n            \"step_description\": \"Record the generated speech.\",\n            \"task_name\": \"Automatic Speech Recognition\"\n        },\n        {\n            \"step_description\": \"Classify the recorded speech.\",\n            \"task_name\": \"Audio Classification\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Image Classification\",\n        \"Object Detection\",\n        \"Text Generation\",\n        \"Text-to-Speech\",\n        \"Automatic Speech Recognition\",\n        \"Audio Classification\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Image Classification\", \"target\": \"Object Detection\"},\n        {\"source\": \"Object Detection\", \"target\": \"Text Generation\"},\n        {\"source\": \"Text Generation\", \"target\": \"Text-to-Speech\"},\n        {\"source\": \"Text-to-Speech\", \"target\": \"Automatic Speech Recognition\"},\n        {\"source\": \"Automatic Speech Recognition\", \"target\": \"Audio Classification\"}\n    ]\n"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Perform image classification to identify the image as a table image.\",\n            \"task_name\": \"Image Classification\"\n        },\n        {\n            \"step_description\": \"Perform object detection to locate and extract the table from the image.\",\n            \"task_name\": \"Object Detection\"\n        },\n        {\n            \"step_description\": \"Perform tabular classification to extract the data from the table.\",\n            \"task_name\": \"Tabular Classification\"\n        },\n        {\n            \"step_description\": \"Perform text summarization to generate a short summary of the data related to the most visited cities and their primary attractions.\",\n            \"task_name\": \"Text Summarization\"\n        },\n        {\n            \"step_description\": \"Perform question answering to extract the answer to the question 'What are the primary attractions in the most visited cities?' from the summarized text.\",\n            \"task_name\": \"Question Answering\"\n        },\n        {\n            \"step_description\": \"Display the answer and the summarized text to the user.\",\n            \"task_name\": \"Text Generation\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Image Classification\",\n        \"Object Detection\",\n        \"Tabular Classification\",\n        \"Text Summarization\",\n        \"Question Answering\",\n        \"Text Generation\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Image Classification\", \"target\": \"Object Detection\"},\n        {\"source\": \"Object Detection\", \"target\": \"Tabular Classification\"},\n        {\"source\": \"Tabular Classification\", \"target\": \"Text Summarization\"},\n        {\""
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Perform document question answering to extract the historical event and the leader's name from the provided image document.\",\n            \"task_name\": \"Document Question Answering\"\n        },\n        {\n            \"step_description\": \"Perform image-to-text conversion to extract the textual answer about the leader from the extracted information.\",\n            \"task_name\": \"Text-to-Text\"\n        },\n        {\n            \"step_description\": \"Perform image classification to identify the leader's image based on the textual answer.\",\n            \"task_name\": \"Image Classification\"\n        },\n        {\n            \"step_description\": \"Perform image search using the identified leader's name to find an appropriate image.\",\n            \"task_name\": \"Image-to-Image\"\n        },\n        {\n            \"step_description\": \"Generate an image of the leader based on the textual answer.\",\n            \"task_name\": \"Text-to-Image\"\n        },\n        {\n            \"step_description\": \"Perform image segmentation to separate the leader's image from the background.\",\n            \"task_name\": \"Image Segmentation\"\n        },\n        {\n            \"step_description\": \"Perform depth estimation to estimate the depth of the objects in the leader's image.\",\n            \"task_name\": \"Depth Estimation\"\n        },\n        {\n            \"step_description\": \"Apply a stylized effect to the depth image.\",\n            \"task_name\": \"Image Editing\"\n        },\n        {\n            \"step_description\": \"Perform text extraction from the stylized image.\",\n            \"task_name\": \"Text-to-Text\""
"{\n  \"task_steps\": [\n    {\n      \"step_description\": \"Perform image depth estimation on example.jpg using an Image Depth Estimation API.\",\n      \"task_name\": \"Image Depth Estimation\"\n    },\n    {\n      \"step_description\": \"Classify the depth-estimated image using an Image Classification API.\",\n      \"task_name\": \"Image Classification\"\n    },\n    {\n      \"step_description\": \"Translate the image classification result into French using a Text-to-Text Translation API.\",\n      \"task_name\": \"Text-to-Text Translation\"\n    },\n    {\n      \"step_description\": \"Generate new text based on the translated result using a Text Generation API.\",\n      \"task_name\": \"Text Generation\"\n    },\n    {\n      \"step_description\": \"Perform token classification on the generated text using a Token Classification API.\",\n      \"task_name\": \"Token Classification\"\n    }\n  ],\n  \"task_nodes\": [\n    \"Image Depth Estimation\",\n    \"Image Classification\",\n    \"Text-to-Text Translation\",\n    \"Text Generation\",\n    \"Token Classification\"\n  ],\n  \"task_links\": [\n    {\n      \"source\": \"Image Depth Estimation\",\n      \"target\": \"Image Classification\"\n    },\n    {\n      \"source\": \"Image Classification\",\n      \"target\": \"Text-to-Text Translation\"\n    },\n    {\n      \"source\": \"Text-to-Text Translation\",\n      \"target\": \"Text Generation\"\n    },\n    {\n      \"source\": \"Text Generation\",\n      \"target\": \"Token Classification\"\n    }\n"
"{\n    \"task_steps\": [\n        \"Load 'example.jpg' and perform image segmentation to identify and extract regions of interest.\",\n        \"From the segmented image, identify the region corresponding to the car.\",\n        \"Determine the color of the car by analyzing the pixel values of the identified region.\",\n        \"Edit the original image to highlight the identified car region and change its color based on the answer.\",\n        \"Load the depth estimation image and perform object detection to identify the object appearing closest to the viewer.\",\n        \"Extract the position and dimensions of the identified object from the object detection output.\",\n        \"Answer the document question by retrieving the name of the object based on its position and dimensions.\",\n        \"Convert the answer into speech using a text-to-speech API.\",\n        \"Record the speech output using an automatic speech recognition API.\",\n        \"Transcribe the recorded speech back into text.\"\n    ],\n    \"task_nodes\": [\n        \"Image Segmentation\",\n        \"Color Identification\",\n        \"Image Editing\",\n        \"Depth Estimation\",\n        \"Object Detection\",\n        \"Document Question Answering\",\n        \"Text-to-Speech\",\n        \"Automatic Speech Recognition\",\n        \"Speech-to-Text\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Image Segmentation\", \"target\": \"Color Identification\"},\n        {\"source\": \"Color Identification\", \"target\": \"Image Editing\"},\n        {\"source\": \"Image Segmentation\", \"target\": \"Depth Estimation\"},\n        {\"source\": \"Depth Estimation\", \"target\": \"Object Detection\"},\n        {\"source\": \"Object Detection\", \"target\": \"Document Question Answering\"},\n        {\"source\": \"Document Question"
"{\"task_steps\": [\n\"Load the example image using an Image Classification API to identify the image's content and label it.\",\n\"Use a Text-to-Speech API to read out the image label for better understanding.\",\n\"Use a Text-to-Question Generator API to generate potential study questions related to the image label.\",\n\"Use a Document Question Answering API to find answers to the generated study questions from a relevant text corpus.\",\n\"Use a Text Generation API to write out the answers as study guide entries.\",\n\"Use a Text-to-Speech API to read out the study guide entries for review.\",\n\"Use a Text-to-Video API to create a video presentation of the study guide for better engagement.\"\n],\n\"task_nodes\": [\n\"Image Classification\",\n\"Text-to-Speech (for image label)\",\n\"Text-to-Question Generator\",\n\"Document Question Answering\",\n\"Text Generation (for study guide entries)\",\n\"Text-to-Speech (for study guide entries)\",\n\"Text-to-Video\"\n],\n\"task_links\": [\n{\"source\": \"Image Classification\", \"target\": \"Text-to-Speech (for image label)\"},\n{\"source\": \"Text-to-Speech (for image label)\", \"target\": \"Text-to-Question Generator\"},\n{\"source\": \"Text-to-Question Generator\", \"target\": \"Document Question Answering\"},\n{\"source\": \"Document Question Answering\", \"target\": \"Text Generation (for study guide entries)\"},\n{\"source\": \"Text Generation (for study guide entries)\", \"target\": \"Text-to-Speech (for study guide entries)\"},\n{\"source\": \"Text-to-Speech (for study guide entries)\", \"target\": \"Text-to"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Load the audio recording file (example.wav) for speech-to-text conversion.\"\n        },\n        {\n            \"step_description\": \"Invoke Automatic Speech Recognition (ASR) API to transcribe the audio recording into text.\"\n        },\n        {\n            \"step_description\": \"Load the image file (example.jpg) for text-to-image or image-to-text analysis.\"\n        },\n        {\n            \"step_description\": \"Invoke Text-to-Speech (TTS) API to generate summarized text from the transcribed meeting text.\"\n        },\n        {\n            \"step_description\": \"Invoke Text Summarization API to extract key points from the transcribed meeting text.\"\n        },\n        {\n            \"step_description\": \"Invoke Image Classification or Object Detection API to analyze the image and extract relevant information.\"\n        },\n        {\n            \"step_description\": \"Compare the key points extracted from the meeting text with the information extracted from the image.\"\n        },\n        {\n            \"step_description\": \"Generate a summary report explaining the relationship between the key points from the meeting and the image.\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Automatic Speech Recognition (ASR)\",\n        \"Text Summarization\",\n        \"Text-to-Speech (TTS)\",\n        \"Image Classification or Object Detection\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Automatic Speech Recognition (ASR)\", \"target\": \"Text Summarization\"},\n        {\"source\": \"Text Summarization\", \"target\": \"Text-to-Speech (TTS)\"},\n"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Translate the given Spanish text to English using a translation API.\",\n            \"task_name\": \"Translation\"\n        },\n        {\n            \"step_description\": \"Parse the translated text and extract relevant information for generating a new text.\",\n            \"task_name\": \"Text Processing\"\n        },\n        {\n            \"step_description\": \"Generate a new text based on the extracted information.\",\n            \"task_name\": \"Text Generation\"\n        },\n        {\n            \"step_description\": \"Analyze the example.jpg document image to understand its content.\",\n            \"task_name\": \"Image Analysis\"\n        },\n        {\n            \"step_description\": \"Extract relevant information from the image analysis results.\",\n            \"task_name\": \"Text Extraction\"\n        },\n        {\n            \"step_description\": \"Compare the extracted information from the image with the translated text.\",\n            \"task_name\": \"Text Comparison\"\n        },\n        {\n            \"step_description\": \"Generate a conversational response based on the comparison results.\",\n            \"task_name\": \"Conversational\"\n        }\n    ],\n    \"task_nodes\": [\n        {\n            \"task_name\": \"Translation\"\n        },\n        {\n            \"task_name\": \"Text Processing\"\n        },\n        {\n            \"task_name\": \"Text Generation\"\n        },\n        {\n            \"task_name\": \"Image Analysis\"\n        },\n        {\n            \"task_name\": \"Text Extraction\"\n        },\n        {\n            \"task_name\": \"Text Comparison\"\n        },\n        {\n            \"task_name\": \"Conversational"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Load and preprocess the audio file 'example.wav' for automatic speech recognition.\",\n            \"task_name\": \"Automatic Speech Recognition\"\n        },\n        {\n            \"step_description\": \"Extract the command from the recognized speech.\",\n            \"task_name\": \"Text Extraction\"\n        },\n        {\n            \"step_description\": \"Load and preprocess the image file 'example.jpg' for image editing.\",\n            \"task_name\": \"Image Preprocessing\"\n        },\n        {\n            \"step_description\": \"Apply the command-based image edits to the image.\",\n            \"task_name\": \"Image Editing\"\n        },\n        {\n            \"step_description\": \"Load and preprocess the edited image with the table for table classification.\",\n            \"task_name\": \"Tabular Classification\"\n        },\n        {\n            \"step_description\": \"Extract the table data from the classified table.\",\n            \"task_name\": \"Table Data Extraction\"\n        },\n        {\n            \"step_description\": \"Calculate the total revenue from the extracted table data.\",\n            \"task_name\": \"Text Processing\"\n        },\n        {\n            \"step_description\": \"Generate a summary of the total revenue.\",\n            \"task_name\": \"Text Summarization\"\n        },\n        {\n            \"step_description\": \"Output the summary as the final result.\",\n            \"task_name\": \"Text Generation\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Automatic Speech Recognition\",\n        \"Text Extraction\",\n        \"Image Preprocessing\",\n        \"Image Editing\",\n"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Load the image 'example.jpg' for image processing tasks.\"\n        },\n        {\n            \"step_description\": \"Perform object detection on the loaded image to identify the main object.\"\n        },\n        {\n            \"step_description\": \"Extract the identified object from the image.\"\n        },\n        {\n            \"step_description\": \"Perform image-to-text conversion to get a textual representation of the identified object.\"\n        },\n        {\n            \"step_description\": \"Use text-to-speech API to pronounce the identified object in English.\"\n        },\n        {\n            \"step_description\": \"Use image-to-text API to extract textual information from the image, if any, related to the identified object.\"\n        },\n        {\n            \"step_description\": \"Use text summarization API to generate a brief description of the extracted textual information.\"\n        },\n        {\n            \"step_description\": \"Use text translation API to translate the identified object label and the brief description into French.\"\n        },\n        {\n            \"step_description\": \"Print or display the translated object label and the brief description.\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Image Classification\",\n        \"Object Detection\",\n        \"Text Generation\",\n        \"Text-to-Speech\",\n        \"Text Translation\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Image Classification\", \"target\": \"Object Detection\"},\n        {\"source\": \"Object Detection\", \"target\": \"Text Generation\"},\n        {\"source\": \"Text Generation\", \"target\": \"Text-to-Speech\"},\n        {\"source\": \"Text Generation\","
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Load and preprocess the input image example.jpg for object detection.\",\n            \"task_name\": \"Image Classification\"\n        },\n        {\n            \"step_description\": \"Run object detection model to identify and extract objects present in the image.\",\n            \"task_name\": \"Object Detection\"\n        },\n        {\n            \"step_description\": \"Extract relevant information from the detected objects, such as object names and locations.\",\n            \"task_name\": \"Text Extraction\"\n        },\n        {\n            \"step_description\": \"Generate a text summary of the objects present in the image.\",\n            \"task_name\": \"Text Summarization\"\n        },\n        {\n            \"step_description\": \"Create a storyboard for the video based on the text summary.\",\n            \"task_name\": \"Text-to-Video\"\n        },\n        {\n            \"step_description\": \"Generate the video frames for each scene in the storyboard.\",\n            \"task_name\": \"Video Generation\"\n        },\n        {\n            \"step_description\": \"Combine the generated video frames to create the final video.\",\n            \"task_name\": \"Video Editing\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Image Classification\",\n        \"Object Detection\",\n        \"Text Extraction\",\n        \"Text Summarization\",\n        \"Text-to-Video\",\n        \"Video Generation\",\n        \"Video Editing\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Image Classification\", \"target\": \"Object Detection\"},\n        {\"source\": \"Object Detection\", \"target\": \"Text Extraction\"},\n        {\""
"{\n    \"task_steps\": [\n        \"Step 1: Text-to-Image generation using a Text-to-Image API to create an image based on the given text description: 'A beautiful beach with a red umbrella and crystal clear water'.\",\n        \"Step 2: Image Classification using an Image Classification API to classify the generated image and ensure it matches the given text description.\",\n        \"Step 3: Question Answering using a Question Answering API to extract the main color of the umbrella from the text description: 'A beautiful beach with a red umbrella and crystal clear water'.\",\n        \"Step 4: Comparison using a Text Comparison API to compare the extracted answer with the given text: 'The main color of the umbrella is red'.\",\n        \"Step 5: Text-to-Speech using a Text-to-Speech API to convert the extracted color information into speech audio.\",\n    ],\n    \"task_nodes\": [\n        \"Text-to-Image\",\n        \"Image Classification\",\n        \"Question Answering\",\n        \"Text Comparison\",\n        \"Text-to-Speech\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Text-to-Image\", \"target\": \"Image Classification\"},\n        {\"source\": \"Question Answering\", \"target\": \"Text Comparison\"},\n        {\"source\": \"Text Comparison\", \"target\": \"Text-to-Speech\"}\n    ]\n}"
"```json\n{\n  \"task_steps\": [\n    \"Load the example.wav audio file\",\n    \"Apply audio noise reduction to enhance the audio quality\",\n    \"Perform Automatic Speech Recognition (ASR) to transcribe the audio to text\",\n    \"Generate a new, clearer speech audio from the transcribed text using Text-to-Speech (TTS)\",\n    \"Perform Speaker Emotion Classification on the transcribed text\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Audio Classification and Enhancement\",\n      \"task_description\": \"Apply audio noise reduction to enhance the audio quality\"\n    },\n    {\n      \"task_name\": \"Automatic Speech Recognition\",\n      \"task_description\": \"Transcribe the audio to text\"\n    },\n    {\n      \"task_name\": \"Text-to-Speech\",\n      \"task_description\": \"Generate a new, clearer speech audio from the text\"\n    },\n    {\n      \"task_name\": \"Speaker Emotion Classification\",\n      \"task_description\": \"Classify the speaker's emotion from the transcribed text\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Audio Classification and Enhancement\", \"target\": \"Automatic Speech Recognition\"},\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text-to-Speech\"},\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Speaker Emotion Classification\"}\n  ]\n}\n```"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Load the audio file 'example.wav' for automatic speech recognition\",\n            \"task_name\": \"Automatic Speech Recognition\"\n        },\n        {\n            \"step_description\": \"Transcribe the speech from the audio file to text in English\",\n            \"task_name\": \"Text-to-Speech (for inverse text-to-speech to get text from speech)\",\n            \"depends_on\": [\"Automatic Speech Recognition\"]\n        },\n        {\n            \"step_description\": \"Translate the English text to French\",\n            \"task_name\": \"Text-to-Text (Translation)\",\n            \"depends_on\": [\"Text-to-Speech\"]\n        },\n        {\n            \"step_description\": \"Generate an image representation of the French instruction\",\n            \"task_name\": \"Text-to-Image\",\n            \"depends_on\": [\"Text-to-Text\"]\n        },\n        {\n            \"step_description\": \"Load the generated image for image analysis\",\n            \"task_name\": \"Image Classification\"\n        },\n        {\n            \"step_description\": \"Determine the main action performed in the image\",\n            \"task_name\": \"Question Answering (Visual Question Answering)\",\n            \"depends_on\": [\"Image Classification\"]\n        }\n    ],\n    \"task_nodes\": [\n        \"Automatic Speech Recognition\",\n        \"Text-to-Speech\",\n        \"Text-to-Text (Translation)\",\n        \"Text-to-Image\",\n        \"Image Classification\",\n        \"Question Answering (Visual Question Answering)\"\n    ],"
"{\n  \"task_steps\": [\n    {\n      \"step_description\": \"Perform image classification to identify the presence of a table in the image.\",\n      \"task_name\": \"Image Classification\"\n    },\n    {\n      \"step_description\": \"Extract the table data from the image using OCR and tabular classification.\",\n      \"task_name\": \"Tabular Classification\"\n    },\n    {\n      \"step_description\": \"Extract the quotes from the table data.\",\n      \"task_name\": \"Text Extraction\"\n    },\n    {\n      \"step_description\": \"Perform text summarization to generate paraphrased versions of the quotes.\",\n      \"task_name\": \"Text Summarization\"\n    },\n    {\n      \"step_description\": \"Generate visuals based on the quote content using text-to-image or image-to-text and text generation.\",\n      \"task_name\": \"Text-to-Image or Image-to-Text and Text Generation\"\n    },\n    {\n      \"step_description\": \"Combine the quotes and visuals to create a storyboard for the video.\",\n      \"task_name\": \"Text Generation\"\n    },\n    {\n      \"step_description\": \"Create a video using the storyboard, quotes, and visuals.\",\n      \"task_name\": \"Video Generation\"\n    },\n    {\n      \"step_description\": \"Review and edit the video as needed.\",\n      \"task_name\": \"Video Editing\"\n    }\n  ],\n  \"task_nodes\": [\n    \"Image Classification\",\n    \"Tabular Classification\",\n    \"Text Extraction\",\n    \"Text Summarization\",\n    \"Text-to-Image or Image-to-"
"{\n    \"task_steps\": [\n        \"Load the document image 'example.jpg'\",\n        \"Perform Optical Character Recognition (OCR) on the document image to extract text\",\n        \"Perform Document Question Answering (DQA) on the extracted text to find the answer to the question\",\n        \"Load the Spanish translation model\",\n        \"Translate the answer obtained from DQA into Spanish\"\n    ],\n    \"task_nodes\": [\n        \"Text-to-Text: Document Question Answering\",\n        \"Text-to-Text: Translation (Spanish)\",\n        \"Text-to-Text: Optical Character Recognition\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Text-to-Text: Optical Character Recognition\", \"target\": \"Text-to-Text: Document Question Answering\"},\n        {\"source\": \"Text-to-Text: Document Question Answering\", \"target\": \"Text-to-Text: Translation (Spanish)\"},\n    ]\n}"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Load the image 'example.jpg' for image classification.\"\n        },\n        {\n            \"step_description\": \"Invoke Image Classification API to determine the class of the image.\"\n        },\n        {\n            \"step_description\": \"Store the image class for further use.\"\n        },\n        {\n            \"step_description\": \"Invoke Text-to-Speech API to convert the question 'What time of day was the picture taken?' into speech.\"\n        },\n        {\n            \"step_description\": \"Invoke Image Metadata API to extract metadata from the image, including the time of day it was taken.\"\n        },\n        {\n            \"step_description\": \"Parse the extracted metadata to find the time of day.\"\n        },\n        {\n            \"step_description\": \"Store the time of day for the final answer.\"\n        },\n        {\n            \"step_description\": \"Invoke Text-to-Speech API again to convert the answer into speech.\"\n        },\n        {\n            \"step_description\": \"Output the final answer as speech.\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Image Classification\",\n        \"Text-to-Speech (Question)\",\n        \"Image Metadata\",\n        \"Text-to-Speech (Answer)\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Image Classification\", \"target\": \"Text-to-Speech (Question)\"},\n        {\"source\": \"Text-to-Speech (Question)\", \"target\": \"Image Metadata\"},\n        {\"source\": \"Image Metadata\", \"target\": \"Text-to-Speech (Answer)\"},\n        {\"source\": \"Text-to"
"```json\n{\n  \"task_steps\": [\n    \"Load the audio file 'example.wav'\",\n    \"Perform Automatic Speech Recognition (ASR) on the audio file to extract text from the audio description\",\n    \"Perform Text-to-Image generation to create an image based on the text description\",\n    \"Perform Object Detection on the generated image to identify objects in the scene\",\n    \"Perform Image-to-Text extraction to extract text from the identified objects in the image\",\n    \"Perform Token Classification on the extracted text to classify the tokens associated with the identified objects\"\n  ],\n  \"task_nodes\": [\n    \"Automatic Speech Recognition\",\n    \"Text-to-Image Generation\",\n    \"Object Detection\",\n    \"Image-to-Text Extraction\",\n    \"Token Classification\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text-to-Image Generation\"},\n    {\"source\": \"Text-to-Image Generation\", \"target\": \"Object Detection\"},\n    {\"source\": \"Object Detection\", \"target\": \"Image-to-Text Extraction\"},\n    {\"source\": \"Image-to-Text Extraction\", \"target\": \"Token Classification\"}\n  ]\n}\n```"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Load the text file 'example.txt' and extract the artist's name using Text-to-Question Answering model.\"\n        },\n        {\n            \"step_description\": \"Invoke Text-to-Image API to generate an image based on the artist's name.\"\n            \"output_file\": \"example.jpg\"\n        },\n        {\n            \"step_description\": \"Load the generated image 'example.jpg' and use Image Classification model to identify the dominant color.\"\n        },\n        {\n            \"step_description\": \"Invoke Text-to-Speech API to generate an audio answer for the dominant color.\"\n            \"output_file\": \"example.wav\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Text-to-Question Answering\",\n        \"Text-to-Image\",\n        \"Image Classification\",\n        \"Text-to-Speech\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Text-to-Question Answering\", \"target\": \"Text-to-Image\"},\n        {\"source\": \"Text-to-Image\", \"target\": \"Image Classification\"},\n        {\"source\": \"Image Classification\", \"target\": \"Text-to-Speech\"}\n    ]\n}"
"```json\n{\n  \"task_steps\": [\n    \"Load the example.jpg image.\",\n    \"Perform image segmentation to identify and separate objects in the image.\",\n    \"Perform depth estimation to determine the depth of each object in the image.\",\n    \"Generate a text description of the depth of each object.\",\n    \"Use text-to-speech API to convert the text description into spoken words.\",\n    \"Combine the spoken words with visuals of the original image and the depth information to create a video.\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image Segmentation\"\n    },\n    {\n      \"task_name\": \"Depth Estimation\"\n    },\n    {\n      \"task_name\": \"Text Generation\"\n    },\n    {\n      \"task_name\": \"Text-to-Speech\"\n    },\n    {\n      \"task_name\": \"Video Generation\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Segmentation\", \"target\": \"Depth Estimation\"},\n    {\"source\": \"Depth Estimation\", \"target\": \"Text Generation\"},\n    {\"source\": \"Text Generation\", \"target\": \"Text-to-Speech\"},\n    {\"source\": \"Text-to-Speech\", \"target\": \"Video Generation\"}\n  ]\n}\n```"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Perform image-to-text extraction to obtain text from the English paragraph in the image.\",\n            \"task_name\": \"Image-to-Text\"\n        },\n        {\n            \"step_description\": \"Perform text summarization to extract the main topic of the English paragraph.\",\n            \"task_name\": \"Summarization\"\n        },\n        {\n            \"step_description\": \"Perform text-to-speech synthesis to generate an audio representation of the main topic in English.\",\n            \"task_name\": \"Text-to-Speech\"\n        },\n        {\n            \"step_description\": \"Perform automatic speech recognition to transcribe the English audio into text.\",\n            \"task_name\": \"Automatic Speech Recognition\"\n        },\n        {\n            \"step_description\": \"Perform translation to convert the English text to French.\",\n            \"task_name\": \"Translation\"\n        },\n        {\n            \"step_description\": \"Perform text-to-speech synthesis to generate an audio representation of the French translation.\",\n            \"task_name\": \"Text-to-Speech\"\n        },\n        {\n            \"step_description\": \"Perform automatic speech recognition to transcribe the French audio into text.\",\n            \"task_name\": \"Automatic Speech Recognition\"\n        },\n        {\n            \"step_description\": \"Perform sentence similarity analysis between the French translation and the given sentence 'Le sujet principal est la technologie.'.\",\n            \"task_name\": \"Sentence Similarity\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Image-to-Text\",\n        \"Summarization\","
"```json\n{\n  \"task_steps\": [\n    \"Load the audio file 'example.wav' for automatic speech recognition.\",\n    \"Perform Automatic Speech Recognition (ASR) on the loaded audio file to extract the command.\",\n    \"Search for the command in the provided text 'How to train your dog: step by step guide'.\",\n    \"Identify the corresponding step number and title in the text for the given command.\",\n    \"Load the image related to the identified step number or title from the text.\",\n    \"Generate a related image based on the loaded image, if necessary.\"\n  ],\n  \"task_nodes\": [\n    \"Automatic Speech Recognition\",\n    \"Text Search\",\n    \"Image Retrieval\",\n    \"Image Generation (optional)\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text Search\"},\n    {\"source\": \"Text Search\", \"target\": \"Image Retrieval\"},\n    {\"source\": \"Text Search\", \"target\": \"Image Generation\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load example.jpg image\",\n    \"Generate image from text 'A beautiful sunset over the ocean with dolphins jumping'\",\n    \"Perform depth estimation on generated image\",\n    \"Detect objects in depth-estimated image\",\n    \"Extract labels of detected objects\",\n    \"Calculate object label similarity with reference text 'sun, ocean, dolphins'\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Text-to-Image\"\n    },\n    {\n      \"task_name\": \"Image Generation\"\n    },\n    {\n      \"task_name\": \"Depth Estimation\"\n    },\n    {\n      \"task_name\": \"Object Detection\"\n    },\n    {\n      \"task_name\": \"Text Similarity\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Text-to-Image\", \"target\": \"Image Generation\"},\n    {\"source\": \"Image Generation\", \"target\": \"Depth Estimation\"},\n    {\"source\": \"Depth Estimation\", \"target\": \"Object Detection\"},\n    {\"source\": \"Object Detection\", \"target\": \"Text Similarity\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load the image 'example.jpg' for object detection.\",\n    \"Perform object detection on the loaded image using Object Detection task.\",\n    \"Extract the identified objects' names and bounding boxes from the Object Detection task output.\",\n    \"Generate a summarization text based on the extracted objects' names.\"\n  ],\n  \"task_nodes\": [\n    \"Object Detection\",\n    \"Text Generation\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification\", \"target\": \"Object Detection\"},\n    {\"source\": \"Object Detection\", \"target\": \"Text Generation\"}\n  ]\n}\n```\n\nPlease note that Image Classification task is assumed to be executed before Object Detection task, but it is not explicitly mentioned in the user request. If the assumption is incorrect, you should replace \"Image Classification\" in the task_links with an empty string or remove it entirely."
"{\n    \"task_steps\": [\n        \"Step 1: Use Object Detection task to identify and label objects in example.jpg.\",\n        \"Step 2: Use Text Generation task to generate a response to the prompt 'What do you see in the image?' based on the identified objects.\",\n        \"Step 3: Use Translation task to translate the generated response into French.\",\n        \"Step 4: Use Image-to-Text task to extract the text from example.jpg and save it as a temporary file.\",\n        \"Step 5: Use Text-to-Image task to generate an image based on the translated text.\",\n        \"Step 6: Use Image Editing task to modify example.jpg based on the new image generated in step 5.\",\n        \"Step 7: Use Depth Estimation task to estimate the depth of the objects in the modified image.\",\n        \"Step 8: Use Image-to-Image task to apply the depth estimation results to modify the image further.\",\n        \"Step 9: Use Tabular Classification task to classify the objects in the resulting image.\"\n    ],\n    \"task_nodes\": [\n        \"Object Detection\",\n        \"Text Generation\",\n        \"Translation\",\n        \"Image-to-Text\",\n        \"Text-to-Image\",\n        \"Image Editing\",\n        \"Depth Estimation\",\n        \"Image-to-Image\",\n        \"Tabular Classification\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Object Detection\", \"target\": \"Text Generation\"},\n        {\"source\": \"Text Generation\", \"target\": \"Translation\"},\n        {\"source\": \"Translation\", \"target\": \"Image-to-Text\"},\n        {\"source\": \"Image-to-Text\", \"target\": \"Text-to-Image\"},"
"```json\n{\n  \"task_steps\": [\n    \"Load the audio file 'example.wav' and apply automatic speech recognition to extract commands.\",\n    \"Load the image file 'example.jpg' for further processing.\",\n    \"Apply image-to-text model to extract textual instructions from the recognized speech.\",\n    \"Process the extracted instructions to identify the image modification task.\",\n    \"Apply the identified image modification task to the image 'example.jpg'.\",\n    \"Perform color detection on the main object in the modified image.\",\n    \"Convert the color detection answer into text format.\",\n    \"Use text-to-speech model to convert the textual answer into a speech file.\"\n  ],\n  \"task_nodes\": [\n    \"Automatic Speech Recognition\",\n    \"Image-to-Text\",\n    \"Text Processing\",\n    \"Image Modification\",\n    \"Color Detection\",\n    \"Text-to-Speech\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Image-to-Text\"},\n    {\"source\": \"Image-to-Text\", \"target\": \"Text Processing\"},\n    {\"source\": \"Text Processing\", \"target\": \"Image Modification\"},\n    {\"source\": \"Image Modification\", \"target\": \"Color Detection\"},\n    {\"source\": \"Color Detection\", \"target\": \"Text-to-Speech\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load document image 'example.jpg'\",\n    \"Perform Optical Character Recognition (OCR) on the document image to extract text\",\n    \"Perform Text-to-Question Answering to extract the question 'What are the main benefits of the product described in the document?' from the extracted text\",\n    \"Perform Text-to-Speech to convert the answer to an audio file\",\n    \"Apply audio enhancement and modification to the audio file\",\n    \"Perform Automatic Speech Recognition (ASR) on the enhanced audio file to extract text\",\n    \"Perform Text-to-Image to edit the image 'example.png' based on the extracted text\",\n    \"Perform Image-to-Text to extract text from the edited image\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Text-to-Question-Answering\"\n    },\n    {\n      \"task_name\": \"Text-to-Speech\"\n    },\n    {\n      \"task_name\": \"Audio-enhancement-and-modification\"\n    },\n    {\n      \"task_name\": \"Automatic-Speech-Recognition\"\n    },\n    {\n      \"task_name\": \"Text-to-Image\"\n    },\n    {\n      \"task_name\": \"Image-to-Text\"\n    },\n    {\n      \"task_name\": \"OCR\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"OCR\", \"target\": \"Text-to-Question-Answering\"},\n    {\"source\": \"Text-to-Question-Answering\", \"target\": \""
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Load the audio file 'example.wav' for table classification\"\n        },\n        {\n            \"step_description\": \"Perform table classification on the loaded audio file using 'Image-to-Tabular' or 'Audio-to-Tabular' task\"\n        },\n        {\n            \"step_description\": \"Extract the table classification result from the output\"\n        },\n        {\n            \"step_description\": \"Invoke 'Tabular Classification' task to classify the extracted table\"\n        },\n        {\n            \"step_description\": \"Extract the classification result from the 'Tabular Classification' output\"\n        },\n        {\n            \"step_description\": \"Invoke 'Text-to-Speech' task to convert the classification result into spoken Spanish\"\n        },\n        {\n            \"step_description\": \"Invoke 'Automatic Speech Recognition' task to convert the spoken Spanish back into text\"\n        },\n        {\n            \"step_description\": \"Invoke 'Text Translation' task to translate the recognized Spanish text into written Spanish\"\n        },\n        {\n            \"step_description\": \"Output the final translated table classification result\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Image-to-Tabular\",\n        \"Tabular Classification\",\n        \"Text-to-Speech\",\n        \"Automatic Speech Recognition\",\n        \"Text Translation\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Image-to-Tabular\", \"target\": \"Tabular Classification\"},\n        {\"source\": \"Tabular Classification\", \"target\": \"Text-to-Speech\"},\n        {\"source\": \"Text-"
"```json\n{\n  \"task_steps\": [\n    \"Load 'example.wav' audio file\",\n    \"Apply audio enhancement and source separation using 'Audio-to-Audio' task\",\n    \"Transcribe the enhanced audio into text using 'Automatic Speech Recognition' task\",\n    \"Load 'example.jpg' image file\",\n    \"Apply text-based image editing based on the transcribed text using 'Text-to-Image' task\",\n    \"Classify the modified image using 'Image Classification' task\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Audio-to-Audio\"\n    },\n    {\n      \"task_name\": \"Automatic Speech Recognition\"\n    },\n    {\n      \"task_name\": \"Text-to-Image\"\n    },\n    {\n      \"task_name\": \"Image Classification\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Audio-to-Audio\", \"target\": \"Automatic Speech Recognition\"},\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text-to-Image\"},\n    {\"source\": \"Text-to-Image\", \"target\": \"Image Classification\"}\n  ]\n}\n```"
"{\n    \"task_steps\": [\n        \"Load 'example.wav' audio file\",\n        \"Improve audio quality using Audio Editing\",\n        \"Transcribe improved audio to text using Automatic Speech Recognition\",\n        \"Classify transcribed text using Text Classification\",\n        \"Generate additional text using Text Generation\",\n        \"Summarize text using Summarization\",\n        \"Transcribe summarized text back to audio using Text-to-Speech\",\n        \"Combine summarized text and generated text to create a script\",\n        \"Create a video presentation using Text-to-Video\"\n    ],\n    \"task_nodes\": [\n        {\n            \"task_name\": \"Audio Editing\"\n        },\n        {\n            \"task_name\": \"Automatic Speech Recognition\"\n        },\n        {\n            \"task_name\": \"Text Classification\"\n        },\n        {\n            \"task_name\": \"Text Generation\"\n        },\n        {\n            \"task_name\": \"Summarization\"\n        },\n        {\n            \"task_name\": \"Text-to-Speech\"\n        },\n        {\n            \"task_name\": \"Text-to-Video\"\n        }\n    ],\n    \"task_links\": [\n        {\"source\": \"Audio Editing\", \"target\": \"Automatic Speech Recognition\"},\n        {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text Classification\"},\n        {\"source\": \"Text Classification\", \"target\": \"Text Generation\"},\n        {\"source\": \"Text Generation\", \"target\": \"Summarization\"},\n        {\"source\": \"Summarization\", \"target\": \"Text-to-Speech\"},\n        {\"source\": \""
"{\n    \"task_steps\": [\n        \"Load 'example.wav' audio file\",\n        \"Improve audio quality using Audio Editing\",\n        \"Transcribe improved audio to text using Automatic Speech Recognition and Text-to-Text\",\n        \"Load 'example.jpg' document image\",\n        \"Extract text from 'example.jpg' using Optical Character Recognition and Text-to-Text\",\n        \"Combine transcribed text and extracted text\",\n        \"Find answer to question 'What is the main idea discussed in the audio?' using Question Answering and Document Question Answering\",\n        \"Create visualization of answer using Text-to-Image\",\n        \"Classify visualization image using Image Classification\"\n    ],\n    \"task_nodes\": [\n        \"Audio Editing\",\n        \"Automatic Speech Recognition\",\n        \"Text-to-Text\",\n        \"Optical Character Recognition\",\n        \"Text-to-Text\",\n        \"Question Answering\",\n        \"Document Question Answering\",\n        \"Text-to-Image\",\n        \"Image Classification\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Audio Editing\", \"target\": \"Automatic Speech Recognition\"},\n        {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text-to-Text\"},\n        {\"source\": \"Text-to-Text\", \"target\": \"Optical Character Recognition\"},\n        {\"source\": \"Text-to-Text\", \"target\": \"Question Answering\"},\n        {\"source\": \"Question Answering\", \"target\": \"Text-to-Image\"},\n        {\"source\": \"Text-to-Image\", \"target\": \"Image Classification\"}\n"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Perform text summarization to extract key information from the given text.\"\n        },\n        {\n            \"step_description\": \"Use text classification to identify and extract the date and location from the summarized text.\"\n        },\n        {\n            \"step_description\": \"Use image-to-text model to extract textual information from example.jpg.\"\n        },\n        {\n            \"step_description\": \"Perform text comparison to match the extracted text from the image with the summarized text.\"\n        },\n        {\n            \"step_description\": \"Use the extracted date and location from the summarized text to apply a themed filter to the image.\"\n        },\n        {\n            \"step_description\": \"Perform image enhancement to improve the quality of example.jpg.\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Text Summarization\",\n        \"Text Classification\",\n        \"Image-to-Text\",\n        \"Text Comparison\",\n        \"Image Filtering\",\n        \"Image Enhancement\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Text Summarization\", \"target\": \"Text Classification\"},\n        {\"source\": \"Text Classification\", \"target\": \"Image-to-Text\"},\n        {\"source\": \"Text Classification\", \"target\": \"Image Filtering\"},\n        {\"source\": \"Image-to-Text\", \"target\": \"Text Comparison\"},\n        {\"source\": \"Text Comparison\", \"target\": \"Image Filtering\"},\n        {\"source\": \"Text Summarization\", \"target\": \"Image Enhancement\"},\n        {\"source\": \"Text Classification\", \"target\": \"Image Enhancement\"},\n       "
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Perform Automatic Speech Recognition (ASR) on the given audio file 'example.wav' to extract text from the audio.\",\n            \"task_name\": \"Automatic Speech Recognition\"\n        },\n        {\n            \"step_description\": \"Use Text-to-Image model to generate an image based on the extracted text description.\",\n            \"task_name\": \"Text-to-Image\"\n        },\n        {\n            \"step_description\": \"Perform Image Description Extraction to obtain a textual description of the generated image.\",\n            \"task_name\": \"Text-to-Speech\"\n            // or \"Text-to-Text\" depending on the desired output format\n        }\n    ],\n    \"task_nodes\": [\n        \"Automatic Speech Recognition\",\n        \"Text-to-Image\",\n        \"Text-to-Speech\" // or \"Text-to-Text\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text-to-Image\"},\n        {\"source\": \"Text-to-Image\", \"target\": \"Text-to-Speech\"}\n    ]\n}"
"```json\n{\n  \"task_steps\": [\n    \"Load 'example.wav' audio file\",\n    \"Transcribe the audio file using Automatic Speech Recognition (ASR)\",\n    \"Obtain transcribed text from ASR\",\n    \"Perform Document Question Answering (DQA) using transcribed text as question and 'example.jpg' as document\",\n    \"Extract information from DQA result\",\n    \"Perform Token Classification on extracted text to identify specific entities\",\n    \"Create 'example.mp4' video using extracted information and Text-to-Video API\"\n  ],\n  \"task_nodes\": [\n    \"Automatic Speech Recognition\",\n    \"Document Question Answering\",\n    \"Token Classification\",\n    \"Text-to-Video\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Token Classification\"},\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Document Question Answering\"},\n    {\"source\": \"Document Question Answering\", \"target\": \"Token Classification\"},\n    {\"source\": \"Document Question Answering\", \"target\": \"Text-to-Video\"},\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text-to-Video\"}\n  ]\n}\n```"
"{\n  \"task_steps\": [\n    \"Load 'example.jpg' image\",\n    \"Apply image editing technique to remove graffiti from the image\",\n    \"Perform object detection on the cleaned image to identify objects\",\n    \"Extract text from the image to identify any textual information related to the objects\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image Editing\",\n      \"input\": {\n        \"image_path\": \"example.jpg\"\n      },\n      \"output\": {\n        \"edited_image_path\": \"edited_example.jpg\"\n      }\n    },\n    {\n      \"task_name\": \"Object Detection\",\n      \"input\": {\n        \"image_path\": \"edited_example.jpg\"\n      },\n      \"output\": {\n        \"object_detections\": \"object_detections.json\"\n      }\n    },\n    {\n      \"task_name\": \"Text Extraction\",\n      \"input\": {\n        \"image_path\": \"edited_example.jpg\"\n      },\n      \"output\": {\n        \"text_data\": \"text_data.txt\"\n      }\n    },\n    {\n      \"task_name\": \"Question Answering\",\n      \"input\": {\n        \"object_detections\": \"object_detections.json\",\n        \"text_data\": \"text_data.txt\"\n      },\n      \"output\": {\n        \"answers\": \"answers.json\"\n      }\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Editing\", \"target\": \"Object Detection\"},\n    {\"source\": \""
"```json\n{\n  \"task_steps\": [\n    \"Load the audio file: example.wav\",\n    \"Perform Automatic Speech Recognition (ASR) to extract text from the audio file\",\n    \"Summarize the extracted text using Text Summarization\",\n    \"Load the image file: example.jpg\",\n    \"Perform Image-to-Text conversion to extract text from the image\",\n    \"Compare the summarized text with the extracted text using Text Similarity\",\n    \"If the text similarity score is above a certain threshold, proceed with the next step, else reject the request\",\n    \"Perform Image Editing based on the summarized text\",\n    \"Perform Image Classification to determine the category of the edited image\"\n  ],\n  \"task_nodes\": [\n    \"Automatic Speech Recognition\",\n    \"Text Summarization\",\n    \"Image-to-Text\",\n    \"Text Similarity\",\n    \"Image Editing\",\n    \"Image Classification\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text Summarization\"},\n    {\"source\": \"Text Summarization\", \"target\": \"Image-to-Text\"},\n    {\"source\": \"Image-to-Text\", \"target\": \"Text Similarity\"},\n    {\"source\": \"Text Similarity\", \"target\": \"Image Editing\"},\n    {\"source\": \"Image Editing\", \"target\": \"Image Classification\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load the example.jpg image\",\n    \"Perform image-to-image transformation to match target image characteristics using Image-to-Image task\",\n    \"Perform depth estimation using Depth Estimation task\",\n    \"Perform object detection and labeling using Object Detection task\",\n    \"Convert object labels to speech using Text-to-Speech task\",\n    \"Record and transcribe the speech back to text using Automatic Speech Recognition and Text-to-Text task\",\n    \"Compare the similarity between the original labels and the transcribed text using Sentence Similarity task\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image-to-Image\"\n    },\n    {\n      \"task_name\": \"Depth Estimation\"\n    },\n    {\n      \"task_name\": \"Object Detection\"\n    },\n    {\n      \"task_name\": \"Text-to-Speech\"\n    },\n    {\n      \"task_name\": \"Automatic Speech Recognition\"\n    },\n    {\n      \"task_name\": \"Text-to-Text\"\n    },\n    {\n      \"task_name\": \"Sentence Similarity\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Image-to-Image\", \"target\": \"Depth Estimation\"},\n    {\"source\": \"Depth Estimation\", \"target\": \"Object Detection\"},\n    {\"source\": \"Object Detection\", \"target\": \"Text-to-Speech\"},\n    {\"source\": \"Text-to-Speech\", \"target\": \"Automatic Speech Recognition\"},\n    {\"source\": \"Automatic Speech"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Transcribe the audio file 'example.wav' to text using Automatic Speech Recognition (ASR) API.\",\n            \"task_name\": \"Automatic Speech Recognition\"\n        },\n        {\n            \"step_description\": \"Extract text from the document image 'example.jpg' using Text-to-Text OCR API.\",\n            \"task_name\": \"Text-to-Text OCR\"\n        },\n        {\n            \"step_description\": \"Combine the transcribed text from the audio file and the extracted text from the document image.\",\n            \"task_name\": \"Text Merging\"\n        },\n        {\n            \"step_description\": \"Generate a response text based on the combined text using Text Generation API.\",\n            \"task_name\": \"Text Generation\"\n        },\n        {\n            \"step_description\": \"Transcribe the generated response text back into speech using Text-to-Speech API.\",\n            \"task_name\": \"Text-to-Speech\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Automatic Speech Recognition\",\n        \"Text-to-Text OCR\",\n        \"Text Merging\",\n        \"Text Generation\",\n        \"Text-to-Speech\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text Merging\"},\n        {\"source\": \"Text-to-Text OCR\", \"target\": \"Text Merging\"},\n        {\"source\": \"Text Merging\", \"target\": \"Text Generation\"},\n        {\"source\": \"Text Generation\", \"target\": \"Text-to-Speech\"}\n   "
"```json\n{\n  \"task_steps\": [\n    \"Load 'example.jpg' image\",\n    \"Perform image preprocessing to enhance table image\",\n    \"Perform image-to-text conversion to extract table data from enhanced image\",\n    \"Perform text translation to convert English question to target language (if required)\",\n    \"Perform table data parsing to extract required data from translated text\",\n    \"Perform text summarization to extract answer from parsed table data\",\n    \"Generate final answer\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image Classification\",\n      \"input\": [\"example.jpg\"],\n      \"output\": [\"enhanced_image\"]\n    },\n    {\n      \"task_name\": \"Image-to-Text\",\n      \"input\": [\"enhanced_image\"],\n      \"output\": [\"table_data_text\"]\n    },\n    {\n      \"task_name\": \"Text Translation\",\n      \"input\": [\"question\"],\n      \"output\": [\"translated_question\"],\n      \"depends_on\": [\"Image-to-Text\"]\n    },\n    {\n      \"task_name\": \"Tabular Classification\",\n      \"input\": [\"table_data_text\"],\n      \"output\": [\"parsed_table_data\"]\n    },\n    {\n      \"task_name\": \"Text Summarization\",\n      \"input\": [\"parsed_table_data\"],\n      \"output\": [\"answer\"]\n    },\n    {\n      \"task_name\": \"Text-to-Speech\",\n      \"input\": [\"answer\"],\n      \"output\": [\"final_answer\"]\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Load the image 'example.jpg' for further processing.\",\n            \"task_name\": \"Image Classification\"\n        },\n        {\n            \"step_description\": \"Classify the table in the image using the Image Classification API.\",\n            \"task_name\": \"Image Classification\"\n        },\n        {\n            \"step_description\": \"Extract the classification result and use it as input for the Text-to-Image API.\",\n            \"task_name\": \"Text-to-Image\"\n        },\n        {\n            \"step_description\": \"Generate a new image based on the classification result.\",\n            \"task_name\": \"Text-to-Image\"\n        },\n        {\n            \"step_description\": \"Load the original image 'example.jpg' for image enhancement.\",\n            \"task_name\": \"Image Editing\"\n        },\n        {\n            \"step_description\": \"Apply image enhancement techniques to the original image.\",\n            \"task_name\": \"Image Editing\"\n        },\n        {\n            \"step_description\": \"Combine the enhanced image and the generated image.\",\n            \"task_name\": \"Image Editing\"\n        },\n        {\n            \"step_description\": \"Save the final result as a new image file.\",\n            \"task_name\": \"None\"\n        }\n    ],\n    \"task_nodes\": [\n        {\n            \"task_name\": \"Image Classification\"\n        },\n        {\n            \"task_name\": \"Text-to-Image\"\n        },\n        {\n            \"task_name\": \"Image Editing\"\n        }\n    ],\n    \"task_links\": [\n        {\n            \"source"
"{\n    \"task_steps\": [\n        \"Load 'example.wav' audio file\",\n        \"Apply audio enhancement to 'example.wav'\",\n        \"Load 'example.jpg' image file\",\n        \"Apply conversation-based image editing to 'example.jpg'\",\n        \"Apply image enhancement to the edited image\",\n        \"Generate a descriptive label for the enhanced image\",\n        \"Extract significant entities from the image label\",\n        \"Identify the event mention and its date from the conversation\",\n        \"Answer the query: 'When will the event mentioned in the conversation take place?'\"\n    ],\n    \"task_nodes\": [\n        {\n            \"task_name\": \"Audio Enhancement\"\n        },\n        {\n            \"task_name\": \"Conversation Analysis\"\n        },\n        {\n            \"task_name\": \"Image Editing\"\n        },\n        {\n            \"task_name\": \"Image Enhancement\"\n        },\n        {\n            \"task_name\": \"Text Generation\"\n        },\n        {\n            \"task_name\": \"Named Entity Recognition\"\n        },\n        {\n            \"task_name\": \"Question Answering\"\n        }\n    ],\n    \"task_links\": [\n        {\"source\": \"Load 'example.wav' audio file\", \"target\": \"Apply audio enhancement to 'example.wav'\"},\n        {\"source\": \"Load 'example.jpg' image file\", \"target\": \"Apply conversation-based image editing to 'example.jpg'\"},\n        {\"source\": \"Apply conversation-based image editing to 'example.jpg'\", \"target\": \"Apply image enhancement to the edited image\"},\n        {\"source\": \"Apply image enhancement to the edited image\", \"target\": \"Generate"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Load the input image 'example.jpg' for image processing.\"\n        },\n        {\n            \"step_description\": \"Apply the specified artistic style to the input image while preserving depth information using an Image-to-Image model.\"\n        },\n        {\n            \"step_description\": \"Perform Object Detection on the transformed image to identify and locate objects within the scene.\"\n        },\n        {\n            \"step_description\": \"Save the processed image with identified objects for further analysis or display.\"\n        }\n    ],\n    \"task_nodes\": [\n        {\n            \"task_name\": \"Image-to-Image\"\n        },\n        {\n            \"task_name\": \"Object Detection\"\n        }\n    ],\n    \"task_links\": [\n        {\n            \"source\": \"Image Processing\",\n            \"target\": \"Image-to-Image\"\n        },\n        {\n            \"source\": \"Image-to-Image\",\n            \"target\": \"Object Detection\"\n        }\n    ]\n}\n\n# Explanation #:\nThe user request involves applying a specific artistic style to an image while preserving depth information and then detecting and identifying objects within the transformed image. To accomplish this, we will use the Image-to-Image model for applying the artistic style and preserving depth information, followed by Object Detection to identify and locate objects within the transformed image. The task steps and task nodes are defined accordingly, and the task links reflect the dependencies between the tasks."
"```json\n{\n  \"task_steps\": [\n    \"Load 'example.wav' audio file and perform Automatic Speech Recognition to extract text.\",\n    \"Load 'example.jpg' image file and perform Image-to-Text conversion to extract text from the image.\",\n    \"Compare the text from audio and image using Text Similarity task.\",\n    \"If text similarity score is above a certain threshold, proceed with image editing based on the audio content using Image Editing task.\",\n    \"Load the modified image and perform Object Detection task to detect and label objects in the image.\",\n    \"Extract summaries of the detected objects using Text Summarization task.\"\n  ],\n  \"task_nodes\": [\n    \"Automatic Speech Recognition\",\n    \"Text-to-Text (Image-to-Text)\",\n    \"Text Similarity\",\n    \"Image Editing\",\n    \"Object Detection\",\n    \"Text Summarization\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text-to-Text (Image-to-Text)\"},\n    {\"source\": \"Text-to-Text (Image-to-Text)\", \"target\": \"Text Similarity\"},\n    {\"source\": \"Text Similarity\", \"target\": \"Image Editing\"},\n    {\"source\": \"Image Editing\", \"target\": \"Object Detection\"},\n    {\"source\": \"Object Detection\", \"target\": \"Text Summarization\"}\n  ]\n}\n```"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Load the source image 'example.jpg' for image-to-image transformation.\"\n        },\n        {\n            \"step_description\": \"Apply image-to-image transformation to source image 'example.jpg' to match the characteristics of the target image domain.\"\n        },\n        {\n            \"step_description\": \"Classify the transformed image as a table using tabular image classification.\"\n        },\n        {\n            \"step_description\": \"Extract information from the classified table image using document question answering.\"\n        },\n        {\n            \"step_description\": \"Formulate the first question: 'What is the main point of the table?'\"\n        },\n        {\n            \"step_description\": \"Invoke the question answering API with the first question and the classified table image as input.\"\n        },\n        {\n            \"step_description\": \"Store the answer to the first question.\"\n        },\n        {\n            \"step_description\": \"Formulate the second question: 'Is the generated image in Step 4 relevant to the table?'\"\n        },\n        {\n            \"step_description\": \"Invoke the question answering API with the second question and the classified table image and the generated image as input.\"\n        },\n        {\n            \"step_description\": \"Store the answer to the second question.\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Image-to-Image\",\n        \"Tabular Classification\",\n        \"Document Question Answering\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Image Classification\", \"target\": \"Image-to-Image\"},\n        {\"source\": \"Image-to-Image\", \"target\": \"Tabular Classification\"},\n       "
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Load and preprocess the input image (example.jpg) for image-to-image translation.\",\n            \"task_name\": \"Image-to-Image\"\n        },\n        {\n            \"step_description\": \"Transform the input image to match the target image domain using image-to-image translation.\",\n            \"task_name\": \"Image-to-Image\"\n        },\n        {\n            \"step_description\": \"Load and preprocess the transformed image for depth estimation.\",\n            \"task_name\": \"Depth Estimation\"\n        },\n        {\n            \"step_description\": \"Predict the depth of objects within the transformed image using depth estimation.\",\n            \"task_name\": \"Depth Estimation\"\n        },\n        {\n            \"step_description\": \"Load and preprocess the image containing the table for tabular classification.\",\n            \"task_name\": \"Tabular Classification\"\n        },\n        {\n            \"step_description\": \"Classify the table contained in the image using tabular classification.\",\n            \"task_name\": \"Tabular Classification\"\n        },\n        {\n            \"step_description\": \"Generate a conversational response based on the table classification result.\",\n            \"task_name\": \"Conversational\"\n        },\n        {\n            \"step_description\": \"Compare the generated conversational response with the reference text using text similarity.\",\n            \"task_name\": \"Sentence Similarity\"\n        }\n    ],\n    \"task_nodes\": [\n        {\n            \"task_name\": \"Image-to-Image\"\n        },\n        {\n            \"task_name\": \"Depth Estimation\"\n        },\n        {\n            \"task_name\":"
"```json\n{\n  \"task_steps\": [\n    \"Load 'example.wav' audio file\",\n    \"Perform Automatic Speech Recognition (ASR) on the audio file to extract text\",\n    \"Classify the content of the text using Text Classification\",\n    \"Generate a conversation about the classified text using Conversational AI\",\n    \"Paraphrase the conversation using Text Paraphrasing\",\n    \"Load 'example.jpg' image file\",\n    \"Perform Image Classification on the image\",\n    \"Generate a question related to the image and its classification\",\n    \"Use Text-to-Question Answering model to answer the question using the paraphrased conversation as context\"\n  ],\n  \"task_nodes\": [\n    \"Automatic Speech Recognition\",\n    \"Text Classification\",\n    \"Conversational AI\",\n    \"Text Paraphrasing\",\n    \"Image Classification\",\n    \"Text-to-Question Answering\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text Classification\"},\n    {\"source\": \"Text Classification\", \"target\": \"Conversational AI\"},\n    {\"source\": \"Conversational AI\", \"target\": \"Text Paraphrasing\"},\n    {\"source\": \"Image Classification\", \"target\": \"Text-to-Question Answering\"},\n    {\"source\": \"Text Paraphrasing\", \"target\": \"Text-to-Question Answering\"}\n  ]\n}\n```\n\nThis JSON format represents the task steps, task nodes, and task links required to fulfill the user's request. The user's audio file 'example.wav' is first processed using Automatic Spe"
"```json\n{\n  \"task_steps\": [\n    \"Load the example.jpg image file.\",\n    \"Perform Object Detection on the loaded image to identify objects present.\",\n    \"Extract the object names and their respective bounding boxes from the Object Detection output.\",\n    \"For each object, perform Image-to-Text task to generate a textual description of the object.\",\n    \"Store the generated textual descriptions in a list.\",\n    \"Combine the textual descriptions into a coherent audio description using Text-to-Speech task.\"\n  ],\n  \"task_nodes\": [\n    \"Object Detection\",\n    \"Image-to-Text (for each object)\",\n    \"Text-to-Speech\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Object Detection\", \"target\": \"Image-to-Text\"},\n    {\"source\": \"Image-to-Text\", \"target\": \"Text-to-Speech\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    {\n      \"step_description\": \"Load the example.jpg image and apply the desired style transformation using an Image-to-Image model.\",\n      \"task_name\": \"Image-to-Image\"\n    },\n    {\n      \"step_description\": \"Identify objects in the transformed image using an Object Detection model.\",\n      \"task_name\": \"Object Detection\"\n    },\n    {\n      \"step_description\": \"Classify the identified object tokens using a Text Classification model.\",\n      \"task_name\": \"Text Classification\"\n    },\n    {\n      \"step_description\": \"Convert the classified labels to speech using a Text-to-Speech model.\",\n      \"task_name\": \"Text-to-Speech\"\n    },\n    {\n      \"step_description\": \"Transcribe the spoken text back to text using an Automatic Speech Recognition model.\",\n      \"task_name\": \"Automatic Speech Recognition\"\n    },\n    {\n      \"step_description\": \"Generate a new description based on the classified object tokens using a Text Generation model.\",\n      \"task_name\": \"Text Generation\"\n    },\n    {\n      \"step_description\": \"Compare the generated description's similarity to 'The beautiful scenery in the park has several trees, a bench, and people walking by.' using a Sentence Similarity model.\",\n      \"task_name\": \"Sentence Similarity\"\n    }\n  ],\n  \"task_nodes\": [\n    \"Image-to-Image\",\n    \"Object Detection\",\n    \"Text Classification\",\n    \"Text-to-Speech\",\n    \"Automatic Speech Recognition\",\n   "
"{\n    \"task_steps\": [\n        {\n            \"step\": \"1. Transcribe the audio file 'example.wav' into text using Automatic Speech Recognition.\",\n            \"task_name\": \"Automatic Speech Recognition\"\n        },\n        {\n            \"step\": \"2. Preprocess the transcribed text for summarization and entity recognition.\",\n            \"task_name\": \"Text Preprocessing\"\n        },\n        {\n            \"step\": \"3. Summarize the main points from the transcribed text using Text Summarization.\",\n            \"task_name\": \"Text Summarization\"\n        },\n        {\n            \"step\": \"4. Identify important entities in the summarized text using Named Entity Recognition.\",\n            \"task_name\": \"Named Entity Recognition\"\n        },\n        {\n            \"step\": \"5. Generate a video based on the summarized text and important entities using Text-to-Video.\",\n            \"task_name\": \"Text-to-Video\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Automatic Speech Recognition\",\n        \"Text Preprocessing\",\n        \"Text Summarization\",\n        \"Named Entity Recognition\",\n        \"Text-to-Video\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text Preprocessing\"},\n        {\"source\": \"Text Preprocessing\", \"target\": \"Text Summarization\"},\n        {\"source\": \"Text Preprocessing\", \"target\": \"Named Entity Recognition\"},\n        {\"source\": \"Text Summarization\", \"target\": \"Text-to-Video\"},\n        {\"source\": \"Named Entity Recognition\", \"target\":"
"```json\n{\n  \"task_steps\": [\n    \"Load 'example.jpg' image into memory.\",\n    \"Perform table text extraction on the image using OCR (Optical Character Recognition) technology.\",\n    \"Clean and preprocess the extracted text data.\",\n    \"Generate a new image based on the extracted text using Text-to-Image model.\",\n    \"Load 'example_target.jpg' image into memory.\",\n    \"Perform Image-to-Image transformation on the generated image to match the style of 'example_target.jpg'\",\n    \"Classify the transformed image as a table using Tabular Classification model.\"\n  ],\n  \"task_nodes\": [\n    \"Image Classification: Image-to-Text (OCR)\",\n    \"Text Generation: Text-to-Image\",\n    \"Image Classification: Tabular Classification\",\n    \"Image Classification: Image-to-Image\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification: Image-to-Text (OCR)\", \"target\": \"Text Generation: Text-to-Image\"},\n    {\"source\": \"Text Generation: Text-to-Image\", \"target\": \"Image Classification: Tabular Classification\"},\n    {\"source\": \"Image Classification: Image-to-Text (OCR)\", \"target\": \"Image Classification: Tabular Classification\"}\n  ]\n}\n```\n\nThis JSON format represents the task steps, task nodes, and task links required to extract text from an image, generate a new image based on the extracted text, transform the generated image to match a target image, and classify the transformed image as a table. The task steps are strictly aligned with the task nodes, and the number of task steps is equal to the number of task nodes. The task"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Load and preprocess the input image and text.\",\n            \"task_name\": \"Image Preprocessing, Text Preprocessing\"\n        },\n        {\n            \"step_description\": \"Perform image-to-text recognition to extract textual information from the image.\",\n            \"task_name\": \"Image-to-Text\"\n        },\n        {\n            \"step_description\": \"Perform text summarization to get a concise summary of the input text.\",\n            \"task_name\": \"Text Summarization\"\n        },\n        {\n            \"step_description\": \"Identify and extract historic events mentioned in both the image and text.\",\n            \"task_name\": \"Document Question Answering\"\n        },\n        {\n            \"step_description\": \"Compare the extracted historic events from the image and text to find a match.\",\n            \"task_name\": \"Sentence Similarity\"\n        },\n        {\n            \"step_description\": \"Output the matched historic event and the summary of the answer.\",\n            \"task_name\": \"Text Generation\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Image Preprocessing, Text Preprocessing\",\n        \"Image-to-Text\",\n        \"Text Summarization\",\n        \"Document Question Answering\",\n        \"Sentence Similarity\",\n        \"Text Generation\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Image Preprocessing, Text Preprocessing\", \"target\": \"Image-to-Text\"},\n        {\"source\": \"Image-to-Text\", \"target\": \"Text Summarization\"},\n        {\"source\": \"Text Summarization\", \"target\": \"Document Question Answering\"},\n        {\""
"```json\n{\n  \"task_steps\": [\n    \"Load 'example.wav' audio file\",\n    \"Perform Automatic Speech Recognition (ASR) on the audio file to extract command text\",\n    \"Convert command text to French using Translation API\",\n    \"Load 'example.jpg' image file\",\n    \"Perform Image-to-Text conversion on 'example.jpg' to extract initial image description\",\n    \"Edit image based on the translated command using Text-to-Image API\",\n    \"Perform Image Segmentation on the edited image to identify objects\",\n    \"Estimate depth of objects in the edited image using Depth Estimation API\",\n    \"Compare depth-estimated image with target domain using Image Similarity API\",\n    \"Answer question about the transformed image using Question Answering API\",\n    \"Load given document text\",\n    \"Answer question about the transformed image from the document text using Document Question Answering API\"\n  ],\n  \"task_nodes\": [\n    \"Automatic Speech Recognition\",\n    \"Translation\",\n    \"Text-to-Image\",\n    \"Image Segmentation\",\n    \"Depth Estimation\",\n    \"Image Similarity\",\n    \"Question Answering\",\n    \"Document Question Answering\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text-to-Text\"},\n    {\"source\": \"Text-to-Text\", \"target\": \"Translation\"},\n    {\"source\": \"Translation\", \"target\": \"Text-to-Image\"},\n    {\"source\": \"Text-to-Image\", \"target\": \"Image Segmentation\"},\n    {\"source\": \"Image Segmentation\", \"target\": \""
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Convert audio file to text using Automatic Speech Recognition (ASR) API.\",\n            \"task_name\": \"Automatic Speech Recognition\"\n        },\n        {\n            \"step_description\": \"Extract the question 'What was the main cause of the event?' from user's request.\",\n            \"task_name\": \"Question Answering\"\n        },\n        {\n            \"step_description\": \"Use Text-to-Question Answering API to find the answer to the question from the transcribed text.\",\n            \"task_name\": \"Question Answering\"\n        },\n        {\n            \"step_description\": \"Generate a summary of the event using Text Summarization API.\",\n            \"task_name\": \"Text Summarization\"\n        },\n        {\n            \"step_description\": \"Tokenize the transcribed text and classify tokens for important entities like dates, individuals, and places using Named Entity Recognition (NER) API.\",\n            \"task_name\": \"Token Classification\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Automatic Speech Recognition\",\n        \"Question Answering\",\n        \"Text Summarization\",\n        \"Token Classification\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Automatic Speech Recognition\", \"target\": \"Question Answering\"},\n        {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text Summarization\"},\n        {\"source\": \"Automatic Speech Recognition\", \"target\": \"Token Classification\"},\n        {\"source\": \"Question Answering\", \"target\": \"Text Summarization\"},\n        {\"source"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Convert text to speech using Text-to-Speech API\",\n            \"task_name\": \"Text-to-Speech\"\n        },\n        {\n            \"step_description\": \"Enhance speech quality using Speech Enhancement API\",\n            \"task_name\": \"Speech Enhancement\"\n        },\n        {\n            \"step_description\": \"Transcribe enhanced speech back to text using Automatic Speech Recognition API\",\n            \"task_name\": \"Automatic Speech Recognition\"\n        },\n        {\n            \"step_description\": \"Generate new version of text using Text Generation API\",\n            \"task_name\": \"Text Generation\"\n        },\n        {\n            \"step_description\": \"Translate text to French using Translation API\",\n            \"task_name\": \"Translation\"\n        },\n        {\n            \"step_description\": \"Summarize text using Summarization API\",\n            \"task_name\": \"Summarization\"\n        },\n        {\n            \"step_description\": \"Answer question 'What is the main idea of the text?' using Document Question Answering API\",\n            \"task_name\": \"Document Question Answering\"\n        },\n        {\n            \"step_description\": \"Generate video illustrating answer using Text-to-Video API\",\n            \"task_name\": \"Text-to-Video\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Text-to-Speech\",\n        \"Speech Enhancement\",\n        \"Automatic Speech Recognition\",\n        \"Text Generation\",\n        \"Translation\",\n        \"Summarization\",\n        \""
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Load and preprocess the example image 'example.jpg' for image-to-text task to extract a descriptive caption of 'Serenity at the beach'.\"\n        },\n        {\n            \"step_description\": \"Invoke Text-to-Image API to generate an artistic interpretation of the descriptive caption as a table format image.\"\n        },\n        {\n            \"step_description\": \"Post-process the generated image to ensure the table format is clear and visually appealing.\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Image Classification\",\n        \"Text-to-Image\",\n        \"Image Editing\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Image Classification\", \"target\": \"Text-to-Image\"},\n        {\"source\": \"Text-to-Image\", \"target\": \"Image Editing\"}\n    ]\n}\n\n# EXPLANATION #:\n# The user request involves generating an artistic interpretation of the concept 'Serenity at the beach' in a table format image.\n# To accomplish this, we first need to extract a descriptive caption of 'Serenity at the beach' from an example image 'example.jpg'.\n# This is done by invoking an Image Classification API to classify the image and then using the extracted information to generate a descriptive caption through a Text-to-Image API.\n# Finally, the generated image is post-processed to ensure the table format is clear and visually appealing using an Image Editing API.\n# Therefore, the task steps and task nodes are defined accordingly, and the task links reflect the dependencies among the tasks."
"{\n    \"task_steps\": [\n        \"Extract keywords from audio file 'example.wav'.\",\n        \"Perform Image-to-Text task to transcribe the keywords into text format.\",\n        \"Apply Text-to-Image task to generate modifications based on the extracted keywords.\",\n        \"Perform Image Editing task to modify the image based on the generated modifications.\",\n        \"Perform Image Segmentation task to separate objects in the image.\",\n        \"Perform Depth Estimation task to estimate the depth of the objects in the image.\",\n        \"Apply Text-to-Image task to generate artistic style transformation.\",\n        \"Perform Image-to-Image task to apply the artistic style transformation to the modified image.\"\n    ],\n    \"task_nodes\": [\n        \"Text-to-Speech\",\n        \"Automatic Speech Recognition\",\n        \"Text-to-Image\",\n        \"Image Editing\",\n        \"Image Segmentation\",\n        \"Depth Estimation\",\n        \"Text-to-Image\",\n        \"Image-to-Image\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text-to-Speech\"},\n        {\"source\": \"Text-to-Speech\", \"target\": \"Text-to-Image\"},\n        {\"source\": \"Text-to-Image\", \"target\": \"Image Editing\"},\n        {\"source\": \"Image Editing\", \"target\": \"Image Segmentation\"},\n        {\"source\": \"Image Segmentation\", \"target\": \"Depth Estimation\"},\n        {\"source\": \"Text-to-Image\", \"target\": \"Text-to-Image\"},\n        {\"source\": \"Text-to-Image\", \"target\": \"Image-to-Image\"},"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Load the example.wav audio file and perform Automatic Speech Recognition (ASR) to extract text from the audio.\",\n            \"task_name\": \"Automatic Speech Recognition\"\n        },\n        {\n            \"step_description\": \"Parse the extracted text to understand the image modification instructions.\",\n            \"task_name\": \"Text Parsing\"\n        },\n        {\n            \"step_description\": \"Load the example.jpg image and perform Image-to-Text conversion to extract initial textual information from the image.\",\n            \"task_name\": \"Image-to-Text\"\n        },\n        {\n            \"step_description\": \"Merge the textual information from the audio and image to generate a combined textual description.\",\n            \"task_name\": \"Text Merging\"\n        },\n        {\n            \"step_description\": \"Use the combined textual description to guide the Image Editing process.\",\n            \"task_name\": \"Image Editing\"\n        },\n        {\n            \"step_description\": \"Load the modified image and perform Depth Estimation to analyze the depth of objects in the image.\",\n            \"task_name\": \"Depth Estimation\"\n        },\n        {\n            \"step_description\": \"Output the modified image and depth estimation results.\",\n            \"task_name\": \"Output\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Automatic Speech Recognition\",\n        \"Text Parsing\",\n        \"Image-to-Text\",\n        \"Text Merging\",\n        \"Image Editing\",\n        \"Depth Estimation\",\n        \"Output\"\n    ],\n    \"task_links\": [\n        {\"source\": \""
"{\n    \"task_steps\": [\n        \"Load image 'example.jpg' for table processing\",\n        \"Identify and extract yellow columns from the table image\",\n        \"Change column colors from yellow to blue\",\n        \"Load target image 'target_example.png' for style transfer\",\n        \"Apply style transfer to the modified table image to make it similar to target image\",\n        \"Perform table content classification using a suitable model\",\n        \"Translate the classification result into French using a translation model\",\n        \"Generate speech audio from the translated text using a text-to-speech model\",\n        \"Recognize a command from the speech audio using an automatic speech recognition model\",\n        \"Generate a video based on the recognized command\"\n    ],\n    \"task_nodes\": [\n        \"Image Classification (Tabular Classification)\",\n        \"Text Generation (Text-to-Speech)\",\n        \"Audio Classification (Automatic Speech Recognition)\",\n        \"Video Generation\",\n        \"Image Editing (Image-to-Image)\",\n        \"Translation (Text-to-Text)\",\n        \"Text Generation (Text-to-Text)\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Image Classification (Tabular Classification)\", \"target\": \"Text Generation (Text-to-Text)\"},\n        {\"source\": \"Text Generation (Text-to-Text)\", \"target\": \"Text Generation (Text-to-Speech)\"},\n        {\"source\": \"Text Generation (Text-to-Speech)\", \"target\": \"Audio Classification (Automatic Speech Recognition)\"},\n        {\"source\": \"Audio Classification (Automatic Speech Recognition)\", \"target\": \"Video Generation\"},\n        {\"source\": \"Image Editing (Image-to-Image)\","
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Perform image classification on the provided image (example.jpg) to identify it as a table image.\",\n            \"task_name\": \"Image Classification\"\n        },\n        {\n            \"step_description\": \"Perform object detection on the classified table image to locate the table and extract its bounding box.\",\n            \"task_name\": \"Object Detection\"\n        },\n        {\n            \"step_description\": \"Extract the table data from the bounding box.\",\n            \"task_name\": \"Text Extraction\"\n        },\n        {\n            \"step_description\": \"Perform tabular classification on the extracted table data to ensure it is in the correct format.\",\n            \"task_name\": \"Tabular Classification\"\n        },\n        {\n            \"step_description\": \"Parse the classified table data and find the row with the highest value in column C.\",\n            \"task_name\": \"Data Processing\"\n        },\n        {\n            \"step_description\": \"Return the result containing the row number with the highest value in column C.\",\n            \"task_name\": \"Question Answering\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Image Classification\",\n        \"Object Detection\",\n        \"Text Extraction\",\n        \"Tabular Classification\",\n        \"Data Processing\",\n        \"Question Answering\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Image Classification\", \"target\": \"Object Detection\"},\n        {\"source\": \"Object Detection\", \"target\": \"Text Extraction\"},\n        {\"source\": \"Text Extraction\", \"target\": \"Tabular Classification\"},\n        {\"source\": \""
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Load and preprocess the audio file 'example.wav' for text extraction using Automatic Speech Recognition (ASR) task.\"\n        },\n        {\n            \"step_description\": \"Invoke ASR task to extract text from the audio file.\"\n        },\n        {\n            \"step_description\": \"Load and preprocess the text extracted from the audio file for conversation generation using Text Generation task.\"\n        },\n        {\n            \"step_description\": \"Invoke Text Generation task to generate a conversation based on the given keywords.\"\n        },\n        {\n            \"step_description\": \"Load and preprocess the conversation text and document image 'example.jpg' for entity identification using Named Entity Recognition (NER) task.\"\n        },\n        {\n            \"step_description\": \"Invoke NER task to identify specific entities from the conversation text.\"\n        },\n        {\n            \"step_description\": \"Load and preprocess the conversation text and identified entities for question answering using Document Question Answering (DQA) task.\"\n        },\n        {\n            \"step_description\": \"Invoke DQA task to answer a question related to the identified entities.\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Automatic Speech Recognition (ASR)\",\n        \"Text Generation\",\n        \"Named Entity Recognition (NER)\",\n        \"Document Question Answering (DQA)\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Automatic Speech Recognition (ASR)\", \"target\": \"Text Generation\"},\n        {\"source\": \"Text Generation\", \"target\": \"Named Entity Recognition (NER)\"},\n        {\"source\": \"Named"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Load the audio file 'example.wav' for emotion and speaker's preference analysis.\",\n            \"task_name\": \"Automatic Speech Recognition\"\n        },\n        {\n            \"step_description\": \"Extract emotions and speaker's preferences from the transcribed text.\",\n            \"task_name\": \"Text Classification\"\n        },\n        {\n            \"step_description\": \"Load the image 'example.jpg' for modification.\",\n            \"task_name\": \"Image Classification\"\n        },\n        {\n            \"step_description\": \"Determine the emotion category based on the extracted emotions.\",\n            \"task_name\": \"Emotion Recognition\"\n        },\n        {\n            \"step_description\": \"Apply the appropriate image enhancement techniques based on the emotion category and speaker's preference.\",\n            \"task_name\": \"Image Editing\"\n        },\n        {\n            \"step_description\": \"Save the modified image with a new name.\",\n            \"task_name\": \"Image Saving\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Automatic Speech Recognition\",\n        \"Text Classification\",\n        \"Image Classification\",\n        \"Emotion Recognition\",\n        \"Image Editing\",\n        \"Image Saving\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text Classification\"},\n        {\"source\": \"Text Classification\", \"target\": \"Emotion Recognition\"},\n        {\"source\": \"Image Classification\", \"target\": \"Image Editing\"},\n        {\"source\": \"Emotion Recognition\", \"target\": \"Image Editing"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Perform text-to-speech conversion to generate an audio file from the given text: 'Rainy clouds are forming in the sky.'\",\n            \"task_name\": \"Text-to-Speech\"\n        },\n        {\n            \"step_description\": \"Invoke an audio enhancement API to improve the quality of the generated audio file\",\n            \"task_name\": \"Audio-to-Audio\"\n        },\n        {\n            \"step_description\": \"Perform automatic speech recognition to transcribe the enhanced audio back to text\",\n            \"task_name\": \"Automatic Speech Recognition\"\n        },\n        {\n            \"step_description\": \"Use the transcribed text to search for and download a more relevant image based on the given text: 'What is the weather like in the image?'\",\n            \"task_name\": \"Document Question Answering\"\n        },\n        {\n            \"step_description\": \"Invoke an image-to-text API to extract textual information from the downloaded image\",\n            \"task_name\": \"Image-to-Text\"\n        },\n        {\n            \"step_description\": \"Answer the question: 'What is the weather like in the image?' based on the extracted textual information\",\n            \"task_name\": \"Question Answering\"\n        },\n        {\n            \"step_description\": \"Generate a video based on the answer using a text-to-video API\",\n            \"task_name\": \"Text-to-Video\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Text-to-Speech\",\n        \"Audio-to-Audio\",\n        \"Automatic Speech Recognition\",\n       "
"{\n    \"task_steps\": [\n        \"Load 'example.wav' audio file\",\n        \"Apply audio enhancement techniques to improve audio quality\",\n        \"Perform Automatic Speech Recognition (ASR) to transcribe the enhanced audio to text\",\n        \"Preprocess the reference text 'Hello, welcome to the conference.' by tokenizing and normalizing it\",\n        \"Perform Text-to-Text Comparison to calculate similarity score between the transcribed text and the reference text\"\n    ],\n    \"task_nodes\": [\n        {\n            \"task_name\": \"Audio Editing\",\n            \"input\": {\"audio_file\": \"example.wav\"},\n            \"output\": {\"enhanced_audio_file\": \"enhanced_example.wav\"}\n        },\n        {\n            \"task_name\": \"Automatic Speech Recognition\",\n            \"input\": {\"audio_file\": \"enhanced_example.wav\"},\n            \"output\": {\"transcribed_text\": \"transcribed_text.txt\"}\n        },\n        {\n            \"task_name\": \"Text Preprocessing\",\n            \"input\": {\"reference_text\": \"Hello, welcome to the conference.\"},\n            \"output\": {\"processed_reference_text\": \"processed_reference_text.txt\"}\n        },\n        {\n            \"task_name\": \"Text-to-Text Comparison\",\n            \"input\": {\"transcribed_text\": \"transcribed_text.txt\", \"processed_reference_text\": \"processed_reference_text.txt\"},\n            \"output\": {\"similarity_score\": \"similarity_score.txt\"}\n        }\n    ],\n    \"task_links\": [\n        {\"source\": \"Audio Ed"
"{\n  \"task_steps\": [\n    \"Load 'example.jpg' into memory\",\n    \"Identify the red car object in the image\",\n    \"Change the color of the red car object to blue\",\n    \"Detect objects present in the modified image\",\n    \"Generate a summarized description of the detected objects\",\n    \"Classify important tokens in the summary\",\n    \"Translate the classified summary into French\",\n    \"Answer the question 'Quelle est la couleur de la voiture?' based on the translated summary and modified image\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image Classification\",\n      \"input\": {\n        \"image_path\": \"example.jpg\",\n        \"object_detection\": true\n      },\n      \"output\": {\n        \"objects_detected\": []\n      }\n    },\n    {\n      \"task_name\": \"Text Generation\",\n      \"input\": {\n        \"objects_detected\": \"${task_nodes[0].output.objects_detected}\",\n        \"summary_template\": \"The image contains the following objects: {objects}\"\n      },\n      \"output\": {\n        \"summary\": \"\"\n      }\n    },\n    {\n      \"task_name\": \"Token Classification\",\n      \"input\": {\n        \"text\": \"${task_nodes[1].output.summary}\"\n      },\n      \"output\": {\n        \"classified_tokens\": []\n      }\n    },\n    {\n      \"task_name\": \"Translation\",\n      \"input\": {\n        \"text\": \"${task_nodes[1].output.summary}\",\n        \"source_language\": \"English\",\n        \"target_language\": \"F"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Load and preprocess the image example.jpg for image classification and object detection tasks.\",\n            \"task_name\": \"Image Preprocessing\"\n        },\n        {\n            \"step_description\": \"Perform image classification to identify the main object in the image.\",\n            \"task_name\": \"Image Classification\"\n        },\n        {\n            \"step_description\": \"Perform object detection to identify the specific animal and its location in the image.\",\n            \"task_name\": \"Object Detection\"\n        },\n        {\n            \"step_description\": \"Extract the identified animal type and its location from the object detection results.\",\n            \"task_name\": \"Data Extraction\"\n        },\n        {\n            \"step_description\": \"Generate a text description about the identified animal and its location.\",\n            \"task_name\": \"Text Generation\"\n        },\n        {\n            \"step_description\": \"Engage in a short conversation about the identified animal and its location.\",\n            \"task_name\": \"Conversational\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Image Preprocessing\",\n        \"Image Classification\",\n        \"Object Detection\",\n        \"Data Extraction\",\n        \"Text Generation\",\n        \"Conversational\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Image Preprocessing\", \"target\": \"Image Classification\"},\n        {\"source\": \"Image Classification\", \"target\": \"Object Detection\"},\n        {\"source\": \"Object Detection\", \"target\": \"Data Extraction\"},\n        {\"source\": \"Data Extraction\", \"target\": \"Text Generation\"},\n        {\"source\": \"Text Generation\", \"target\":"
"{\n  \"task_steps\": [\n    {\n      \"step_description\": \"Load the text description and example image\",\n      \"task_name\": \"Text-to-Image\"\n    },\n    {\n      \"step_description\": \"Generate an image based on the text description\",\n      \"task_name\": \"Text-to-Image\"\n    },\n    {\n      \"step_description\": \"Transform the generated image's appearance to match example.jpg\",\n      \"task_name\": \"Image Editing\"\n    },\n    {\n      \"step_description\": \"Load example.jpg for reference\",\n      \"task_name\": \"Image Loading\"\n    },\n    {\n      \"step_description\": \"Perform image segmentation on the transformed image\",\n      \"task_name\": \"Image Segmentation\"\n    },\n    {\n      \"step_description\": \"Apply object detection to identify objects and their classes in the segmented image\",\n      \"task_name\": \"Object Detection\"\n    }\n  ],\n  \"task_nodes\": [\n    \"Text-to-Image\",\n    \"Image Loading\",\n    \"Image Editing\",\n    \"Image Segmentation\",\n    \"Object Detection\"\n  ],\n  \"task_links\": [\n    {\n      \"source\": \"Text-to-Image\",\n      \"target\": \"Image Editing\"\n    },\n    {\n      \"source\": \"Image Loading\",\n      \"target\": \"Image Editing\"\n    },\n    {\n      \"source\": \"Image Editing\",\n      \"target\": \"Image Segmentation\"\n    },\n    {\n      \"source\": \"Image Segmentation\",\n      \"target\": \"Object Detection\"\n    }"
"```json\n{\n  \"task_steps\": [\n    \"Load the example.jpg image\",\n    \"Perform image-to-image transformation to match the style of the target image\",\n    \"Perform image segmentation on the transformed image\",\n    \"Modify the segmented image to make all objects green as described in the text\",\n    \"Perform image classification on the modified image to assign it a label\",\n    \"Generate a new text based on the image classification label\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image-to-Image\"\n    },\n    {\n      \"task_name\": \"Image Segmentation\"\n    },\n    {\n      \"task_name\": \"Image Editing\"\n    },\n    {\n      \"task_name\": \"Image Classification\"\n    },\n    {\n      \"task_name\": \"Text Generation\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Image-to-Image\", \"target\": \"Image Segmentation\"},\n    {\"source\": \"Image Segmentation\", \"target\": \"Image Editing\"},\n    {\"source\": \"Image Editing\", \"target\": \"Image Classification\"},\n    {\"source\": \"Image Classification\", \"target\": \"Text Generation\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load 'example.jpg' image into memory.\",\n    \"Perform Image Preprocessing.\",\n    \"Execute Image Segmentation task.\",\n    \"Extract segmented objects from the image.\",\n    \"Execute Depth Estimation task.\",\n    \"Extract depth information for each segmented object.\",\n    \"Execute Object Detection task.\",\n    \"Identify and label detected objects.\",\n    \"Compare 'example sentence' with object labels.\",\n    \"Calculate object label similarity scores.\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image Classification\"\n    },\n    {\n      \"task_name\": \"Depth Estimation\"\n    },\n    {\n      \"task_name\": \"Image Segmentation\"\n    },\n    {\n      \"task_name\": \"Object Detection\"\n    },\n    {\n      \"task_name\": \"Text-to-Speech\"\n    },\n    {\n      \"task_name\": \"Sentence Similarity\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification\", \"target\": \"Depth Estimation\"},\n    {\"source\": \"Image Classification\", \"target\": \"Image Segmentation\"},\n    {\"source\": \"Image Segmentation\", \"target\": \"Depth Estimation\"},\n    {\"source\": \"Image Segmentation\", \"target\": \"Object Detection\"},\n    {\"source\": \"Object Detection\", \"target\": \"Sentence Similarity\"},\n    {\"source\": \"Depth Estimation\", \"target\": \"Object Detection\"},\n    {\"source\": \"Object Detection\", \"target\": \"Text-to-Speech\"},\n    {\"source\": \"Text-to-Speech"
"{\n  \"task_steps\": [\n    \"Load the example.jpg image\",\n    \"Apply image-to-style transfer to change the image style\",\n    \"Perform object segmentation on the transformed image\",\n    \"Classify the segmented objects using object detection\",\n    \"Answer the question 'What is the major object in this image?' using the object detection results\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image-to-Text\",\n      \"input\": \"example.jpg\",\n      \"output\": \"text_description_of_image\"\n    },\n    {\n      \"task_name\": \"Text-to-Image\",\n      \"input\": \"text_description_of_image\",\n      \"output\": \"styled_image\"\n    },\n    {\n      \"task_name\": \"Image Segmentation\",\n      \"input\": \"styled_image\",\n      \"output\": \"segmented_objects\"\n    },\n    {\n      \"task_name\": \"Object Detection\",\n      \"input\": \"segmented_objects\",\n      \"output\": \"object_detection_results\"\n    },\n    {\n      \"task_name\": \"Document Question Answering\",\n      \"input\": \"object_detection_results\",\n      \"output\": \"answer\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Image-to-Text\", \"target\": \"Text-to-Image\"},\n    {\"source\": \"Text-to-Image\", \"target\": \"Image Segmentation\"},\n    {\"source\": \"Image Segmentation\", \"target\": \"Object Detection\"},\n    {\"source\": \"Object Detection\", \"target\": \"Document Question Answering"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Perform token classification to identify entities such as dates, individuals, and places in the given text.\"\n        },\n        {\n            \"step_description\": \"Extract the identified entities from the token classification output.\"\n        },\n        {\n            \"step_description\": \"Invoke Text-to-Speech API to convert the identified entities to speech.\"\n        }\n    ],\n    \"task_nodes\": [\n        {\n            \"task_name\": \"Token Classification\"\n        },\n        {\n            \"task_name\": \"Text-to-Speech\"\n        }\n    ],\n    \"task_links\": [\n        {\n            \"source\": \"Token Classification\",\n            \"target\": \"Text-to-Speech\"\n        }\n    ]\n}\n\n# EXPLANATION #:\nThe user request involves identifying specific entities in a text and converting them to speech. To accomplish this, we will first perform token classification to identify entities such as dates, individuals, and places in the text. Once the entities have been identified, we will extract them from the token classification output and then use a Text-to-Speech API to convert them to speech. The task steps and task nodes are aligned, and the task links reflect the dependencies among the tasks, with the Text-to-Speech task depending on the Token Classification task."
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Load the original image 'example.jpg' for image processing.\"\n        },\n        {\n            \"step_description\": \"Perform object detection on the image to identify the red car.\"\n        },\n        {\n            \"step_description\": \"Change the color of the identified red car to blue using text-to-image API.\"\n        },\n        {\n            \"step_description\": \"Perform image segmentation on the modified image to separate the car from the background.\"\n        },\n        {\n            \"step_description\": \"Perform image-to-image API to change the color of the car from red to blue.\"\n        },\n        {\n            \"step_description\": \"Perform image classification on the modified image to ensure the car is still recognizable as a car and the color is correctly changed.\"\n        },\n        {\n            \"step_description\": \"Generate a summary of the image content after the car color change.\"\n        },\n        {\n            \"step_description\": \"Perform text-to-speech API to generate a conversation about the modified image.\"\n        },\n        {\n            \"step_description\": \"Perform automatic speech recognition API to convert the generated conversation to text.\"\n        },\n        {\n            \"step_description\": \"Perform question answering on the text to extract key information from the conversation.\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Image Classification\",\n        \"Object Detection\",\n        \"Text-to-Image\",\n        \"Image Segmentation\",\n        \"Image-to-Image\",\n        \"Text Generation\",\n        \"Text-to-Speech\",\n        \"Automatic Speech Recognition\",\n        \"Question Answ"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Load the audio file 'example.wav' for emotion detection\",\n            \"task_name\": \"Automatic Speech Recognition\"\n        },\n        {\n            \"step_description\": \"Extract emotions from the audio file using Automatic Speech Recognition\",\n            \"task_name\": \"Emotion Detection\"\n        },\n        {\n            \"step_description\": \"Load the image file 'example.jpg' for editing\",\n            \"task_name\": \"Image Classification\"\n        },\n        {\n            \"step_description\": \"Classify the image based on the detected emotion\",\n            \"task_name\": \"Image Editing\"\n        },\n        {\n            \"step_description\": \"Edit the image based on the emotion classification result\",\n            \"task_name\": \"Image Editing\"\n        },\n        {\n            \"step_description\": \"Generate a description of the edited image\",\n            \"task_name\": \"Text Generation\"\n        },\n        {\n            \"step_description\": \"Compare the generated description with the given text 'The edited image should show a calm scenery'\",\n            \"task_name\": \"Text-to-Speech\"\n        },\n        {\n            \"step_description\": \"Speak the comparison result for user confirmation\",\n            \"task_name\": \"Text-to-Speech\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Automatic Speech Recognition\",\n        \"Emotion Detection\",\n        \"Image Classification\",\n        \"Image Editing\",\n        \"Text Generation\",\n        \"Text-to-Speech\"\n    ],\n    \"task_links\": [\n        {\"source"
"{\n    \"task_steps\": [\n        \"Load 'example.wav' for audio processing\",\n        \"Apply audio enhancement techniques to improve the quality of 'example.wav'\",\n        \"Classify the enhanced audio to determine the speaker's emotion using an Emotion Recognition model\",\n        \"Load 'example.jpg' for image processing\",\n        \"Edit the color of the object in 'example.jpg' based on the emotion label\",\n        \"Determine the primary color of the object after editing using an Object Detection and Color Extraction model\",\n        \"Generate a text description of the primary color\",\n        \"Load 'example.mp4' for video processing\",\n        \"Create a video of the text description using the given 'example.mp4'\"\n    ],\n    \"task_nodes\": [\n        \"Audio Enhancement and Emotion Recognition\",\n        \"Image Processing and Object Detection with Color Extraction\",\n        \"Text Generation\",\n        \"Video Generation\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Load 'example.wav' for audio processing\", \"target\": \"Apply audio enhancement techniques to improve the quality of 'example.wav'\"},\n        {\"source\": \"Apply audio enhancement techniques to improve the quality of 'example.wav'\", \"target\": \"Classify the enhanced audio to determine the speaker's emotion using an Emotion Recognition model\"},\n        {\"source\": \"Load 'example.jpg' for image processing\", \"target\": \"Edit the color of the object in 'example.jpg' based on the emotion label\"},\n        {\"source\": \"Edit the color of the object in 'example.jpg' based on the emotion label\", \"target\": \"Determine the primary color of the object after editing using an Object Detection and Color"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Load the audio file 'example.wav' for processing\"\n        },\n        {\n            \"step_description\": \"Apply Automatic Speech Recognition (ASR) to transcribe the audio to text\"\n        },\n        {\n            \"step_description\": \"Preprocess the transcribed text to remove background noise and irrelevant information\"\n        },\n        {\n            \"step_description\": \"Apply Text-to-Speech (TTS) to generate a clear and noise-free audio from the preprocessed text\"\n        },\n        {\n            \"step_description\": \"Apply Text Summarization to extract the key points from the preprocessed text\"\n        },\n        {\n            \"step_description\": \"Apply Text-to-Speech (TTS) to generate a clear and noise-free audio in French for the key points\"\n        },\n        {\n            \"step_description\": \"Output the French audio containing the key points as the final result\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Automatic Speech Recognition\",\n        \"Text Preprocessing\",\n        \"Text Summarization\",\n        \"Text-to-Speech (French)\",\n        \"Text-to-Speech (Clear and noise-free)\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text Preprocessing\"},\n        {\"source\": \"Text Preprocessing\", \"target\": \"Text Summarization\"},\n        {\"source\": \"Text Summarization\", \"target\": \"Text-to-Speech (French)\"},\n        {\"source\": \"Text Preprocessing\", \"target\": \"Text-to-"
"{\n    \"task_steps\": [\n        \"Load image 'example.jpg'\",\n        \"Perform object detection on the loaded image to identify objects and their bounding boxes\",\n        \"For each identified object, invoke image-to-text API to extract object label in English\",\n        \"Invoke text translation API to translate each English object label to French\",\n        \"For each translated French object label, invoke text generation API to generate a descriptive text in French\"\n    ],\n    \"task_nodes\": [\n        \"Image Classification (Object Detection)\",\n        \"Text-to-Text (Translation from English to French)\",\n        \"Text Generation (French descriptive text)\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Image Classification (Object Detection)\", \"target\": \"Text-to-Text (Translation from English to French)\"},\n        {\"source\": \"Text-to-Text (Translation from English to French)\", \"target\": \"Text Generation (French descriptive text)\"},\n        {\"source\": \"Image Classification (Object Detection)\", \"target\": \"Text-to-Text (Translation from English to French)}\n    ]\n}"
"```json\n{\n  \"task_steps\": [\n    \"Load the input image 'example.jpg'.\",\n    \"Perform object detection on the input image to identify and extract all objects in the image.\",\n    \"For each object identified in the previous step, generate a new image focusing on that object.\",\n    \"Perform image classification on each generated image to determine the object's category.\",\n    \"Edit the original image based on the classified information, such as adding labels or highlighting the objects.\",\n    \"Perform text-to-speech conversion on the answer to the question 'How many red objects are in the image?'\",\n    \"Determine the number of red objects in the original image based on the object detection results.\"\n  ],\n  \"task_nodes\": [\n    \"Object Detection\",\n    \"Image Generation for each Object\",\n    \"Image Classification for each Generated Image\",\n    \"Image Editing\",\n    \"Question Answering: 'How many red objects are in the image?'\",\n    \"Text-to-Speech\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Object Detection\", \"target\": \"Image Generation for each Object\"},\n    {\"source\": \"Image Generation for each Object\", \"target\": \"Image Classification for each Generated Image\"},\n    {\"source\": \"Image Classification for each Generated Image\", \"target\": \"Image Editing\"},\n    {\"source\": \"Object Detection\", \"target\": \"Question Answering: 'How many red objects are in the image?'\"},\n    {\"source\": \"Question Answering: 'How many red objects are in the image?'\", \"target\": \"Text-to-Speech\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Read the input text 'The quick brown fox jumps over the lazy dog.' and save it as a variable.\",\n    \"Read the input image 'example.jpg' and save it as a variable.\",\n    \"Use Text-to-Speech API to convert the input text to speech and save the audio file.\",\n    \"Use Automatic Speech Recognition API to transcribe the audio file and extract the speech text.\",\n    \"Use Speech Recognition Summary API to summarize the speech text.\",\n    \"Use Speech Recognition Classification API to classify the summarized speech text.\",\n    \"Use Conversational Response Generation API to generate a conversational response based on the speech classification.\",\n    \"Use Image Editing API to edit the input image based on the conversational response.\",\n    \"Use Object Detection API to detect objects in the edited image.\",\n    \"Use Sentence Similarity API to find the similarity between the conversational response and the object detection results.\"\n  ],\n  \"task_nodes\": [\n    \"Text-to-Speech\",\n    \"Automatic Speech Recognition\",\n    \"Speech Recognition Summary\",\n    \"Speech Recognition Classification\",\n    \"Conversational Response Generation\",\n    \"Image Editing\",\n    \"Object Detection\",\n    \"Sentence Similarity\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Text-to-Speech\", \"target\": \"Automatic Speech Recognition\"},\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Speech Recognition Summary\"},\n    {\"source\": \"Speech Recognition Summary\", \"target\": \"Speech Recognition Classification\"},"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Load the image 'example.png' and perform image preprocessing to extract table data.\",\n            \"task_name\": \"Image-to-Tabular\"\n        },\n        {\n            \"step_description\": \"Classify the table data using the provided image and perform text summarization.\",\n            \"task_name\": \"Image-to-Text (Table Extraction) > Text Classification > Text Summarization\"\n        },\n        {\n            \"step_description\": \"Load the image 'example.jpg' and perform image preprocessing.\",\n            \"task_name\": \"Image-to-Text (Image Preprocessing)\"\n        },\n        {\n            \"step_description\": \"Analyze the context of the table information with the image 'example.jpg' using image-text analysis.\",\n            \"task_name\": \"Image-to-Text (Image Preprocessing) > Text-to-Image > Visual Question Answering\"\n        },\n        {\n            \"step_description\": \"Extract the key information from the table data.\",\n            \"task_name\": \"Tabular Classification > Key Information Extraction\"\n        },\n        {\n            \"step_description\": \"Provide an answer to the question 'What are the key information in the table?' based on the analysis.\",\n            \"task_name\": \"Document Question Answering\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Image-to-Tabular\",\n        \"Text Classification\",\n        \"Text Summarization\",\n        \"Image-to-Text (Table Extraction)\",\n        \"Visual Question Answering\",\n        \"Tabular Classification\",\n        \"Key Information Extraction\",\n        \"Document Question"
"```json\n{\n  \"task_steps\": [\n    \"Load 'example.jpg' image\",\n    \"Apply red color filter to the tree in the image\",\n    \"Save the edited image as 'red_tree.jpg'\",\n    \"Classify the 'red_tree.jpg' image using Image Classification API\",\n    \"Store the classification result\",\n    \"Initiate a conversational interaction based on the image classification result\",\n    \"Generate text based on the conversational interaction\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image Editing\",\n      \"input\": {\n        \"image_path\": \"example.jpg\",\n        \"output_path\": \"red_tree.jpg\",\n        \"operation\": \"Apply color filter\",\n        \"color\": \"Red\"\n      }\n    },\n    {\n      \"task_name\": \"Image Classification\",\n      \"input\": {\n        \"image_path\": \"red_tree.jpg\"\n      },\n      \"depends_on\": [\"Image Editing\"]\n    },\n    {\n      \"task_name\": \"Conversational\",\n      \"input\": {\n        \"image_classification_result\": \"${Image Classification output}\"\n      },\n      \"depends_on\": [\"Image Classification\"]\n    },\n    {\n      \"task_name\": \"Text Generation\",\n      \"input\": {\n        \"conversational_interaction\": \"${Conversational output}\"\n      },\n      \"depends_on\": [\"Conversational\"]\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Editing\", \"target\": \"Image Classification\"},\n    {\"source\": \"Image Classification\", \"target\": \"Con"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Perform text-to-image generation based on the given text description 'A cute kitten playing with a ball of yarn in a cozy room'.\",\n            \"task_name\": \"Text-to-Image\"\n        },\n        {\n            \"step_description\": \"Generate an image based on the text description from the Text-to-Image API.\",\n            \"task_name\": \"Text-to-Image_Generation\"\n        },\n        {\n            \"step_description\": \"Change the kitten's fur color to white in the generated image.\",\n            \"task_name\": \"Image-Editing_Change_Fur_Color\"\n        },\n        {\n            \"step_description\": \"Change the yarn color to red in the edited image.\",\n            \"task_name\": \"Image-Editing_Change_Yarn_Color\"\n        },\n        {\n            \"step_description\": \"Perform image-to-text generation based on the edited image.\",\n            \"task_name\": \"Image-to-Text\"\n        },\n        {\n            \"step_description\": \"Generate a text description from the edited image using the Image-to-Text API.\",\n            \"task_name\": \"Image-to-Text_Generation\"\n        },\n        {\n            \"step_description\": \"Compare the similarity between the original text description and the generated text description.\",\n            \"task_name\": \"Text_Similarity\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Text-to-Image_Generation\",\n        \"Image-Editing_Change_Fur_Color\",\n        \"Image-Editing_Change_Yarn_Color\",\n        \"Image"
"```json\n{\n  \"task_steps\": [\n    \"Load the audio file 'example.wav' for Automatic Speech Recognition.\",\n    \"Perform Automatic Speech Recognition to extract the instructions from the audio file.\",\n    \"Load the image file 'example.jpg' for Object Detection.\",\n    \"Perform Object Detection on the image to identify the object mentioned in the instructions.\",\n    \"Output the result: Object name and its location in the image.\"\n  ],\n  \"task_nodes\": [\n    \"Automatic Speech Recognition\",\n    \"Object Detection\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Object Detection\"}\n  ]\n}\n```"
"{\n    \"task_steps\": [\n        {\n            \"step\": \"User uploads audio clip 'example.wav'\",\n            \"description\": \"The user provides an audio clip 'example.wav' for processing.\"\n        },\n        {\n            \"step\": \"Automatic Speech Recognition\",\n            \"description\": \"ASR is used to transcribe the user's request for directions to the nearest cafe.\"\n        },\n        {\n            \"step\": \"Emotion Detection\",\n            \"description\": \"Emotion detection is applied to the user's speech to determine their emotional state.\"\n        },\n        {\n            \"step\": \"Text-to-Image\",\n            \"description\": \"Based on the detected emotion, a tailored image is generated using text-to-image model.\"\n        },\n        {\n            \"step\": \"Image Processing and Formatting\",\n            \"description\": \"The generated image is processed and formatted for optimal display.\"\n        },\n        {\n            \"step\": \"Response Generation\",\n            \"description\": \"A tailored response containing the generated image is created for the user.\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Automatic Speech Recognition\",\n        \"Emotion Detection\",\n        \"Text-to-Image\",\n        \"Image Processing and Formatting\",\n        \"Response Generation\"\n    ],\n    \"task_links\": [\n        {\"source\": \"User uploads audio clip 'example.wav'\", \"target\": \"Automatic Speech Recognition\"},\n        {\"source\": \"Automatic Speech Recognition\", \"target\": \"Emotion Detection\"},\n        {\"source\": \"Emotion Detection\", \"target\": \"Text-to-Image\"},\n        {\"source\": \""
"{\n    \"task_steps\": [\n        \"Load 'example.wav' audio file\",\n        \"Perform Automatic Speech Recognition (ASR) on 'example.wav' to extract text\",\n        \"Perform Emotion Detection on the transcribed text from ASR\",\n        \"Perform Command Detection on the transcribed text from ASR\",\n        \"Load 'example.jpg' image file\",\n        \"Perform Object Detection on 'example.jpg' to identify the subject\",\n        \"Perform Image-to-Text conversion to extract text from 'example.jpg'\",\n        \"Perform Image Classification on 'example.jpg' to understand the scene\",\n        \"Compare the results from Emotion Detection, Command Detection, Object Detection, and Image Classification\",\n        \"Load 'Visual impacts on emotions and commands are crucial for understanding human reactions' reference text\",\n        \"Perform Document Question Answering (DQA) on the reference text to extract more details about visual impacts on emotions and commands\",\n        \"Generate a summary of the findings from the audio, image, and reference text\",\n        \"Perform Text-to-Speech conversion to create an audio summary\",\n        \"Perform Translation of the summary text to the desired language\",\n        \"Perform Text-to-Video conversion using 'example.mp4' to create a video summary\"\n    ],\n    \"task_nodes\": [\n        \"Automatic Speech Recognition\",\n        \"Emotion Detection\",\n        \"Command Detection\",\n        \"Object Detection\",\n        \"Image Classification\",\n        \"Image-to-Text conversion\",\n        \"Document Question Answering\",\n        \"Text-to-Speech conversion\",\n        \"Translation\",\n        \"Text-to"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Translate the given text to French\"\n        },\n        {\n            \"step_description\": \"Generate speech audio from the translated text\"\n        },\n        {\n            \"step_description\": \"Enhance the speech audio quality\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Text-to-Speech\",\n        \"Automatic Speech Recognition\",\n        \"Audio Editing\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Text-to-Speech\", \"target\": \"Automatic Speech Recognition\"},\n        {\"source\": \"Automatic Speech Recognition\", \"target\": \"Audio Editing\"}\n    ]\n}\n\n# EXPLANATION #:\n# The user request involves translating a text to French, generating speech audio from the translated text, and enhancing the speech audio quality.\n# To fulfill this request, we will first execute the \"Text-to-Speech\" task node to translate the given text to French.\n# The output of this task will be a translated text, which will be passed as input to the \"Automatic Speech Recognition\" task node.\n# This task will generate speech audio from the translated text.\n# Finally, the \"Audio Editing\" task node will be executed to enhance the quality of the generated speech audio.\n# The task steps are aligned with the task nodes, and the number of task steps is the same as the number of task nodes.\n# The task links reflect the dependencies among the task nodes, indicating the order in which they should be invoked."
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Perform text summarization on the given input text.\",\n            \"task_name\": \"Text Summarization\"\n        },\n        {\n            \"step_description\": \"Edit the image 'example.jpg' to match the summarized description.\",\n            \"task_name\": \"Image-to-Text, Text-to-Image\"\n        },\n        {\n            \"step_description\": \"Perform object detection and image segmentation on the edited image to identify and extract the balls.\",\n            \"task_name\": \"Object Detection, Image Segmentation\"\n        },\n        {\n            \"step_description\": \"Estimate the depth of the detected objects in the edited image.\",\n            \"task_name\": \"Depth Estimation\"\n        },\n        {\n            \"step_description\": \"Determine which ball is closer to the viewer based on the depth estimation.\",\n            \"task_name\": \"Question Answering\"\n        },\n        {\n            \"step_description\": \"Compare the answer to the reference answer.\",\n            \"task_name\": \"Question Answering\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Text Summarization\",\n        \"Image-to-Text\",\n        \"Text-to-Image\",\n        \"Object Detection\",\n        \"Image Segmentation\",\n        \"Depth Estimation\",\n        \"Question Answering\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Text Summarization\", \"target\": \"Image-to-Text\"},\n        {\"source\": \"Image-to-Text\", \"target\": \"Text-to-Image\"},\n        {\"source\": \"Text-to-Image\", \"target\": \""
"```json\n{\n  \"task_steps\": [\n    \"Load the image 'example.jpg' and perform image preprocessing.\",\n    \"Perform object detection to locate the table in the image.\",\n    \"Perform table segmentation to extract the table region from the image.\",\n    \"Perform tabular classification to identify the type of table and its structure.\",\n    \"Extract the text from the table using OCR (Optical Character Recognition).\",\n    \"Perform text summarization to generate a narrative summary of the table content.\",\n    \"Perform text-to-speech to generate an audio summary of the table content.\"\n  ],\n  \"task_nodes\": [\n    \"Image Classification: Image-to-Tabular\",\n    \"Object Detection: Image Object Detection\",\n    \"Text Extraction: OCR\",\n    \"Text Summarization: Text Summarization\",\n    \"Text-to-Speech: Text-to-Speech\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification: Image-to-Tabular\", \"target\": \"Object Detection: Image Object Detection\"},\n    {\"source\": \"Object Detection: Image Object Detection\", \"target\": \"Text Extraction: OCR\"},\n    {\"source\": \"Text Extraction: OCR\", \"target\": \"Text Summarization: Text Summarization\"},\n    {\"source\": \"Text Summarization: Text Summarization\", \"target\": \"Text-to-Speech: Text-to-Speech\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load example.jpg image\",\n    \"Perform table classification on the image using Tabular Classification\",\n    \"Extract content from the classified table using Text Extraction\",\n    \"Generate a new image based on the extracted content using Text-to-Image\",\n    \"Estimate the depth of the generated image using Depth Estimation\",\n    \"Determine the most significant object in the generated image using Object Detection and Question Answering\",\n    \"Modify the background of the generated image based on the identified most significant object using Image Editing\",\n    \"Answer the question 'What changes were made?' using Text-to-Speech and Natural Language Processing\",\n    \"Engage in a conversational interaction about the process using Conversational\"\n  ],\n  \"task_nodes\": [\n    \"Tabular Classification\",\n    \"Text Extraction\",\n    \"Text-to-Image\",\n    \"Depth Estimation\",\n    \"Object Detection\",\n    \"Question Answering\",\n    \"Image Editing\",\n    \"Text-to-Speech\",\n    \"Conversational\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification\", \"target\": \"Tabular Classification\"},\n    {\"source\": \"Tabular Classification\", \"target\": \"Text Extraction\"},\n    {\"source\": \"Text Extraction\", \"target\": \"Text-to-Image\"},\n    {\"source\": \"Text-to-Image\", \"target\": \"Depth Estimation\"},\n    {\"source\": \"Depth Estimation\", \"target\": \"Object Detection\"},\n    {\"source\": \"Object Detection\", \"target\": \"Question Answering\"},\n    {\"source\": \"Question Answering\","
"```json\n{\n  \"task_steps\": [\n    \"Load document image example.jpg\",\n    \"Perform Optical Character Recognition (OCR) on the document image to extract text\",\n    \"Use Text Extraction model to identify and extract information about event location, date, and organizer from the extracted text\",\n    \"Use Named Entity Recognition (NER) model to identify specific entities (location, date, organizer) in the extracted text\",\n    \"Use Translation API to translate the extracted information into French\",\n    \"Use Named Entity Recognition (NER) model to identify specific entities (location, date, organizer) in the translated text\",\n    \"Use Text-to-Speech API to convert the recognized entities into speech\"\n  ],\n  \"task_nodes\": [\n    \"Image-to-Text\",\n    \"Text Classification (Text Extraction and NER)\",\n    \"Translation\",\n    \"Text-to-Speech\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image-to-Text\", \"target\": \"Text Classification\"},\n    {\"source\": \"Text Classification\", \"target\": \"Translation\"},\n    {\"source\": \"Translation\", \"target\": \"Text-to-Speech\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    {\n      \"step_description\": \"Load the audio file 'example.wav' for understanding the changes to be made to the image 'example.jpg'\"\n    },\n    {\n      \"step_description\": \"Use the 'Automatic Speech Recognition' task to transcribe the audio file into text\"\n    },\n    {\n      \"step_description\": \"Use the 'Text-to-Image' task to generate an edited image based on the transcribed text\"\n    },\n    {\n      \"step_description\": \"Use the 'Object Detection' task to identify and label the objects in the edited image\"\n    },\n    {\n      \"step_description\": \"Extract the label and color information of the primary object from the Object Detection output\"\n    },\n    {\n      \"step_description\": \"Use the 'Text-to-Speech' task to convert the answer into French text\"\n    },\n    {\n      \"step_description\": \"Use the 'Text-to-French' translation API to translate the French text into spoken French\"\n    },\n    {\n      \"step_description\": \"Output the final result: the type and color of the primary object in the picture, translated into French\"\n    }\n  ],\n  \"task_nodes\": [\n    \"Automatic Speech Recognition\",\n    \"Text-to-Image\",\n    \"Object Detection\",\n    \"Text-to-Speech\",\n    \"Text-to-French\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text-to-Image\"},\n    {\"source\": \"Text-to-Image\", \"target\": \"Object"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Load and preprocess the image example.jpg using an Image Classification API.\",\n            \"task_name\": \"Image Classification\"\n        },\n        {\n            \"step_description\": \"Run the Image Classification API to identify the main object in the image.\",\n            \"task_name\": \"Image Classification\"\n        },\n        {\n            \"step_description\": \"Extract the identified object label as the answer.\",\n            \"task_name\": \"Question Answering\"\n        },\n        {\n            \"step_description\": \"Tokenize the answer into individual words.\",\n            \"task_name\": \"Token Classification\"\n        },\n        {\n            \"step_description\": \"Classify each token in the answer using a Token Classification API.\",\n            \"task_name\": \"Token Classification\"\n        },\n        {\n            \"step_description\": \"Store the classified tokens and their corresponding labels.\",\n            \"task_name\": \"Memory\"\n        },\n        {\n            \"step_description\": \"Load a Translation API.\",\n            \"task_name\": \"Translation\"\n        },\n        {\n            \"step_description\": \"Translate each classified token and its corresponding label from English to French.\",\n            \"task_name\": \"Translation\"\n        },\n        {\n            \"step_description\": \"Store the translated tokens and their corresponding labels.\",\n            \"task_name\": \"Memory\"\n        },\n        {\n            \"step_description\": \"Combine the translated tokens back into a coherent answer.\",\n            \"task_name\": \"Text Generation\"\n        },\n        {\n            \"step_description\": \"Output the final translated answer.\",\n            \"task_name\": \"Text-"
"```json\n{\n  \"task_steps\": [\n    \"Read and understand the user's text: 'In the tranquil valley, a proud lion lays beside a graceful deer and a wise owl perches on a majestic tree'.\",\n    \"Perform text-to-image generation to create an image based on the user's text.\",\n    \"Perform image segmentation to label each element in the image (lion, deer, owl, tree, tranquil valley) for easier understanding.\",\n    \"Perform image-to-text generation to extract labels and descriptions from the segmented image.\",\n    \"Output the labeled image and corresponding text descriptions to the user.\"\n  ],\n  \"task_nodes\": [\n    \"Text-to-Image\",\n    \"Image Segmentation\",\n    \"Image-to-Text\",\n    \"Text Generation\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Text-to-Image\", \"target\": \"Image Segmentation\"},\n    {\"source\": \"Image Segmentation\", \"target\": \"Image-to-Text\"},\n    {\"source\": \"Image-to-Text\", \"target\": \"Text Generation\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Read the text file 'animal_facts.txt' to extract facts about different animals.\",\n    \"Search for the fact related to 'giraffes' in the extracted data.\",\n    \"Generate an image of a 'giraffe' using an Image-to-Text model.\",\n    \"Use an Image Classification model to confirm the generated image is of a 'giraffe'.\",\n    \"Once the image is confirmed as a 'giraffe', extract the fact about giraffes from the text file.\",\n    \"Generate a video based on the extracted fact about giraffes using a Text-to-Video model.\"\n  ],\n  \"task_nodes\": [\n    \"Text Summarization or Extraction (from 'animal_facts.txt')\",\n    \"Text-to-Image (Giraffe)\",\n    \"Image Classification (Giraffe)\",\n    \"Text Extraction (Giraffe fact)\",\n    \"Text-to-Video (Giraffe fact)\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Text Summarization or Extraction (from 'animal_facts.txt')\", \"target\": \"Text-to-Image (Giraffe)\"},\n    {\"source\": \"Text-to-Image (Giraffe)\", \"target\": \"Image Classification (Giraffe)\"},\n    {\"source\": \"Image Classification (Giraffe)\", \"target\": \"Text Extraction (Giraffe fact)\"},\n    {\"source\": \"Text Extraction (Giraffe fact)\", \"target\": \"Text-to-Video (Giraffe fact)\"},\n  ]\n}\n```\n\nThis JSON format represents the task steps, task nodes,"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Load the text document 'example.txt' and perform text summarization.\",\n            \"output_description\": \"The output will be a summarized text.\"\n        },\n        {\n            \"step_description\": \"Invoke Text Summarization API with 'example.txt' as input.\",\n            \"output_description\": \"The output will be a summarized text.\"\n        },\n        {\n            \"step_description\": \"Generate an image from the summarized text.\",\n            \"output_description\": \"The output will be an image representing the summarized text.\"\n        },\n        {\n            \"step_description\": \"Invoke Text-to-Image API with the summarized text as input.\",\n            \"output_description\": \"The output will be an image.\"\n        },\n        {\n            \"step_description\": \"Determine the main topic of the original text document.\",\n            \"output_description\": \"The output will be the main topic.\"\n        },\n        {\n            \"step_description\": \"Invoke Document Question Answering API with 'What is the main topic?' as question and 'example.txt' as input.\",\n            \"output_description\": \"The output will be the main topic.\"\n        },\n        {\n            \"step_description\": \"Print all intermediary outputs.\",\n            \"output_description\": \"The outputs will be the summarized text, the image, and the main topic.\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Text Summarization\",\n        \"Text-to-Image\",\n        \"Document Question Answering\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Text Summarization\", \"target\": \"Text-to-Image\"},"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Load the noisy audio file 'example.wav' for processing\"\n        },\n        {\n            \"step_description\": \"Apply Automatic Speech Recognition (ASR) to transcribe the audio\"\n        },\n        {\n            \"step_description\": \"Use Audio Classification to identify the main topic of the audio\"\n        },\n        {\n            \"step_description\": \"Invoke Text-to-Speech to read out the transcribed audio for human verification and understanding of the main topic\"\n        },\n        {\n            \"step_description\": \"Apply Text Classification or Named Entity Recognition to extract key topics and entities from the transcribed text\"\n        },\n        {\n            \"step_description\": \"Use Text Summarization to generate a summary of the main topic\"\n        },\n        {\n            \"step_description\": \"Formulate a specific question related to the main topic\"\n        },\n        {\n            \"step_description\": \"Invoke Document Question Answering to find the answer to the specific question\"\n        }\n    ],\n    \"task_nodes\": [\n        {\n            \"task_name\": \"Automatic Speech Recognition\"\n        },\n        {\n            \"task_name\": \"Audio Classification\"\n        },\n        {\n            \"task_name\": \"Text-to-Speech\"\n        },\n        {\n            \"task_name\": \"Text Classification or Named Entity Recognition\"\n        },\n        {\n            \"task_name\": \"Text Summarization\"\n        },\n        {\n            \"task_name\": \"Document Question Answering\"\n        }\n    ],\n    \"task_links\":"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Load the audio file 'example.wav' for automatic speech recognition.\",\n            \"task_name\": \"Automatic Speech Recognition\"\n        },\n        {\n            \"step_description\": \"Recognize the spoken language in the audio file.\",\n            \"task_name\": \"Language Detection\"\n        },\n        {\n            \"step_description\": \"Transcribe the spoken words from the audio file in Spanish.\",\n            \"task_name\": \"Speech-to-Text\"\n        },\n        {\n            \"step_description\": \"Translate the Spanish text to English.\",\n            \"task_name\": \"Translation\"\n        },\n        {\n            \"step_description\": \"Load the image file 'example.jpg' for image processing and question answering.\",\n            \"task_name\": \"Image Processing\"\n        },\n        {\n            \"step_description\": \"Extract information from the image that is relevant to the user's question.\",\n            \"task_name\": \"Image-to-Text\"\n        },\n        {\n            \"step_description\": \"Formulate a response based on the translated command and the image information.\",\n            \"task_name\": \"Text Generation\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Automatic Speech Recognition\",\n        \"Language Detection\",\n        \"Speech-to-Text\",\n        \"Translation\",\n        \"Image Processing\",\n        \"Image-to-Text\",\n        \"Text Generation\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Automatic Speech Recognition\", \"target\": \"Language Detection\"},\n        {\"source\": \"Language Detection\", \"target"
"{\n    \"task_steps\": [\n        \"Load audio file 'example.wav' for audio processing\",\n        \"Apply audio enhancement techniques to improve audio quality\",\n        \"Perform Automatic Speech Recognition (ASR) on enhanced audio to extract text\",\n        \"Analyze the emotion of the speaker using Text-based Emotion Recognition model\",\n        \"Load image file 'example.jpg' for image processing\",\n        \"Perform Object Detection on image to locate and extract person's face\",\n        \"Detect and modify facial expressions in the image based on detected emotion\",\n        \"Save modified image with emotion label\"\n    ],\n    \"task_nodes\": [\n        \"Audio Enhancement\",\n        \"Automatic Speech Recognition\",\n        \"Text-based Emotion Recognition\",\n        \"Object Detection\",\n        \"Facial Expression Modification\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Load audio file 'example.wav' for audio processing\", \"target\": \"Audio Enhancement\"},\n        {\"source\": \"Audio Enhancement\", \"target\": \"Perform Automatic Speech Recognition on enhanced audio to extract text\"},\n        {\"source\": \"Perform Automatic Speech Recognition on enhanced audio to extract text\", \"target\": \"Analyze the emotion of the speaker using Text-based Emotion Recognition\"},\n        {\"source\": \"Load image file 'example.jpg' for image processing\", \"target\": \"Object Detection\"},\n        {\"source\": \"Object Detection\", \"target\": \"Detect and modify facial expressions in the image based on detected emotion\"},\n        {\"source\": \"Detect and modify facial expressions in the image based on detected emotion\", \"target\": \"Save modified image with emotion label"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Load the text document 'example.txt' for analysis.\"\n        },\n        {\n            \"step_description\": \"Perform Text Summarization to extract the main topics from the document.\"\n        },\n        {\n            \"step_description\": \"Use Question Answering model to identify the main topic from the summarized text.\"\n        },\n        {\n            \"step_description\": \"Generate a paraphrased answer for the main topic using Text Generation.\"\n        },\n        {\n            \"step_description\": \"Use Text-to-Speech API to convert the paraphrased answer into an audio response.\"\n        },\n        {\n            \"step_description\": \"Use additional related information from the document, if available, and summarize it.\"\n        },\n        {\n            \"step_description\": \"Use Text Generation to paraphrase the related information.\"\n        },\n        {\n            \"step_description\": \"Combine the paraphrased main topic answer and related information into a coherent response.\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Text Summarization\",\n        \"Question Answering\",\n        \"Text Generation\",\n        \"Text-to-Speech\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Text Summarization\", \"target\": \"Question Answering\"},\n        {\"source\": \"Question Answering\", \"target\": \"Text Generation\"},\n        {\"source\": \"Text Generation\", \"target\": \"Text-to-Speech\"},\n        {\"source\": \"Text Summarization\", \"target\": \"Text Generation\"},\n        {\"source\": \"Text Summarization\", \"target\": \"Text Generation\"}\n    ]\n"
"{\n    \"task_steps\": [\n        \"Load image 'example.jpg'\",\n        \"Perform object detection on the image to identify objects and their bounding boxes\",\n        \"For each detected object, perform image-to-text OCR to extract object labels\",\n        \"Perform image classification on each extracted object label to obtain initial labels\",\n        \"Perform text-to-speech synthesis to pronounce each initial label in English\",\n        \"Perform text translation using a French to English translator to obtain French translations of the initial labels\",\n        \"Perform text-to-speech synthesis to pronounce each French translation\"\n    ],\n    \"task_nodes\": [\n        {\n            \"task_name\": \"Object Detection\"\n        },\n        {\n            \"task_name\": \"Text OCR\"\n        },\n        {\n            \"task_name\": \"Image Classification\"\n        },\n        {\n            \"task_name\": \"Text Translation\"\n        },\n        {\n            \"task_name\": \"Text-to-Speech (English)\"\n        },\n        {\n            \"task_name\": \"Text-to-Speech (French)\"\n        }\n    ],\n    \"task_links\": [\n        {\"source\": \"Object Detection\", \"target\": \"Text OCR\"},\n        {\"source\": \"Text OCR\", \"target\": \"Image Classification\"},\n        {\"source\": \"Image Classification\", \"target\": \"Text Translation\"},\n        {\"source\": \"Text Translation\", \"target\": \"Text-to-Speech (English)\"},\n        {\"source\": \"Text Translation\", \"target\": \"Text-to-Speech (French)\"},\n    ]\n}"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Load the image 'example.jpg' for image processing tasks.\"\n        },\n        {\n            \"step_description\": \"Perform image segmentation to separate the objects in the image from the background.\"\n        },\n        {\n            \"step_description\": \"Apply depth estimation to determine the distance of each pixel from the camera.\"\n        },\n        {\n            \"step_description\": \"Identify the objects in the image based on the segmented regions and their depth values.\"\n        },\n        {\n            \"step_description\": \"Determine the closest object to the camera based on the depth values.\"\n        },\n        {\n            \"step_description\": \"Generate a text description of the closest object for text-to-speech conversion.\"\n        },\n        {\n            \"step_description\": \"Convert the text description to speech using text-to-speech API.\"\n        },\n        {\n            \"step_description\": \"Create a video describing the closest object to the camera using the generated speech and the original image.\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Image Segmentation\",\n        \"Depth Estimation\",\n        \"Object Detection\",\n        \"Question Answering\",\n        \"Text-to-Speech\",\n        \"Text Generation\",\n        \"Video Generation\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Image Processing\", \"target\": \"Image Segmentation\"},\n        {\"source\": \"Image Segmentation\", \"target\": \"Depth Estimation\"},\n        {\"source\": \"Depth Estimation\", \"target\": \"Object Detection\"},\n        {\"source\": \"Object Detection\", \"target\": \"Question Answering\"},\n        {\"source"
"```json\n{\n  \"task_steps\": [\n    \"Load the image 'example.jpg'\",\n    \"Perform Object Detection on the loaded image to identify objects in it\",\n    \"Estimate the depth of each identified object using Depth Estimation\",\n    \"Perform Image Segmentation based on the depth estimates to segment each object\",\n    \"Answer the question 'Which object is closest to the camera?' by identifying the object with the minimum depth estimate\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image Classification\"\n    },\n    {\n      \"task_name\": \"Object Detection\"\n    },\n    {\n      \"task_name\": \"Depth Estimation\"\n    },\n    {\n      \"task_name\": \"Image Segmentation\"\n    },\n    {\n      \"task_name\": \"Question Answering\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification\", \"target\": \"Object Detection\"},\n    {\"source\": \"Object Detection\", \"target\": \"Depth Estimation\"},\n    {\"source\": \"Depth Estimation\", \"target\": \"Image Segmentation\"},\n    {\"source\": \"Image Segmentation\", \"target\": \"Question Answering\"}\n  ]\n}\n```\n\nNote: I assumed that Image Classification is not required for the user's request, but if it is, it should be added as the first task node and linked to Object Detection accordingly."
"```json\n{\n  \"task_steps\": [\n    \"Load the example.jpg image.\",\n    \"Perform image-to-text extraction to get text from the image.\",\n    \"Use Object Detection task to identify the object in the image.\",\n    \"Use Image Editing task to invert the color of the identified object.\",\n    \"Use Image Segmentation task to divide the edited image into segments.\"\n  ],\n  \"task_nodes\": [\n    \"Image Classification (for text extraction)\",\n    \"Object Detection\",\n    \"Image Editing\",\n    \"Image Segmentation\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification\", \"target\": \"Text-to-Text\"},\n    {\"source\": \"Object Detection\", \"target\": \"Image Editing\"},\n    {\"source\": \"Image Editing\", \"target\": \"Image Segmentation\"}\n  ]\n}\n```"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Load and preprocess the image 'example.jpg' for table detection and classification.\",\n            \"task_name\": \"Image Classification\"\n        },\n        {\n            \"step_description\": \"Detect and segment the table region from the image.\",\n            \"task_name\": \"Image Segmentation\"\n        },\n        {\n            \"step_description\": \"Classify the table data and perform depth estimation.\",\n            \"task_name\": \"Tabular Classification, Depth Estimation\"\n        },\n        {\n            \"step_description\": \"Extract the classified table data as text.\",\n            \"task_name\": \"Text Extraction\"\n        },\n        {\n            \"step_description\": \"Convert the extracted text into an audio format.\",\n            \"task_name\": \"Text-to-Speech\"\n        },\n        {\n            \"step_description\": \"Apply audio processing to the generated audio.\",\n            \"task_name\": \"Audio Processing\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Image Classification\",\n        \"Image Segmentation\",\n        \"Tabular Classification, Depth Estimation\",\n        \"Text Extraction\",\n        \"Text-to-Speech\",\n        \"Audio Processing\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Image Classification\", \"target\": \"Image Segmentation\"},\n        {\"source\": \"Image Segmentation\", \"target\": \"Tabular Classification, Depth Estimation\"},\n        {\"source\": \"Tabular Classification, Depth Estimation\", \"target\": \"Text Extraction\"},\n        {\"source\": \"Text Extraction\", \"target\": \"Text-"
"{\"task_steps\": [\n\"Read and understand the input text: 'A dog is happily playing with a ball near a tree in a sunny park'.\",\n\"Perform text summarization to extract key information from the input text.\",\n\"Generate a summarized description of the scene based on the key information extracted.\"\n],\n\"task_nodes\": [\n\"Text Summarization\",\n\"Text Generation\"\n],\n\"task_links\": [\n{\"source\": \"Text Classification and Summarization\", \"target\": \"Text Summarization\"},\n{\"source\": \"Text Summarization\", \"target\": \"Text Generation\"}\n]\n}\n\n\"Final summarized description: A dog plays joyfully with a ball in a sunny park, near a tree.\""
"{\n  \"task_steps\": [\n    {\n      \"step_description\": \"Define the conversational text for the digital marketing campaign.\"\n    },\n    {\n      \"step_description\": \"Invoke Conversational task to generate conversational text.\"\n    },\n    {\n      \"step_description\": \"Edit the example.jpg file based on the generated conversational text.\"\n    },\n    {\n      \"step_description\": \"Invoke Text-to-Image task to create a dynamic image.\"\n    },\n    {\n      \"step_description\": \"Identify objects in the edited image.\"\n    },\n    {\n      \"step_description\": \"Invoke Object Detection task.\"\n    },\n    {\n      \"step_description\": \"Determine if there are any 't-shirts' in the picture.\"\n    },\n    {\n      \"step_description\": \"Invoke Question Answering task to identify 't-shirts' in the image.\"\n    }\n  ],\n  \"task_nodes\": [\n    \"Conversational\",\n    \"Text-to-Image\",\n    \"Object Detection\",\n    \"Question Answering\"\n  ],\n  \"task_links\": [\n    {\n      \"source\": \"Define the conversational text for the digital marketing campaign.\",\n      \"target\": \"Invoke Conversational task to generate conversational text.\"\n    },\n    {\n      \"source\": \"Invoke Conversational task to generate conversational text.\",\n      \"target\": \"Edit the example.jpg file based on the generated conversational text.\"\n    },\n    {\n      \"source\": \"Edit the example.jpg file based on the generated conversational text.\",\n      \"target\": \"Invoke Text-to-Image task to create a dynamic image.\"\n   "
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Perform image-to-image transformation to make the example.jpg image match the characteristics of a similar image domain.\",\n            \"task_name\": \"Image-to-Image\"\n        },\n        {\n            \"step_description\": \"Identify objects and labels within the transformed image.\",\n            \"task_name\": \"Object Detection\"\n        },\n        {\n            \"step_description\": \"Create a document with the image and the identified objects and labels.\",\n            \"task_name\": \"Text-to-Text\"\n        },\n        {\n            \"step_description\": \"Answer the question 'what is the main topic of this image?' using the image and the text input.\",\n            \"task_name\": \"Question Answering\"\n        },\n        {\n            \"step_description\": \"Retrieve answers to questions within the document created in step 3.\",\n            \"task_name\": \"Document Question Answering\"\n        },\n        {\n            \"step_description\": \"Generate a video based on these answers.\",\n            \"task_name\": \"Text-to-Video\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Image-to-Image\",\n        \"Object Detection\",\n        \"Text-to-Text\",\n        \"Question Answering\",\n        \"Document Question Answering\",\n        \"Text-to-Video\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Image-to-Image\", \"target\": \"Object Detection\"},\n        {\"source\": \"Object Detection\", \"target\": \"Text-to-Text\"},\n        {\"source\": \"Text-to-Text\", \"target\": \"Question Answering\"},\n"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Perform image classification to identify the main object or scene in the image.\",\n            \"task_name\": \"Image Classification\"\n        },\n        {\n            \"step_description\": \"Use object detection to identify and locate specific objects within the image.\",\n            \"task_name\": \"Object Detection\"\n        },\n        {\n            \"step_description\": \"Generate a summary or description of the image based on the identified objects.\",\n            \"task_name\": \"Text Generation\"\n        },\n        {\n            \"step_description\": \"Initiate a conversational model to discuss the image and its contents.\",\n            \"task_name\": \"Conversational\"\n        },\n        {\n            \"step_description\": \"Transcribe the conversational text into written format.\",\n            \"task_name\": \"Text-to-Speech\"\n            \"Text-to-Text\":\n        },\n        {\n            \"step_description\": \"Convert the transcribed text into written format for final output.\",\n            \"task_name\": \"Text Generation\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Image Classification\",\n        \"Object Detection\",\n        \"Text Generation\",\n        \"Conversational\",\n        \"Text-to-Speech\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Image Classification\", \"target\": \"Object Detection\"},\n        {\"source\": \"Object Detection\", \"target\": \"Text Generation\"},\n        {\"source\": \"Text Generation\", \"target\": \"Conversational\"},\n        {\"source\": \"Conversational\", \"target\": \"Text-to-Speech\"},\n        {\"source\": \"Text Generation\", \"target\": \"Text"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Load and preprocess the input image (example.jpg) for object detection.\"\n        },\n        {\n            \"step_description\": \"Invoke Object Detection API to identify and locate objects in the image.\"\n        },\n        {\n            \"step_description\": \"Extract the identified objects' names and their respective bounding boxes.\"\n        },\n        {\n            \"step_description\": \"Use Text-to-Speech API to read out the identified objects' names.\"\n        },\n        {\n            \"step_description\": \"Preprocess the question: 'What furniture is in the room?' for Question Answering.\"\n        },\n        {\n            \"step_description\": \"Invoke Question Answering API to extract the answer to the question from the text.\"\n        },\n        {\n            \"step_description\": \"Generate a summary of the answer using Text Summarization API.\"\n        },\n        {\n            \"step_description\": \"Create a new video frame with a text overlay of the summary.\"\n        },\n        {\n            \"step_description\": \"Repeat the previous step for each identified object, adding their names to the video frames.\"\n        },\n        {\n            \"step_description\": \"Combine all the video frames into a single video file.\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Object Detection\",\n        \"Text-to-Speech\",\n        \"Question Answering\",\n        \"Text Summarization\",\n        \"Video Generation\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Object Detection\", \"target\": \"Text-to-Speech\"},\n        {\"source\": \"Object Detection\", \"target\": \"Question An"
"```json\n{\n  \"task_steps\": [\n    \"Load the example.jpg image\",\n    \"Perform image preprocessing\",\n    \"Run image segmentation to identify individual objects in the image\",\n    \"Run depth estimation to estimate the depth of each object in the image\",\n    \"Identify the object with the minimum depth value as the closest object to the camera\",\n    \"Generate text description about the closest object\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image Classification\"\n    },\n    {\n      \"task_name\": \"Image Segmentation\"\n    },\n    {\n      \"task_name\": \"Depth Estimation\"\n    },\n    {\n      \"task_name\": \"Text Generation\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification\", \"target\": \"Image Segmentation\"},\n    {\"source\": \"Image Segmentation\", \"target\": \"Depth Estimation\"},\n    {\"source\": \"Depth Estimation\", \"target\": \"Text Generation\"}\n  ]\n}\n```\n\nNote: I assumed \"Image Classification\" was a typo and changed it to \"Image Preprocessing\" as it is not mentioned in the user request. If the user intended to use Image Classification, please let me know and I will update the JSON accordingly."
"```json\n{\n  \"task_steps\": [\n    \"Load the audio file 'example.wav' for speech recognition.\",\n    \"Perform automatic speech recognition on the audio file to extract the user's instructions.\",\n    \"Load the image file 'example.jpg' for image processing.\",\n    \"Perform image segmentation on the image to identify and separate the objects.\",\n    \"Perform object detection on the segmented image to identify the objects and their locations.\",\n    \"Apply the user's instructions to modify the detected objects in the image.\",\n    \"Create a new image 'example_modified.jpg' with the modified objects.\",\n    \"Create a new video 'example.mp4' by combining the original image 'example.jpg' and the modified image 'example_modified.jpg'\",\n    \"Save the video 'example.mp4'\"\n  ],\n  \"task_nodes\": [\n    \"Automatic Speech Recognition\",\n    \"Image Segmentation\",\n    \"Object Detection\",\n    \"Text-to-Image\",\n    \"Image Processing\",\n    \"Video Creation\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Image Segmentation\"},\n    {\"source\": \"Image Segmentation\", \"target\": \"Object Detection\"},\n    {\"source\": \"Object Detection\", \"target\": \"Text-to-Image\"},\n    {\"source\": \"Text-to-Image\", \"target\": \"Image Processing\"},\n    {\"source\": \"Image Processing\", \"target\": \"Video Creation\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    {\n      \"step_description\": \"Perform image segmentation to identify and extract individual segments from the image.\"\n    },\n    {\n      \"step_description\": \"Classify each segment using image classification API to determine the object class.\"\n    },\n    {\n      \"step_description\": \"Extract entities (dates, individuals, places) from the class names using Named Entity Recognition (NER) model.\"\n    },\n    {\n      \"step_description\": \"Identify the main object based on the segment with the highest confidence class.\"\n    },\n    {\n      \"step_description\": \"Determine the location of the main object by analyzing the class name and entity information.\"\n    },\n    {\n      \"step_description\": \"Summarize the overall context of the image based on the class names and entities identified.\"\n    },\n    {\n      \"step_description\": \"Answer the given questions using the information obtained from the previous steps.\"\n    }\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image Segmentation\"\n    },\n    {\n      \"task_name\": \"Image Classification\"\n    },\n    {\n      \"task_name\": \"Named Entity Recognition\"\n    },\n    {\n      \"task_name\": \"Question Answering\"\n    }\n  ],\n  \"task_links\": [\n    {\n      \"source\": \"Image Segmentation\",\n      \"target\": \"Image Classification\"\n    },\n    {\n      \"source\": \"Image Classification\",\n      \"target\": \"Named Entity Recognition\"\n    },\n    {\n      \"source\": \"Named Entity Recognition\",\n     "
"```json\n{\n  \"task_steps\": [\n    \"Load and preprocess conversation prompt 'What are the benefits of exercising regularly?'\",\n    \"Invoke conversational model for generating response based on the prompt\",\n    \"Store generated conversational response\",\n    \"Load and preprocess image 'example.jpg'\",\n    \"Invoke image-to-text model to extract text from the image (if any)\",\n    \"Load and preprocess summarization model with the conversational response as input\",\n    \"Invoke summarization model to generate summarized version of the conversational response\",\n    \"Store summarized conversational response\",\n    \"Invoke image editing model with the image 'example.jpg' and the summarized conversational response as inputs\",\n    \"Save edited image with the person engaging in exercise\"\n  ],\n  \"task_nodes\": [\n    \"Conversational Model (Token Classification, Translation, Summarization, Question Answering, Conversational)\",\n    \"Image-to-Text Model (Image-to-Text)\",\n    \"Summarization Model (Summarization)\",\n    \"Image Editing Model (Image Editing)\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Load and preprocess conversation prompt\", \"target\": \"Invoke conversational model\"},\n    {\"source\": \"Invoke conversational model\", \"target\": \"Store generated conversational response\"},\n    {\"source\": \"Load and preprocess image\", \"target\": \"Invoke image-to-text model\"},\n    {\"source\": \"Invoke image-to-text model\", \"target\": \"Load and preprocess summarization model\"},\n    {\"source\": \"Load and preprocess summarization model\", \"target\": \"Invoke summarization model\"},\n    {\"source\": \"Invoke summarization model\", \"target\": \"Store summarized conversational"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Perform text-to-speech conversion with emotion recognition\",\n            \"task_name\": \"Text-to-Speech\",\n            \"output\": \"Speech output in English with recognized emotions\"\n        },\n        {\n            \"step_description\": \"Perform emotion-based classification on the input text\",\n            \"task_name\": \"Emotion Classification\",\n            \"input\": \"English news article\",\n            \"output\": \"Emotion classification result\"\n        },\n        {\n            \"step_description\": \"Summarize the emotion-based classification result\",\n            \"task_name\": \"Text Summarization\",\n            \"input\": \"Emotion classification result\",\n            \"output\": \"Summarized emotion-based classification result\"\n        },\n        {\n            \"step_description\": \"Perform text translation into French\",\n            \"task_name\": \"Text-to-Text Translation\",\n            \"input\": \"English news article\",\n            \"output\": \"French translation of the news article\"\n        },\n        {\n            \"step_description\": \"Combine summarized emotion-based classification result and French translation\",\n            \"task_name\": \"Text Merging\",\n            \"input\": [\"Summarized emotion-based classification result\", \"French translation of the news article\"],\n            \"output\": \"Final output in French with summarized emotion-based classification result\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Text-to-Speech\",\n        \"Emotion Classification\",\n        \"Text Summarization\",\n        \"Text-to-Text Translation\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Text-to-"
"```json\n{\n  \"task_steps\": [\n    \"Load 'example.wav' audio file\",\n    \"Perform audio source separation to isolate individual voices\",\n    \"Transcribe the separated audio into text using Automatic Speech Recognition\",\n    \"Enhance the transcribed text using Text-to-Speech\",\n    \"Perform Audio Classification on the enhanced speech\",\n    \"Perform Token Classification on the audio classification result\",\n    \"Generate conversational response based on token classification\",\n    \"Create an image representing the conversational response using Text-to-Image\",\n    \"Extract text from the generated image\"\n  ],\n  \"task_nodes\": [\n    \"Image Editing: Text-to-Image\",\n    \"Text-to-Speech: Automatic Speech Recognition\",\n    \"Speech Recognition: Audio Classification\",\n    \"NLP: Token Classification\",\n    \"NLP: Conversational Response Generation\",\n    \"Audio Processing: Audio Source Separation\",\n    \"Text Processing: Text Extraction\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Audio Processing: Audio Source Separation\", \"target\": \"Text-to-Speech: Automatic Speech Recognition\"},\n    {\"source\": \"Text-to-Speech: Automatic Speech Recognition\", \"target\": \"Speech Recognition: Audio Classification\"},\n    {\"source\": \"Speech Recognition: Audio Classification\", \"target\": \"NLP: Token Classification\"},\n    {\"source\": \"NLP: Token Classification\", \"target\": \"NLP: Conversational Response Generation\"},\n    {\"source\": \"NLP: Conversational Response Generation\", \"target\": \"Image Ed"
"```json\n{\n  \"task_steps\": [\n    \"Load the image 'example.jpg'\",\n    \"Perform image editing: Change color of car to blue and background to grayscale\",\n    \"Save the edited image\",\n    \"Load the saved image for scene analysis\",\n    \"Perform scene analysis\",\n    \"Extract tabular information from the analyzed scene\",\n    \"Compare the extracted tabular information to the given text: 'The car is now blue on a grayscale background'\",\n    \"Compare the results and confirm if they match\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image Classification\",\n      \"task_description\": \"Load the image 'example.jpg'\"\n    },\n    {\n      \"task_name\": \"Image Editing\",\n      \"task_description\": \"Perform image editing: Change color of car to blue and background to grayscale\",\n      \"output\": \"Edited image\"\n    },\n    {\n      \"task_name\": \"Save Image\",\n      \"task_description\": \"Save the edited image\",\n      \"input\": \"Edited image\"\n    },\n    {\n      \"task_name\": \"Scene Analysis\",\n      \"task_description\": \"Load the saved image for scene analysis\",\n      \"input\": \"Saved image\"\n    },\n    {\n      \"task_name\": \"Tabular Classification\",\n      \"task_description\": \"Extract tabular information from the analyzed scene\",\n      \"input\": \"Analyzed scene\"\n    },\n    {\n      \"task_name\": \"Text Comparison\",\n      \"task_description\": \"Compare the extracted tabular information to the given text: 'The car is now blue on a grayscale"
"```json\n{\n  \"task_steps\": [\n    \"Load and preprocess document image (example.jpg)\",\n    \"Perform Image-to-Text OCR to extract text from document image\",\n    \"Perform Text Summarization to extract key points from the document text\",\n    \"Perform Question Answering to identify the answer to the question 'What are the main advantages described in the document?' from the summarized text\",\n    \"Perform Text-to-Speech to convert the answer into speech\",\n    \"Perform Emotion Detection to determine the emotion conveyed by the answer\"\n  ],\n  \"task_nodes\": [\n    \"Image Classification (for document image verification)\",\n    \"Text Generation (for Text Summarization)\",\n    \"Question Answering\",\n    \"Text-to-Speech\",\n    \"Emotion Detection\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification\", \"target\": \"Text Generation\"},\n    {\"source\": \"Text Generation\", \"target\": \"Question Answering\"},\n    {\"source\": \"Question Answering\", \"target\": \"Text-to-Speech\"},\n    {\"source\": \"Text-to-Speech\", \"target\": \"Emotion Detection\"}\n  ]\n}\n```\n\nNote: The first task node \"Image Classification\" is added to ensure the document image is valid before proceeding with the text-based tasks. However, it does not directly contribute to the final answer, so it is not included in the task steps."
"```json\n{\n  \"task_steps\": [\n    \"Load the image 'example.jpg' for processing.\",\n    \"Apply image enhancement techniques to improve the image quality.\",\n    \"Perform image-to-label object detection to identify objects in the enhanced image.\",\n    \"Estimate the depth of objects in the image using depth estimation.\",\n    \"Save the enhanced image, object detection results, and depth estimation output.\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image Classification\",\n      \"task_description\": \"This task is used to classify the image format and validate the input image.\"\n    },\n    {\n      \"task_name\": \"Image Editing\",\n      \"task_description\": \"This task is used to enhance the image quality by adjusting brightness, contrast, and sharpness.\"\n    },\n    {\n      \"task_name\": \"Object Detection\",\n      \"task_description\": \"This task is used to identify and locate objects in the enhanced image using pre-defined labels.\"\n    },\n    {\n      \"task_name\": \"Depth Estimation\",\n      \"task_description\": \"This task is used to estimate the depth of objects in the image using computer vision techniques.\"\n    },\n    {\n      \"task_name\": \"Save Output\",\n      \"task_description\": \"This task is used to save the enhanced image, object detection results, and depth estimation output.\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification\", \"target\": \"Image Editing\"},\n    {\"source\": \"Image Editing\", \"target\": \"Object Detection\"},\n    {\"source\": \"Image Editing\", \"target\": \"Depth Estimation\"},\n    {\"source\": \"Object Detection"
"```json\n{\n  \"task_steps\": [\n    \"Load 'example.wav' audio file\",\n    \"Apply audio denoising to enhance the quality of the audio\",\n    \"Perform speech separation to isolate the command from other sounds\",\n    \"Perform automatic speech recognition (ASR) to extract text from the command\",\n    \"Perform text-to-image generation to create an image representing the command\",\n    \"Perform text extraction from the generated image\",\n    \"Perform text-to-speech synthesis to generate a speech from the extracted text\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Audio Denoising\"\n    },\n    {\n      \"task_name\": \"Speech Separation\"\n    },\n    {\n      \"task_name\": \"Automatic Speech Recognition\"\n    },\n    {\n      \"task_name\": \"Text-to-Image Generation\"\n    },\n    {\n      \"task_name\": \"Text Extraction from Image\"\n    },\n    {\n      \"task_name\": \"Text-to-Speech Synthesis\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Audio Denoising\", \"target\": \"Speech Separation\"},\n    {\"source\": \"Speech Separation\", \"target\": \"Automatic Speech Recognition\"},\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text-to-Image Generation\"},\n    {\"source\": \"Text-to-Image Generation\", \"target\": \"Text Extraction from Image\"},\n    {\"source\": \"Text Extraction from Image\", \"target\": \"Text-to-Speech Synthesis\"}\n "
"```json\n{\n  \"task_steps\": [\n    \"Load 'example.jpg' image\",\n    \"Perform image segmentation on 'example.jpg' to obtain segmented image\",\n    \"Apply image transformation on segmented image to obtain new image\",\n    \"Perform text extraction on transformed image to obtain extracted text\",\n    \"Generate new image based on extracted text\",\n    \"Perform object detection on generated image to identify main object\",\n    \"Perform question answering on 'What is the main object in the generated image?' to obtain answer\",\n    \"Perform translation of answer to French using a translation API\",\n    \"Perform token classification on translated answer using a token classification API\",\n    \"Perform question answering on 'What is the named entity in the classified tokens?' to obtain named entity\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image Segmentation\",\n      \"input\": [\"example.jpg\"],\n      \"output\": [\"segmented_image\"]\n    },\n    {\n      \"task_name\": \"Image Transformation\",\n      \"input\": [\"segmented_image\"],\n      \"output\": [\"transformed_image\"]\n    },\n    {\n      \"task_name\": \"Text Extraction\",\n      \"input\": [\"transformed_image\"],\n      \"output\": [\"extracted_text\"]\n    },\n    {\n      \"task_name\": \"Image Generation\",\n      \"input\": [\"extracted_text\"],\n      \"output\": [\"generated_image\"]\n    },\n    {\n      \"task_name\": \"Object Detection\",\n      \"input\": [\"generated_image\"],\n      \"output\": [\"main_object\"]\n    },\n    {\n      \"task_name\": \"Question An"
"```json\n{\n  \"task_steps\": [\n    \"Load 'example.jpg' image into memory.\",\n    \"Perform object detection on the loaded image to identify red objects.\",\n    \"Modify the color of identified red objects to blue in the image.\",\n    \"Save the modified image with a new name.\",\n    \"Load the saved modified image into memory for depth estimation.\",\n    \"Perform depth estimation on the loaded modified image.\",\n    \"Extract textual output from the depth estimation result.\",\n    \"Perform table classification on the textual output.\",\n    \"Generate speech from the textual output of table classification\"\n  ],\n  \"task_nodes\": [\n    \"Image Editing: Image-to-Image\",\n    \"Computer Vision: Depth Estimation\",\n    \"Natural Language Processing: Text-to-Speech\",\n    \"Computer Vision: Object Detection\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Editing: Image-to-Image\", \"target\": \"Computer Vision: Depth Estimation\"},\n    {\"source\": \"Computer Vision: Depth Estimation\", \"target\": \"Natural Language Processing: Text-to-Speech\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load and preprocess the table image (example.jpg)\",\n    \"Perform table image classification using Image Classification API\",\n    \"Based on the classification result, generate a related image using the Image-to-Image API\",\n    \"Formulate a question about the main theme of the generated image ('What is the main theme of the generated image?')\",\n    \"Use Text-to-Question Answering API to extract the answer from the generated image's caption or metadata\",\n    \"Use Text-to-Speech API to read out the answer\"\n  ],\n  \"task_nodes\": [\n    \"Image Classification\",\n    \"Image-to-Image\",\n    \"Text-to-Question Answering\",\n    \"Text-to-Speech\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification\", \"target\": \"Image-to-Image\"},\n    {\"source\": \"Image-to-Image\", \"target\": \"Text-to-Question Answering\"},\n    {\"source\": \"Text-to-Question Answering\", \"target\": \"Text-to-Speech\"}\n  ]\n}\n```\n\nPlease note that the \"Text-to-Question Answering\" task node assumes that the generated image comes with a caption or metadata that can be used to extract the answer to the question. If this is not the case, additional preprocessing or data generation steps may be required."
"{\n  \"task_steps\": [\n    \"Load the example.wav audio file\",\n    \"Perform Automatic Speech Recognition (ASR) on the audio file to extract text\",\n    \"Load the example.txt file\",\n    \"Perform Text-based Question Answering to extract the question: 'Who played Iron Man in the Marvel movies?'\",\n    \"Perform Web Search or Knowledge Graph Query to find the answer: 'Robert Downey Jr.'\",\n    \"Generate a conversational response: 'The actor who played Iron Man in the Marvel movies is Robert Downey Jr.'\",\n    \"Save the result in an output file\"\n  ],\n  \"task_nodes\": [\n    \"Automatic Speech Recognition\",\n    \"Text-based Question Answering\",\n    \"Web Search or Knowledge Graph Query\",\n    \"Text Generation (Conversational Response)\",\n    \"File I/O (Load example.txt)\",\n    \"File I/O (Save result)\",\n    \"Image/Audio Processing (Load example.wav)\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image/Audio Processing\", \"target\": \"Automatic Speech Recognition\"},\n    {\"source\": \"Text-based Question Answering\", \"target\": \"Web Search or Knowledge Graph Query\"},\n    {\"source\": \"Web Search or Knowledge Graph Query\", \"target\": \"Text Generation (Conversational Response)\"},\n    {\"source\": \"Text Generation (Conversational Response)\", \"target\": \"File I/O (Save result)\"},\n    {\"source\": \"File I/O (Load example.txt)\", \"target\": \"Text-based Question Answering\"},\n    {\"source\": \"Text-based Question Answering\", \"target"
"```json\n{\n  \"task_steps\": [\n    \"Load the document image 'example.jpg'\",\n    \"Perform Optical Character Recognition (OCR) to extract text from the image\",\n    \"Perform Document Question Answering (DQA) to identify the main topic of the document from the extracted text\",\n    \"Generate a related sentence based on the main topic using Text Generation\",\n    \"Perform Sentence Similarity analysis to compare the original question and the newly generated sentence\"\n  ],\n  \"task_nodes\": [\n    \"Image-to-Text\",\n    \"Document Question Answering\",\n    \"Text Generation\",\n    \"Sentence Similarity\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image-to-Text\", \"target\": \"Document Question Answering\"},\n    {\"source\": \"Document Question Answering\", \"target\": \"Text Generation\"},\n    {\"source\": \"Text Generation\", \"target\": \"Sentence Similarity\"}\n  ]\n}\n```"
"```json\n{\n  \"task_steps\": [\n    \"Load image 'example1.jpg' for text enhancement.\",\n    \"Apply text enhancement techniques to improve the clarity of the text in 'example1.jpg'.\",\n    \"Extract text from the enhanced image using Optical Character Recognition (OCR).\",\n    \"Store the extracted text in a variable.\",\n    \"Load image 'example2.jpg' for question answering.\",\n    \"Perform image-to-text conversion to extract relevant information from the dish image.\",\n    \"Determine if the dish is vegetarian based on the extracted information.\",\n    \"Store the vegetarian status in a variable.\",\n    \"Generate an audio file of the vegetarian status using Text-to-Speech.\",\n    \"Improve the audio quality using Audio Editing.\",\n    \"Perform Automatic Speech Recognition to transcribe the audio into text.\",\n    \"Store the transcribed text in a variable.\"\n  ],\n  \"task_nodes\": [\n    \"Text Enhancement\",\n    \"Optical Character Recognition\",\n    \"Question Answering\",\n    \"Image-to-Text\",\n    \"Vegetarian Determination\",\n    \"Text-to-Speech\",\n    \"Audio Editing\",\n    \"Automatic Speech Recognition\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Text Enhancement\", \"target\": \"Optical Character Recognition\"},\n    {\"source\": \"Optical Character Recognition\", \"target\": \"Question Answering\"},\n    {\"source\": \"Question Answering\", \"target\": \"Vegetarian Determination\"},\n    {\"source\": \"Vegetarian Determination\", \"target\": \"Text-to-Spe"
"```json\n{\n  \"task_steps\": [\n    \"Load image from example.jpg\",\n    \"Perform image preprocessing for depth estimation\",\n    \"Invoke Image Depth Estimation API to predict depth of objects in the image\",\n    \"Perform image transformation\",\n    \"Invoke Image Segmentation API to segment the image\",\n    \"Invoke Object Detection API to classify the image and identify primary object\",\n    \"Extract the primary object's label from the classification result\",\n    \"Compare the extracted label with the given text 'a car'\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image Depth Estimation\"\n    },\n    {\n      \"task_name\": \"Image Transformation\"\n    },\n    {\n      \"task_name\": \"Image Segmentation\"\n    },\n    {\n      \"task_name\": \"Object Detection\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Load image from example.jpg\", \"target\": \"Perform image preprocessing for depth estimation\"},\n    {\"source\": \"Perform image preprocessing for depth estimation\", \"target\": \"Invoke Image Depth Estimation API\"},\n    {\"source\": \"Invoke Image Depth Estimation API\", \"target\": \"Perform image transformation\"},\n    {\"source\": \"Perform image transformation\", \"target\": \"Invoke Image Segmentation API\"},\n    {\"source\": \"Invoke Image Segmentation API\", \"target\": \"Invoke Object Detection API\"},\n    {\"source\": \"Invoke Object Detection API\", \"target\": \"Extract the primary object's label from the classification result\"},\n    {\"source\": \"Extract the primary object's label from the classification result\", \"target\": \"Compare the extracted label with the given text"
"```json\n{\n  \"task_steps\": [\n    {\n      \"step_description\": \"Perform image classification to identify objects present in the image.\",\n      \"task_name\": \"Image Classification\"\n    },\n    {\n      \"step_description\": \"Perform object detection to locate and identify the instances of each object in the image.\",\n      \"task_name\": \"Object Detection\"\n    },\n    {\n      \"step_description\": \"Perform image segmentation to separate the pixels of each object from the background.\",\n      \"task_name\": \"Image Segmentation\"\n    },\n    {\n      \"step_description\": \"Perform depth estimation to determine the depth of each object in the image.\",\n      \"task_name\": \"Depth Estimation\"\n    },\n    {\n      \"step_description\": \"Generate a text description of the objects, their depth, and their classification.\",\n      \"task_name\": \"Text Generation\"\n    },\n    {\n      \"step_description\": \"Generate a video from the text description and the example image.\",\n      \"task_name\": \"Text-to-Video\"\n    }\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image Classification\"\n    },\n    {\n      \"task_name\": \"Object Detection\"\n    },\n    {\n      \"task_name\": \"Image Segmentation\"\n    },\n    {\n      \"task_name\": \"Depth Estimation\"\n    },\n    {\n      \"task_name\": \"Text Generation\"\n    },\n    {\n      \"task_name\": \"Text-to-Video\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification\","
"{\n  \"task_steps\": [\n    \"Load example.jpg image\",\n    \"Perform object detection on example.jpg to identify car and extract its bounding box\",\n    \"Extract color information from the bounding box of the car in example.jpg\",\n    \"Generate an image with the answer 'What color is the car?' overlaid on it\",\n    \"Classify the text generated in Step 3 using token classification\",\n    \"Perform question answering on the token-classified text to extract 'What is the model of the car?'\",\n    \"Edit example.jpg image by overlaying the answer 'What is the model of the car?' on it\",\n    \"Perform depth estimation on the edited image from Step 7\",\n    \"Load document for question 'What is the total amount due?'\",\n    \"Perform document question answering on the loaded document using the depth estimation image from Step 8 as context\"\n  ],\n  \"task_nodes\": [\n    \"Image Classification: Object Detection\",\n    \"Text Generation: Answer Generation\",\n    \"Text Classification: Token Classification\",\n    \"Question Answering: Document Question Answering\",\n    \"Text-to-Image: Image Generation\",\n    \"Image Classification: Image Segmentation\",\n    \"Depth Estimation: Monocular Depth Estimation\",\n    \"Image Editing: Text Overlay\",\n    \"Text-to-Text: Document Question Answering\",\n    \"Image Classification: Image Classification\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Load example.jpg image\", \"target\": \"Perform object detection on example.jpg to identify car and extract its bounding box\"},\n    {\"source\": \"Perform object detection on example.jpg to identify car and extract"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Load and preprocess the audio file 'example.wav' for automatic speech recognition.\",\n            \"task_name\": \"Automatic Speech Recognition\"\n        },\n        {\n            \"step_description\": \"Extract the transcribed text from the audio file.\",\n            \"task_name\": \"Text-to-Text\"\n        },\n        {\n            \"step_description\": \"Perform text summarization on the transcribed text to generate a summary.\",\n            \"task_name\": \"Text Summarization\"\n        },\n        {\n            \"step_description\": \"Load and preprocess the document image 'example.jpg' for text extraction.\",\n            \"task_name\": \"Text-to-Text\"\n        },\n        {\n            \"step_description\": \"Extract the text from the document image.\",\n            \"task_name\": \"Document Question Answering\"\n        },\n        {\n            \"step_description\": \"Identify the question 'What is the main point of the summary?' in the extracted text.\",\n            \"task_name\": \"Question Answering\"\n        },\n        {\n            \"step_description\": \"Use the summary text to answer the question.\",\n            \"task_name\": \"Document Question Answering\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Automatic Speech Recognition\",\n        \"Text Summarization\",\n        \"Text-to-Text\",\n        \"Document Question Answering\",\n        \"Question Answering\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text-to-Text\"},\n        {\"source\": \"Text-"
"{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Extract the given text and parse it to identify the required fruits: apples, oranges, and bananas.\"\n        },\n        {\n            \"step_description\": \"Use the Text-to-Table task node to generate a table with the given fruits as columns and 'Popularity' as a row, with initial values set to zero.\"\n        },\n        {\n            \"step_description\": \"Use the Text-to-Image task node to generate an image of the table.\"\n        },\n        {\n            \"step_description\": \"Use the Text-to-Speech task node to read out the table for user confirmation.\"\n        },\n        {\n            \"step_description\": \"Use the Image Classification task node to classify each fruit image in the table and assign a popularity score based on the classification result.\"\n        },\n        {\n            \"step_description\": \"Use the Tabular Classification task node to calculate the total popularity score for each fruit based on the classification results.\"\n        },\n        {\n            \"step_description\": \"Use the Question Answering task node to identify the fruit with the highest popularity score.\"\n        },\n        {\n            \"step_description\": \"Output the name of the most popular fruit and the generated image of the table.\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Text-to-Table\",\n        \"Text-to-Image\",\n        \"Text-to-Speech\",\n        \"Image Classification\",\n        \"Tabular Classification\",\n        \"Question Answering\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Text-to-Table\", \"target\": \"Text-to-Image\"},\n        {\"source\":"
"{\n  \"task_steps\": [\n    \"Load 'example.jpg' image\",\n    \"Apply blue background to the image\",\n    \"Estimate depth of objects in the modified image\",\n    \"Classify the modified image\",\n    \"Generate 'example.mp4' video based on the image label\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image Classification\",\n      \"input\": {\n        \"image\": \"modified_example.jpg\"\n      },\n      \"output\": {\n        \"label\": \"label_name\"\n      }\n    },\n    {\n      \"task_name\": \"Image-to-Video\",\n      \"input\": {\n        \"image\": \"modified_example.jpg\",\n        \"label\": \"label_name\"\n      },\n      \"output\": {\n        \"video\": \"example.mp4\"\n      }\n    },\n    {\n      \"task_name\": \"Image Editing\",\n      \"input\": {\n        \"image\": \"example.jpg\",\n        \"background_color\": \"blue\"\n      },\n      \"output\": {\n        \"modified_image\": \"modified_example.jpg\"\n      }\n    },\n    {\n      \"task_name\": \"Depth Estimation\",\n      \"input\": {\n        \"image\": \"modified_example.jpg\"\n      },\n      \"output\": {\n        \"depth_map\": \"depth_map.png\"\n      }\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Editing\", \"target\": \"Depth Estimation\"},\n    {\"source\": \"Depth Estimation\", \"target\": \"Image Classification\"},\n    {\"source\": \"Image Classification\", \"target"
"{\"task_steps\": [\n\"Load image 'example.jpg'\",\n\"Perform Object Detection to identify objects in the image\",\n\"For each detected object, perform Depth Estimation to determine its distance from the camera\",\n\"Store the object name and its corresponding distance in a list\"\n],\n\"task_nodes\": [\n\"Object Detection\",\n\"Depth Estimation (for each detected object)\"\n],\n\"task_links\": [\n{\"source\": \"Object Detection\", \"target\": \"Depth Estimation\"},\n{\"source\": \"Depth Estimation\", \"target\": \"Output\"}\n]\n}\n\n\"Output\": A JSON object containing a list of detected objects and their corresponding distances."
"{\n  \"task_steps\": [\n    {\n      \"step_description\": \"Translate the given text description into French using Text-to-Text translation API\",\n      \"task_name\": \"Text-to-Text Translation\"\n    },\n    {\n      \"step_description\": \"Edit the example.jpg image according to the translated text description using Image-to-Text and Image Editing APIs\",\n      \"task_name\": \"Image-to-Text and Image Editing\"\n    },\n    {\n      \"step_description\": \"Generate a text description from the edited image using Text Generation API\",\n      \"task_name\": \"Text Generation\"\n    },\n    {\n      \"step_description\": \"Create a new image based on the generated text description using Text-to-Image API\",\n      \"task_name\": \"Text-to-Image\"\n    },\n    {\n      \"step_description\": \"Classify the new image using Image Classification API\",\n      \"task_name\": \"Image Classification\"\n    },\n    {\n      \"step_description\": \"Generate a video from the classification result using Text-to-Video API\",\n      \"task_name\": \"Text-to-Video\"\n    }\n  ],\n  \"task_nodes\": [\n    \"Text-to-Text Translation\",\n    \"Image-to-Text and Image Editing\",\n    \"Text Generation\",\n    \"Text-to-Image\",\n    \"Image Classification\",\n    \"Text-to-Video\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Text-to-Text Translation\", \"target\": \"Image-to-Text and Image Editing\"},\n    {\"source\": \"Image-to-Text and Image Editing\", \"target"
