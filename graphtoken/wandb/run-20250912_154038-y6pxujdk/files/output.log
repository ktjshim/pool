= = = = = = = = = = = = = = = = = = = =
## Starting Time: 09-12 14:40:39
Namespace(dataset='huggingface', llm='Mistral-7B', llm_model_path='', seed=0, device='cuda:0', max_txt_length=512, max_ans_length=512, gnn_in_dim=1024, gnn_hidden_dim=1024, gnn_output_dim=4096, n_layers=2, gnn_type='SAGE', max_degree=300, num_epochs=2, batch_size=6, eval_batch_size=6, patience=2, lr=1e-05, wd=0.05, output_dir='output', grad_steps=4, name='diffpool')

[Training Data] # Chain Samples 1536 (51.20)
[Data Split] # Train 3000  # Test 500
# Train 2400   # Val 600   # Test 500
Loading checkpoint shards: 100%|█████████████████████████████████| 3/3 [00:01<00:00,  2.14it/s]
Finish loading pre-trained Mistral-7B model!
Trainable params 8466467 || all params 7250198563 || trainable% 0.11678
/nas/home/ktshim/tool/pool/graphtoken/../utils/datautil.py:24: RuntimeWarning: divide by zero encountered in power
  d_inv = np.power(row_sum, -0.5).flatten()
/nas/home/ktshim/tool/pool/graphtoken/../utils/datautil.py:19: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:653.)
  return torch.sparse.FloatTensor(index, data, torch.Size(coo.shape))
  0%|                                              | 0/800 [00:00<?, ?it/s]W0912 15:40:47.367000 3839170 torch/_dynamo/variables/tensor.py:1047] [7/0] Graph break from `Tensor.item()`, consider setting:
W0912 15:40:47.367000 3839170 torch/_dynamo/variables/tensor.py:1047] [7/0]     torch._dynamo.config.capture_scalar_outputs = True
W0912 15:40:47.367000 3839170 torch/_dynamo/variables/tensor.py:1047] [7/0] or:
W0912 15:40:47.367000 3839170 torch/_dynamo/variables/tensor.py:1047] [7/0]     env TORCHDYNAMO_CAPTURE_SCALAR_OUTPUTS=1
W0912 15:40:47.367000 3839170 torch/_dynamo/variables/tensor.py:1047] [7/0] to include these operations in the captured graph.
W0912 15:40:47.367000 3839170 torch/_dynamo/variables/tensor.py:1047] [7/0]
W0912 15:40:47.367000 3839170 torch/_dynamo/variables/tensor.py:1047] [7/0] Graph break: from user code at:
W0912 15:40:47.367000 3839170 torch/_dynamo/variables/tensor.py:1047] [7/0]   File "/nas/home/ktshim/tool/pool/graphtoken/glm_diffpool.py", line 62, in encode_task_graph
W0912 15:40:47.367000 3839170 torch/_dynamo/variables/tensor.py:1047] [7/0]     node_embeds = self.graph_tokenizer(task_graph.x, task_graph.edge_index)
W0912 15:40:47.367000 3839170 torch/_dynamo/variables/tensor.py:1047] [7/0]   File "/nas/home/ktshim/tool/pool/graphtoken/gnn_diffpool.py", line 152, in forward
W0912 15:40:47.367000 3839170 torch/_dynamo/variables/tensor.py:1047] [7/0]     x_embed_dense, mask = to_dense_batch(x_embed, batch)
W0912 15:40:47.367000 3839170 torch/_dynamo/variables/tensor.py:1047] [7/0]   File "/home/ktshim/.local/lib/python3.12/site-packages/torch_geometric/experimental.py", line 117, in wrapper
W0912 15:40:47.367000 3839170 torch/_dynamo/variables/tensor.py:1047] [7/0]     return func(*args, **kwargs)
W0912 15:40:47.367000 3839170 torch/_dynamo/variables/tensor.py:1047] [7/0]   File "/home/ktshim/.local/lib/python3.12/site-packages/torch_geometric/utils/_to_dense_batch.py", line 104, in to_dense_batch
W0912 15:40:47.367000 3839170 torch/_dynamo/variables/tensor.py:1047] [7/0]     batch_size = int(batch.max()) + 1
W0912 15:40:47.367000 3839170 torch/_dynamo/variables/tensor.py:1047] [7/0]
W0912 15:40:47.367000 3839170 torch/_dynamo/variables/tensor.py:1047] [7/0]
/nas/home/ktshim/tool/pool/graphtoken/glm_diffpool.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
  0%|                                    | 1/800 [00:42<9:24:01, 42.35s/it]/nas/home/ktshim/tool/pool/graphtoken/glm_diffpool.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
  0%|                                   | 2/800 [01:38<11:14:11, 50.69s/it]/nas/home/ktshim/tool/pool/graphtoken/glm_diffpool.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
  0%|▏                                   | 3/800 [01:39<6:09:27, 27.81s/it]/nas/home/ktshim/tool/pool/graphtoken/glm_diffpool.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
  0%|▏                                   | 4/800 [01:39<3:46:02, 17.04s/it]/nas/home/ktshim/tool/pool/graphtoken/glm_diffpool.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
  1%|▏                                   | 5/800 [01:40<2:26:40, 11.07s/it]/nas/home/ktshim/tool/pool/graphtoken/glm_diffpool.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
  1%|▎                                   | 6/800 [01:40<1:39:00,  7.48s/it]/nas/home/ktshim/tool/pool/graphtoken/glm_diffpool.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
  1%|▎                                   | 7/800 [01:41<1:08:38,  5.19s/it]/nas/home/ktshim/tool/pool/graphtoken/glm_diffpool.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
  1%|▍                                     | 8/800 [01:42<48:56,  3.71s/it]W0912 15:42:26.040000 3839170 torch/_dynamo/convert_frame.py:1016] [0/8] torch._dynamo hit config.recompile_limit (8)
W0912 15:42:26.040000 3839170 torch/_dynamo/convert_frame.py:1016] [0/8]    function: 'forward' (/nas/home/ktshim/tool/pool/graphtoken/glm_diffpool.py:82)
W0912 15:42:26.040000 3839170 torch/_dynamo/convert_frame.py:1016] [0/8]    last reason: 0/7: samples['request'][0] == '# TASK LIST #:\nToken Classification, Translation, Summarization, Question Answering, Conversational, Text Generation, Sentence Similarity, Tabular Classification, Object Detection, Image Classification, Image-to-Image, Image-to-Text, Text-to-Image, Text-to-Video, Visual Question Answering, Document Question Answering, Image Segmentation, Depth Estimation, Text-to-Speech, Automatic Speech Recognition, Audio-to-Audio, Audio Classification, Image Editing\n\n# GOAL #\nPlease understand the user\'s request and generate task steps and task invocation graph to solve it.\n\n# REQUIREMENT #\n1. The format must in a strict JSON format as {"task_steps": [ concrete step descriptions ], "task_nodes": [ a list of tasks to be executed in sequence to fulfill user\'s request ], "task_links": [{"source": "task name i", "target": "task name j"}]}\n2. The generated task steps and task nodes can resolve the given user request perfectly. Task name must be selected from TASK LIST.\n3. Task steps should strictly aligned with task nodes, and the number of task steps should be same with the task nodes.\n4. The task links should reflect the dependencies among task nodes, i.e. the order in which the APIs are invoked.\n\n\n# USER REQUEST #: I have an audio file example.wav, where I express a certain emotion. Based on that emotion, please create a short text, answer the question \'What is the main topic of this document?\' related to the document example.jpg, translate the answer into French, and also answer the question \'What is the key object in this image?\' based on example2.jpg.\nNow please generate your result in a strict JSON format:\n# RESULT #:'
W0912 15:42:26.040000 3839170 torch/_dynamo/convert_frame.py:1016] [0/8] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0912 15:42:26.040000 3839170 torch/_dynamo/convert_frame.py:1016] [0/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
/nas/home/ktshim/tool/pool/graphtoken/glm_diffpool.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
 25%|█████████                           | 200/800 [03:14<04:55,  2.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

--- Running Inference Check at Step 200 ---
 50%|██████████████████                  | 400/800 [05:00<03:10,  2.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

--- Running Inference Check at Step 400 ---
Epoch 0|2: Train Loss (Epoch Mean): 0.4648645970225334
Epoch: 0|2: Val Loss: 0.3282519257068634
Saving checkpoint at epoch 0 to output/huggingface/Mistral-7B/SAGE_Epoch2_checkpoint_best.pth
 75%|███████████████████████████         | 600/800 [07:14<01:35,  2.10it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

--- Running Inference Check at Step 200 ---
100%|████████████████████████████████████| 800/800 [09:04<00:00,  2.03it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

--- Running Inference Check at Step 400 ---
Epoch 1|2: Train Loss (Epoch Mean): 0.3349344743415713
Epoch: 1|2: Val Loss: 0.3134950456023216
Saving checkpoint at epoch 1 to output/huggingface/Mistral-7B/SAGE_Epoch2_checkpoint_best.pth
/home/ktshim/.local/lib/python3.12/site-packages/torch/cuda/memory.py:491: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.
  warnings.warn(
Loading checkpoint from output/huggingface/Mistral-7B/SAGE_Epoch2_checkpoint_best.pth
                                                                                                               Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  0%|                                                                                   | 0/84 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  1%|▉                                                                          | 1/84 [00:10<14:22, 10.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  2%|█▊                                                                         | 2/84 [00:21<14:57, 10.95s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  4%|██▋                                                                        | 3/84 [00:37<17:32, 13.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  5%|███▌                                                                       | 4/84 [00:47<15:46, 11.83s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  6%|████▍                                                                      | 5/84 [00:56<14:19, 10.88s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  7%|█████▎                                                                     | 6/84 [01:11<15:57, 12.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  8%|██████▎                                                                    | 7/84 [01:23<15:49, 12.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 10%|███████▏                                                                   | 8/84 [01:32<14:15, 11.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 11%|████████                                                                   | 9/84 [01:39<12:27,  9.96s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 12%|████████▊                                                                 | 10/84 [01:50<12:25, 10.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 13%|█████████▋                                                                | 11/84 [01:59<11:56,  9.82s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 14%|██████████▌                                                               | 12/84 [02:07<11:16,  9.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 15%|███████████▍                                                              | 13/84 [02:22<12:58, 10.97s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 17%|████████████▎                                                             | 14/84 [02:32<12:30, 10.72s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 18%|█████████████▏                                                            | 15/84 [02:41<11:49, 10.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 19%|██████████████                                                            | 16/84 [02:54<12:19, 10.87s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 20%|██████████████▉                                                           | 17/84 [03:03<11:28, 10.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 21%|███████████████▊                                                          | 18/84 [03:16<12:27, 11.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 23%|████████████████▋                                                         | 19/84 [03:26<11:48, 10.89s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 24%|█████████████████▌                                                        | 20/84 [03:37<11:41, 10.96s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 25%|██████████████████▌                                                       | 21/84 [03:46<10:42, 10.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 26%|███████████████████▍                                                      | 22/84 [03:55<10:06,  9.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 27%|████████████████████▎                                                     | 23/84 [04:05<10:13, 10.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 29%|█████████████████████▏                                                    | 24/84 [04:18<10:53, 10.89s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 30%|██████████████████████                                                    | 25/84 [04:31<11:24, 11.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 31%|██████████████████████▉                                                   | 26/84 [04:48<12:36, 13.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 32%|███████████████████████▊                                                  | 27/84 [05:04<13:22, 14.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 33%|████████████████████████▋                                                 | 28/84 [05:13<11:44, 12.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 35%|█████████████████████████▌                                                | 29/84 [05:21<10:16, 11.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 36%|██████████████████████████▍                                               | 30/84 [05:30<09:25, 10.47s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
[Test Error] Test-ID 10159776 e pred
 37%|███████████████████████████▎                                              | 31/84 [05:50<11:52, 13.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 38%|████████████████████████████▏                                             | 32/84 [05:57<09:57, 11.49s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 39%|█████████████████████████████                                             | 33/84 [06:11<10:24, 12.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 40%|█████████████████████████████▉                                            | 34/84 [06:20<09:15, 11.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 42%|██████████████████████████████▊                                           | 35/84 [06:33<09:31, 11.66s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 43%|███████████████████████████████▋                                          | 36/84 [06:43<08:55, 11.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 44%|████████████████████████████████▌                                         | 37/84 [06:53<08:35, 10.97s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 45%|█████████████████████████████████▍                                        | 38/84 [07:02<07:47, 10.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 46%|██████████████████████████████████▎                                       | 39/84 [07:11<07:24,  9.87s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 48%|███████████████████████████████████▏                                      | 40/84 [07:20<07:07,  9.71s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 49%|████████████████████████████████████                                      | 41/84 [07:33<07:35, 10.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 50%|█████████████████████████████████████                                     | 42/84 [07:47<08:06, 11.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 51%|█████████████████████████████████████▉                                    | 43/84 [08:01<08:23, 12.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 52%|██████████████████████████████████████▊                                   | 44/84 [08:12<08:01, 12.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 54%|███████████████████████████████████████▋                                  | 45/84 [08:23<07:34, 11.65s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 55%|████████████████████████████████████████▌                                 | 46/84 [08:35<07:25, 11.71s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 56%|█████████████████████████████████████████▍                                | 47/84 [08:52<08:12, 13.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 57%|██████████████████████████████████████████▎                               | 48/84 [09:01<07:19, 12.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 58%|███████████████████████████████████████████▏                              | 49/84 [09:15<07:18, 12.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 60%|████████████████████████████████████████████                              | 50/84 [09:24<06:36, 11.65s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 61%|████████████████████████████████████████████▉                             | 51/84 [09:41<07:17, 13.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 62%|█████████████████████████████████████████████▊                            | 52/84 [09:51<06:30, 12.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 63%|██████████████████████████████████████████████▋                           | 53/84 [09:58<05:31, 10.70s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 64%|███████████████████████████████████████████████▌                          | 54/84 [10:09<05:23, 10.80s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 65%|████████████████████████████████████████████████▍                         | 55/84 [10:21<05:21, 11.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 67%|█████████████████████████████████████████████████▎                        | 56/84 [10:31<04:57, 10.64s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 68%|██████████████████████████████████████████████████▏                       | 57/84 [10:39<04:32, 10.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 69%|███████████████████████████████████████████████████                       | 58/84 [10:50<04:26, 10.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 70%|███████████████████████████████████████████████████▉                      | 59/84 [10:59<04:08,  9.95s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 71%|████████████████████████████████████████████████████▊                     | 60/84 [11:14<04:30, 11.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 73%|█████████████████████████████████████████████████████▋                    | 61/84 [11:23<04:06, 10.70s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 74%|██████████████████████████████████████████████████████▌                   | 62/84 [11:34<04:00, 10.93s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 75%|███████████████████████████████████████████████████████▌                  | 63/84 [11:42<03:28,  9.94s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 76%|████████████████████████████████████████████████████████▍                 | 64/84 [11:58<03:52, 11.64s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 77%|█████████████████████████████████████████████████████████▎                | 65/84 [12:09<03:39, 11.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 79%|██████████████████████████████████████████████████████████▏               | 66/84 [12:25<03:50, 12.79s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 80%|███████████████████████████████████████████████████████████               | 67/84 [12:34<03:21, 11.85s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 81%|███████████████████████████████████████████████████████████▉              | 68/84 [12:44<03:00, 11.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 82%|████████████████████████████████████████████████████████████▊             | 69/84 [12:55<02:46, 11.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 83%|█████████████████████████████████████████████████████████████▋            | 70/84 [13:05<02:29, 10.66s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 85%|██████████████████████████████████████████████████████████████▌           | 71/84 [13:13<02:09,  9.93s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 86%|███████████████████████████████████████████████████████████████▍          | 72/84 [13:23<01:59,  9.98s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 87%|████████████████████████████████████████████████████████████████▎         | 73/84 [13:32<01:45,  9.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 88%|█████████████████████████████████████████████████████████████████▏        | 74/84 [13:42<01:37,  9.77s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 89%|██████████████████████████████████████████████████████████████████        | 75/84 [13:52<01:27,  9.74s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 90%|██████████████████████████████████████████████████████████████████▉       | 76/84 [14:04<01:25, 10.68s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 92%|███████████████████████████████████████████████████████████████████▊      | 77/84 [14:22<01:29, 12.81s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 93%|████████████████████████████████████████████████████████████████████▋     | 78/84 [14:39<01:23, 13.99s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 94%|█████████████████████████████████████████████████████████████████████▌    | 79/84 [14:48<01:02, 12.49s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
[Test Error] Test-ID 44885018 e pred
 95%|██████████████████████████████████████████████████████████████████████▍   | 80/84 [15:09<00:59, 14.99s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 96%|███████████████████████████████████████████████████████████████████████▎  | 81/84 [15:17<00:38, 12.93s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 98%|████████████████████████████████████████████████████████████████████████▏ | 82/84 [15:27<00:24, 12.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 99%|█████████████████████████████████████████████████████████████████████████ | 83/84 [15:37<00:11, 11.53s/it]
100%|██████████████████████████████████████████████████████████████████████████| 84/84 [15:47<00:00, 10.97s/it]

## Finishing Time: 09-12 15:06:18
= = = = = = = = = = = = = = = = = = = =
Done!
