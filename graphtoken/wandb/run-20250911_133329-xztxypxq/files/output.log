= = = = = = = = = = = = = = = = = = = =
## Starting Time: 09-11 12:33:30
Namespace(dataset='huggingface', llm='Mistral-7B', llm_model_path='', seed=0, device='cuda:0', max_txt_length=512, max_ans_length=512, gnn_in_dim=1024, gnn_hidden_dim=1024, gnn_output_dim=4096, n_layers=2, gnn_type='SAGE', max_degree=300, num_epochs=2, batch_size=6, eval_batch_size=6, patience=2, lr=1e-05, wd=0.05, output_dir='output', grad_steps=4, name='graph-0911')

[Training Data] # Chain Samples 1536 (51.20)
[Data Split] # Train 3000  # Test 500
# Train 2400   # Val 600   # Test 500
Loading checkpoint shards: 100%|███| 3/3 [00:01<00:00,  2.13it/s]
Finish loading pre-trained Mistral-7B model!
Trainable params 10492928 || all params 7252225024 || trainable% 0.14469
/nas/home/ktshim/tool/pool/graphtoken/../utils/datautil.py:24: RuntimeWarning: divide by zero encountered in power
  d_inv = np.power(row_sum, -0.5).flatten()
/nas/home/ktshim/tool/pool/graphtoken/../utils/datautil.py:19: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:653.)
  return torch.sparse.FloatTensor(index, data, torch.Size(coo.shape))
  0%|                                    | 0/800 [00:00<?, ?it/s]/nas/home/ktshim/tool/pool/graphtoken/glm_graph.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
  0%|                          | 1/800 [00:41<9:06:20, 41.03s/it]/nas/home/ktshim/tool/pool/graphtoken/glm_graph.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
  0%|                         | 2/800 [01:37<11:06:08, 50.09s/it]/nas/home/ktshim/tool/pool/graphtoken/glm_graph.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
  0%|                          | 3/800 [01:37<6:04:40, 27.45s/it]/nas/home/ktshim/tool/pool/graphtoken/glm_graph.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
  0%|▏                         | 4/800 [01:38<3:42:59, 16.81s/it]/nas/home/ktshim/tool/pool/graphtoken/glm_graph.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
  1%|▏                         | 5/800 [01:38<2:24:36, 10.91s/it]/nas/home/ktshim/tool/pool/graphtoken/glm_graph.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
  1%|▏                         | 6/800 [01:39<1:37:08,  7.34s/it]/nas/home/ktshim/tool/pool/graphtoken/glm_graph.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
  1%|▏                         | 7/800 [01:39<1:07:18,  5.09s/it]/nas/home/ktshim/tool/pool/graphtoken/glm_graph.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
  1%|▎                           | 8/800 [01:40<47:48,  3.62s/it]W0911 13:35:15.411000 3585846 torch/_dynamo/convert_frame.py:1016] [0/8] torch._dynamo hit config.recompile_limit (8)
W0911 13:35:15.411000 3585846 torch/_dynamo/convert_frame.py:1016] [0/8]    function: 'forward' (/nas/home/ktshim/tool/pool/graphtoken/glm_graph.py:82)
W0911 13:35:15.411000 3585846 torch/_dynamo/convert_frame.py:1016] [0/8]    last reason: 0/7: samples['request'][0] == '# TASK LIST #:\nToken Classification, Translation, Summarization, Question Answering, Conversational, Text Generation, Sentence Similarity, Tabular Classification, Object Detection, Image Classification, Image-to-Image, Image-to-Text, Text-to-Image, Text-to-Video, Visual Question Answering, Document Question Answering, Image Segmentation, Depth Estimation, Text-to-Speech, Automatic Speech Recognition, Audio-to-Audio, Audio Classification, Image Editing\n\n# GOAL #\nPlease understand the user\'s request and generate task steps and task invocation graph to solve it.\n\n# REQUIREMENT #\n1. The format must in a strict JSON format as {"task_steps": [ concrete step descriptions ], "task_nodes": [ a list of tasks to be executed in sequence to fulfill user\'s request ], "task_links": [{"source": "task name i", "target": "task name j"}]}\n2. The generated task steps and task nodes can resolve the given user request perfectly. Task name must be selected from TASK LIST.\n3. Task steps should strictly aligned with task nodes, and the number of task steps should be same with the task nodes.\n4. The task links should reflect the dependencies among task nodes, i.e. the order in which the APIs are invoked.\n\n\n# USER REQUEST #: Please help me classify tokens in the following text: \'Alice went to the store at 3pm yesterday. She bought a cake and six candles.\'\nNow please generate your result in a strict JSON format:\n# RESULT #:'
W0911 13:35:15.411000 3585846 torch/_dynamo/convert_frame.py:1016] [0/8] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0911 13:35:15.411000 3585846 torch/_dynamo/convert_frame.py:1016] [0/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
/nas/home/ktshim/tool/pool/graphtoken/glm_graph.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
 25%|██████▌                   | 200/800 [03:11<04:33,  2.20it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

--- Running Inference Check at Step 200 ---
 50%|█████████████             | 400/800 [04:54<03:19,  2.00it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

--- Running Inference Check at Step 400 ---
Epoch 0|2: Train Loss (Epoch Mean): 0.5244724781438709
Epoch: 0|2: Val Loss: 0.35176976084709166
Saving checkpoint at epoch 0 to output/huggingface/Mistral-7B/SAGE_Epoch2_checkpoint_best.pth
 75%|███████████████████▌      | 600/800 [07:03<01:31,  2.18it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

--- Running Inference Check at Step 200 ---
100%|██████████████████████████| 800/800 [08:48<00:00,  2.11it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

--- Running Inference Check at Step 400 ---
Epoch 1|2: Train Loss (Epoch Mean): 0.3291739448904991
Epoch: 1|2: Val Loss: 0.31235080942511556
Saving checkpoint at epoch 1 to output/huggingface/Mistral-7B/SAGE_Epoch2_checkpoint_best.pth
/home/ktshim/.local/lib/python3.12/site-packages/torch/cuda/memory.py:491: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.
  warnings.warn(
Loading checkpoint from output/huggingface/Mistral-7B/SAGE_Epoch2_checkpoint_best.pth
                                                                 Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  0%|                                     | 0/84 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  1%|▎                            | 1/84 [00:10<14:49, 10.72s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  2%|▋                            | 2/84 [00:21<14:35, 10.67s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  4%|█                            | 3/84 [00:36<17:18, 12.83s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  5%|█▍                           | 4/84 [00:44<14:29, 10.86s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  6%|█▋                           | 5/84 [00:52<12:44,  9.68s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  7%|██                           | 6/84 [01:04<13:32, 10.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  8%|██▍                          | 7/84 [01:13<13:09, 10.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 10%|██▊                          | 8/84 [01:22<12:13,  9.65s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 11%|███                          | 9/84 [01:28<10:47,  8.63s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 12%|███▎                        | 10/84 [01:36<10:25,  8.46s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 13%|███▋                        | 11/84 [01:45<10:26,  8.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 14%|████                        | 12/84 [01:53<09:56,  8.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 15%|████▎                       | 13/84 [02:04<10:44,  9.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 17%|████▋                       | 14/84 [02:14<10:51,  9.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 18%|█████                       | 15/84 [02:22<10:29,  9.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 19%|█████▎                      | 16/84 [02:35<11:32, 10.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 20%|█████▋                      | 17/84 [02:43<10:37,  9.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 21%|██████                      | 18/84 [02:56<11:46, 10.70s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 23%|██████▎                     | 19/84 [03:06<11:20, 10.46s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 24%|██████▋                     | 20/84 [03:19<12:02, 11.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 25%|███████                     | 21/84 [03:28<11:06, 10.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 26%|███████▎                    | 22/84 [03:36<09:59,  9.68s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 27%|███████▋                    | 23/84 [03:48<10:32, 10.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 29%|████████                    | 24/84 [04:00<11:00, 11.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 30%|████████▎                   | 25/84 [04:10<10:26, 10.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 31%|████████▋                   | 26/84 [04:25<11:31, 11.92s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 32%|█████████                   | 27/84 [04:39<11:48, 12.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
[Test Error] Test-ID 75501770 e pred
 33%|█████████▎                  | 28/84 [04:59<13:50, 14.84s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 35%|█████████▋                  | 29/84 [05:08<11:56, 13.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 36%|██████████                  | 30/84 [05:15<10:14, 11.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 37%|██████████▎                 | 31/84 [05:25<09:33, 10.82s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 38%|██████████▋                 | 32/84 [05:37<09:41, 11.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 39%|███████████                 | 33/84 [05:50<09:57, 11.71s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 40%|███████████▎                | 34/84 [05:59<09:08, 10.96s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 42%|███████████▋                | 35/84 [06:09<08:34, 10.49s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 43%|████████████                | 36/84 [06:18<08:11, 10.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 44%|████████████▎               | 37/84 [06:27<07:38,  9.75s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
[Test Error] Test-ID 83888896 e pred
 45%|████████████▋               | 38/84 [06:47<09:55, 12.94s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 46%|█████████████               | 39/84 [06:59<09:23, 12.51s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 48%|█████████████▎              | 40/84 [07:08<08:28, 11.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 49%|█████████████▋              | 41/84 [07:21<08:37, 12.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 50%|██████████████              | 42/84 [07:33<08:19, 11.88s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 51%|██████████████▎             | 43/84 [07:47<08:37, 12.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 52%|██████████████▋             | 44/84 [08:00<08:33, 12.85s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 54%|███████████████             | 45/84 [08:10<07:39, 11.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 55%|███████████████▎            | 46/84 [08:22<07:36, 12.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 56%|███████████████▋            | 47/84 [08:39<08:13, 13.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 57%|████████████████            | 48/84 [08:47<07:05, 11.82s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 58%|████████████████▎           | 49/84 [09:00<07:07, 12.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 60%|████████████████▋           | 50/84 [09:10<06:30, 11.48s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 61%|█████████████████           | 51/84 [09:28<07:28, 13.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 62%|█████████████████▎          | 52/84 [09:43<07:29, 14.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 63%|█████████████████▋          | 53/84 [09:52<06:27, 12.50s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 64%|██████████████████          | 54/84 [10:06<06:26, 12.89s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 65%|██████████████████▎         | 55/84 [10:18<06:00, 12.42s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 67%|██████████████████▋         | 56/84 [10:26<05:18, 11.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 68%|███████████████████         | 57/84 [10:36<04:48, 10.70s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 69%|███████████████████▎        | 58/84 [10:47<04:43, 10.89s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 70%|███████████████████▋        | 59/84 [10:55<04:10, 10.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 71%|████████████████████        | 60/84 [11:06<04:05, 10.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 73%|████████████████████▎       | 61/84 [11:15<03:52, 10.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 74%|████████████████████▋       | 62/84 [11:26<03:44, 10.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 75%|█████████████████████       | 63/84 [11:33<03:16,  9.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 76%|█████████████████████▎      | 64/84 [11:46<03:29, 10.48s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 77%|█████████████████████▋      | 65/84 [11:57<03:19, 10.50s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 79%|██████████████████████      | 66/84 [12:12<03:35, 11.97s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 80%|██████████████████████▎     | 67/84 [12:20<03:02, 10.72s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 81%|██████████████████████▋     | 68/84 [12:28<02:37,  9.81s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 82%|███████████████████████     | 69/84 [12:36<02:19,  9.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 83%|███████████████████████▎    | 70/84 [12:44<02:04,  8.93s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 85%|███████████████████████▋    | 71/84 [12:53<01:58,  9.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 86%|████████████████████████    | 72/84 [13:04<01:55,  9.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 87%|████████████████████████▎   | 73/84 [13:14<01:45,  9.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 88%|████████████████████████▋   | 74/84 [13:22<01:30,  9.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 89%|█████████████████████████   | 75/84 [13:29<01:18,  8.69s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 90%|█████████████████████████▎  | 76/84 [13:41<01:16,  9.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 92%|█████████████████████████▋  | 77/84 [13:50<01:06,  9.51s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 93%|██████████████████████████  | 78/84 [14:05<01:06, 11.06s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 94%|██████████████████████████▎ | 79/84 [14:13<00:50, 10.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
[Test Error] Test-ID 21511092 e pred
 95%|██████████████████████████▋ | 80/84 [14:34<00:53, 13.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 96%|███████████████████████████ | 81/84 [14:42<00:34, 11.63s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 98%|███████████████████████████▎| 82/84 [14:50<00:21, 10.73s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 99%|███████████████████████████▋| 83/84 [14:59<00:10, 10.27s/it]
100%|████████████████████████████| 84/84 [15:09<00:00, 10.07s/it]

## Finishing Time: 09-11 12:58:09
= = = = = = = = = = = = = = = = = = = =
Done!
