= = = = = = = = = = = = = = = = = = = =
## Starting Time: 09-09 13:14:34
Namespace(dataset='huggingface', llm='Mistral-7B', llm_model_path='', seed=0, device='cuda:0', max_txt_length=512, max_ans_length=512, gnn_in_dim=1024, gnn_hidden_dim=1024, gnn_output_dim=4096, n_layers=2, gnn_type='SAGE', max_degree=300, num_epochs=2, batch_size=6, eval_batch_size=6, patience=2, lr=1e-05, wd=0.05, output_dir='output', grad_steps=4, name='d')

[Training Data] # Chain Samples 1536 (51.20)
[Data Split] # Train 3000  # Test 500
# Train 2400   # Val 600   # Test 500
Loading checkpoint shards:  33%|██████▎            | 1/3 [00:00<00:01,  1.06it/s]
Traceback (most recent call last):
  File "/nas/home/ktshim/tool/pool/graphtoken/main.py", line 92, in <module>
    model = torch.compile(model = GraphToken(args))
                                  ^^^^^^^^^^^^^^^^
  File "/nas/home/ktshim/tool/pool/graphtoken/glm_node.py", line 45, in __init__
    model = AutoModelForCausalLM.from_pretrained(args.llm_model_path, torch_dtype=torch.float16, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ktshim/.local/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py", line 600, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ktshim/.local/lib/python3.12/site-packages/transformers/modeling_utils.py", line 317, in _wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ktshim/.local/lib/python3.12/site-packages/transformers/modeling_utils.py", line 5074, in from_pretrained
    ) = cls._load_pretrained_model(
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ktshim/.local/lib/python3.12/site-packages/transformers/modeling_utils.py", line 5537, in _load_pretrained_model
    _error_msgs, disk_offload_index, cpu_offload_index = load_shard_file(args)
                                                         ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ktshim/.local/lib/python3.12/site-packages/transformers/modeling_utils.py", line 975, in load_shard_file
    disk_offload_index, cpu_offload_index = _load_state_dict_into_meta_model(
                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ktshim/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ktshim/.local/lib/python3.12/site-packages/transformers/modeling_utils.py", line 845, in _load_state_dict_into_meta_model
    param = param.to(casting_dtype)
            ^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
