= = = = = = = = = = = = = = = = = = = =
## Starting Time: 09-12 20:55:46
Namespace(dataset='ultratool', llm='Mistral-7B', llm_model_path='', seed=0, device='cuda:0', max_txt_length=512, max_ans_length=512, gnn_in_dim=1024, gnn_hidden_dim=1024, gnn_output_dim=4096, n_layers=2, gnn_type='SAGE', max_degree=270, max_nodes=23, num_epochs=2, batch_size=6, eval_batch_size=6, patience=2, lr=1e-05, wd=0.05, output_dir='output', grad_steps=4, name='diffpool_fp32_node23_2')

[Training Data] # Chain Samples 3000 (100.00)
[Data Split] # Train 3000  # Test 500
# Train 2400   # Val 600   # Test 500
Loading checkpoint shards: 100%|█████| 3/3 [00:01<00:00,  2.09it/s]
Finish loading pre-trained Mistral-7B model!
Trainable params 8466467 || all params 7250198563 || trainable% 0.11678
/nas/home/ktshim/tool/pool/graphtoken/../utils/datautil.py:24: RuntimeWarning: divide by zero encountered in power
  d_inv = np.power(row_sum, -0.5).flatten()
/nas/home/ktshim/tool/pool/graphtoken/../utils/datautil.py:19: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:654.)
  return torch.sparse.FloatTensor(index, data, torch.Size(coo.shape))
  0%|                                      | 0/800 [00:00<?, ?it/s]W0912 21:55:53.650554 84255 site-packages/torch/_dynamo/variables/tensor.py:913] [7/0] Graph break from `Tensor.item()`, consider setting:
W0912 21:55:53.650554 84255 site-packages/torch/_dynamo/variables/tensor.py:913] [7/0]     torch._dynamo.config.capture_scalar_outputs = True
W0912 21:55:53.650554 84255 site-packages/torch/_dynamo/variables/tensor.py:913] [7/0] or:
W0912 21:55:53.650554 84255 site-packages/torch/_dynamo/variables/tensor.py:913] [7/0]     env TORCHDYNAMO_CAPTURE_SCALAR_OUTPUTS=1
W0912 21:55:53.650554 84255 site-packages/torch/_dynamo/variables/tensor.py:913] [7/0] to include these operations in the captured graph.
W0912 21:55:53.650554 84255 site-packages/torch/_dynamo/variables/tensor.py:913] [7/0]
W0912 21:55:53.650554 84255 site-packages/torch/_dynamo/variables/tensor.py:913] [7/0] Graph break: from user code at:
W0912 21:55:53.650554 84255 site-packages/torch/_dynamo/variables/tensor.py:913] [7/0]   File "/nas/home/ktshim/tool/pool/graphtoken/glm_diffpool.py", line 63, in encode_task_graph
W0912 21:55:53.650554 84255 site-packages/torch/_dynamo/variables/tensor.py:913] [7/0]     node_embeds = self.graph_tokenizer(task_graph.x, task_graph.edge_index)
W0912 21:55:53.650554 84255 site-packages/torch/_dynamo/variables/tensor.py:913] [7/0]   File "/nas/home/ktshim/tool/pool/graphtoken/gnn_diffpool.py", line 152, in forward
W0912 21:55:53.650554 84255 site-packages/torch/_dynamo/variables/tensor.py:913] [7/0]     x_embed_dense, mask = to_dense_batch(x_embed, batch)
W0912 21:55:53.650554 84255 site-packages/torch/_dynamo/variables/tensor.py:913] [7/0]   File "/home/ktshim/anaconda3/envs/tool/lib/python3.9/site-packages/torch_geometric/experimental.py", line 117, in wrapper
W0912 21:55:53.650554 84255 site-packages/torch/_dynamo/variables/tensor.py:913] [7/0]     return func(*args, **kwargs)
W0912 21:55:53.650554 84255 site-packages/torch/_dynamo/variables/tensor.py:913] [7/0]   File "/home/ktshim/anaconda3/envs/tool/lib/python3.9/site-packages/torch_geometric/utils/_to_dense_batch.py", line 104, in to_dense_batch
W0912 21:55:53.650554 84255 site-packages/torch/_dynamo/variables/tensor.py:913] [7/0]     batch_size = int(batch.max()) + 1
W0912 21:55:53.650554 84255 site-packages/torch/_dynamo/variables/tensor.py:913] [7/0]
W0912 21:55:53.650554 84255 site-packages/torch/_dynamo/variables/tensor.py:913] [7/0]
/nas/home/ktshim/tool/pool/graphtoken/glm_diffpool.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
/home/ktshim/anaconda3/envs/tool/lib/python3.9/site-packages/torch/_inductor/compile_fx.py:236: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
  0%|                            | 1/800 [00:44<9:48:22, 44.18s/it]/nas/home/ktshim/tool/pool/graphtoken/glm_diffpool.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
  0%|                           | 2/800 [01:51<12:46:08, 57.60s/it]/nas/home/ktshim/tool/pool/graphtoken/glm_diffpool.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
  0%|▏                          | 4/800 [02:58<10:03:20, 45.48s/it]/nas/home/ktshim/tool/pool/graphtoken/glm_diffpool.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
  1%|▏                           | 7/800 [04:06<7:41:37, 34.93s/it]/nas/home/ktshim/tool/pool/graphtoken/glm_diffpool.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
 25%|███████                     | 200/800 [05:58<05:37,  1.78it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

--- Running Inference Check at Step 200 ---
 50%|██████████████              | 400/800 [08:01<03:59,  1.67it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

--- Running Inference Check at Step 400 ---
Epoch 0|2: Train Loss (Epoch Mean): 0.6979735537618399
/nas/home/ktshim/tool/pool/graphtoken/glm_diffpool.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
/nas/home/ktshim/tool/pool/graphtoken/glm_diffpool.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
/nas/home/ktshim/tool/pool/graphtoken/glm_diffpool.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
/nas/home/ktshim/tool/pool/graphtoken/glm_diffpool.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
/nas/home/ktshim/tool/pool/graphtoken/glm_diffpool.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
Epoch: 0|2: Val Loss: 0.5971872270107269
Saving checkpoint at epoch 0 to output/ultratool/Mistral-7B/SAGE_Epoch2_checkpoint_best.pth
 75%|█████████████████████       | 600/800 [11:54<01:55,  1.73it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

--- Running Inference Check at Step 200 ---
100%|████████████████████████████| 800/800 [13:56<00:00,  1.69it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

--- Running Inference Check at Step 400 ---
Epoch 1|2: Train Loss (Epoch Mean): 0.5810256323218346
Epoch: 1|2: Val Loss: 0.5774990317225456
Saving checkpoint at epoch 1 to output/ultratool/Mistral-7B/SAGE_Epoch2_checkpoint_best.pth
/home/ktshim/anaconda3/envs/tool/lib/python3.9/site-packages/torch/cuda/memory.py:489: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.
  warnings.warn(
Loading checkpoint from output/ultratool/Mistral-7B/SAGE_Epoch2_checkpoint_best.pth
                                                                   Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  0%|                                       | 0/84 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  1%|▎                              | 1/84 [00:04<06:00,  4.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  2%|▋                              | 2/84 [00:08<05:56,  4.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  4%|█                              | 3/84 [00:13<05:52,  4.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  5%|█▍                             | 4/84 [00:17<05:47,  4.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  6%|█▊                             | 5/84 [00:21<05:43,  4.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  7%|██▏                            | 6/84 [00:26<05:39,  4.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  8%|██▌                            | 7/84 [00:30<05:34,  4.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 10%|██▉                            | 8/84 [00:34<05:30,  4.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 11%|███▎                           | 9/84 [00:39<05:29,  4.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 12%|███▌                          | 10/84 [00:43<05:23,  4.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 13%|███▉                          | 11/84 [00:47<05:18,  4.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 14%|████▎                         | 12/84 [00:52<05:14,  4.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 15%|████▋                         | 13/84 [00:56<05:09,  4.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 17%|█████                         | 14/84 [01:01<05:04,  4.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 18%|█████▎                        | 15/84 [01:05<05:00,  4.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 19%|█████▋                        | 16/84 [01:09<04:55,  4.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 20%|██████                        | 17/84 [01:14<04:51,  4.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 21%|██████▍                       | 18/84 [01:18<04:46,  4.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 23%|██████▊                       | 19/84 [01:22<04:42,  4.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 24%|███████▏                      | 20/84 [01:27<04:40,  4.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 25%|███████▌                      | 21/84 [01:31<04:35,  4.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 26%|███████▊                      | 22/84 [01:36<04:33,  4.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 27%|████████▏                     | 23/84 [01:40<04:27,  4.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 29%|████████▌                     | 24/84 [01:44<04:22,  4.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 30%|████████▉                     | 25/84 [01:49<04:17,  4.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 31%|█████████▎                    | 26/84 [01:53<04:13,  4.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 32%|█████████▋                    | 27/84 [01:57<04:08,  4.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 33%|██████████                    | 28/84 [02:02<04:03,  4.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 35%|██████████▎                   | 29/84 [02:06<03:59,  4.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 36%|██████████▋                   | 30/84 [02:10<03:54,  4.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 37%|███████████                   | 31/84 [02:15<03:50,  4.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 38%|███████████▍                  | 32/84 [02:19<03:45,  4.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 39%|███████████▊                  | 33/84 [02:23<03:41,  4.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 40%|████████████▏                 | 34/84 [02:28<03:37,  4.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 42%|████████████▌                 | 35/84 [02:32<03:32,  4.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 43%|████████████▊                 | 36/84 [02:36<03:28,  4.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 44%|█████████████▏                | 37/84 [02:41<03:25,  4.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 45%|█████████████▌                | 38/84 [02:45<03:20,  4.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 46%|█████████████▉                | 39/84 [02:50<03:16,  4.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 48%|██████████████▎               | 40/84 [02:54<03:11,  4.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 49%|██████████████▋               | 41/84 [02:58<03:07,  4.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 50%|███████████████               | 42/84 [03:03<03:02,  4.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 51%|███████████████▎              | 43/84 [03:07<02:58,  4.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 52%|███████████████▋              | 44/84 [03:11<02:54,  4.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 54%|████████████████              | 45/84 [03:16<02:51,  4.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 55%|████████████████▍             | 46/84 [03:20<02:46,  4.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 56%|████████████████▊             | 47/84 [03:24<02:41,  4.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 57%|█████████████████▏            | 48/84 [03:29<02:37,  4.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 58%|█████████████████▌            | 49/84 [03:33<02:33,  4.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 60%|█████████████████▊            | 50/84 [03:42<03:11,  5.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 61%|██████████████████▏           | 51/84 [03:46<02:54,  5.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 62%|██████████████████▌           | 52/84 [03:51<02:39,  5.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 63%|██████████████████▉           | 53/84 [03:55<02:30,  4.84s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 64%|███████████████████▎          | 54/84 [04:00<02:21,  4.73s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 65%|███████████████████▋          | 55/84 [04:04<02:13,  4.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 67%|████████████████████          | 56/84 [04:08<02:07,  4.54s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 68%|████████████████████▎         | 57/84 [04:13<02:00,  4.48s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 69%|████████████████████▋         | 58/84 [04:17<01:56,  4.48s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 70%|█████████████████████         | 59/84 [04:21<01:50,  4.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 71%|█████████████████████▍        | 60/84 [04:26<01:45,  4.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 73%|█████████████████████▊        | 61/84 [04:30<01:40,  4.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 74%|██████████████████████▏       | 62/84 [04:34<01:35,  4.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 75%|██████████████████████▌       | 63/84 [04:39<01:31,  4.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 76%|██████████████████████▊       | 64/84 [04:43<01:27,  4.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 77%|███████████████████████▏      | 65/84 [04:47<01:22,  4.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 79%|███████████████████████▌      | 66/84 [04:52<01:18,  4.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 80%|███████████████████████▉      | 67/84 [04:56<01:13,  4.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 81%|████████████████████████▎     | 68/84 [05:00<01:09,  4.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 82%|████████████████████████▋     | 69/84 [05:05<01:05,  4.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 83%|█████████████████████████     | 70/84 [05:09<01:01,  4.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 85%|█████████████████████████▎    | 71/84 [05:14<00:57,  4.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 86%|█████████████████████████▋    | 72/84 [05:18<00:52,  4.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 87%|██████████████████████████    | 73/84 [05:22<00:48,  4.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 88%|██████████████████████████▍   | 74/84 [05:27<00:43,  4.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 89%|██████████████████████████▊   | 75/84 [05:31<00:39,  4.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 90%|███████████████████████████▏  | 76/84 [05:36<00:34,  4.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 92%|███████████████████████████▌  | 77/84 [05:40<00:30,  4.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 93%|███████████████████████████▊  | 78/84 [05:44<00:26,  4.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 94%|████████████████████████████▏ | 79/84 [05:49<00:21,  4.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 95%|████████████████████████████▌ | 80/84 [05:53<00:17,  4.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 96%|████████████████████████████▉ | 81/84 [05:57<00:13,  4.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 98%|█████████████████████████████▎| 82/84 [06:02<00:08,  4.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 99%|█████████████████████████████▋| 83/84 [06:06<00:04,  4.40s/it]
100%|██████████████████████████████| 84/84 [06:10<00:00,  4.36s/it]

## Finishing Time: 09-12 21:16:32
= = = = = = = = = = = = = = = = = = = =
Done!
