["{\n  \"task_steps\": [\n    \"Load example.jpg as input image\",\n    \"Generate empty output image with the same dimensions as input image\",\n    \"Use Text-to-Image API to create a sunset image from the given text 'A beautiful sunset over the mountains'\",\n    \"Use Image Editing API to add mountains to the sunset image\",\n    \"Save the final output image as example.jpg\"\n  ],\n  \"task_nodes\": [\n    \"Text-to-Image\",\n    \"Image Editing\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Text-to-Image\", \"target\": \"Image Editing\"}\n  ]\n}", "{\n    \"task_steps\": [\n        \"Step 1: Text-to-Image: Generate an image of a beautiful night city skyline with tall buildings and bright lights using a Text-to-Image model.\",\n        \"Step 2: Image Segmentation: Segment the objects in the generated image using an Image Segmentation model.\",\n        \"Step 3: Image-to-Image: Transform the segmented image into a watercolor painting style using an Image-to-Image model.\",\n        \"Step 4: Image Editing: Change the color of the sky in the watercolor painting image from dark to a more bluish tone using an Image Editing tool.\"\n    ],\n    \"task_nodes\": [\n        \"Text-to-Image\",\n        \"Image Segmentation\",\n        \"Image-to-Image\",\n        \"Image Editing\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Text-to-Image\", \"target\": \"Image Segmentation\"},\n        {\"source\": \"Image Segmentation\", \"target\": \"Image-to-Image\"},\n        {\"source\": \"Image-to-Image\", \"target\": \"Image Editing\"}\n    ]\n}", "{\n  \"task_steps\": [\n    \"Load 'example.jpg' image into memory\",\n    \"Preprocess the image for segmentation\",\n    \"Invoke Image Segmentation API to segment objects in the image\",\n    \"Postprocess the segmented image results\",\n    \"Save the segmented image results to a new file\"\n  ],\n  \"task_nodes\": [\n    \"Image Classification: Preprocessing\",\n    \"Image Segmentation: Object Detection\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification: Preprocessing\", \"target\": \"Image Segmentation: Object Detection\"}\n  ]\n}", "```json\n{\n  \"task_steps\": [\n    \"Load the image 'example.jpg' using an Image Classification API to detect objects in the image.\",\n    \"Use an Object Detection API to identify and label the objects in the image.\",\n    \"Use a Text-to-Image API to generate a new image based on the detected object labels.\",\n    \"Use an Image Classification API to determine the dominant color of the main object in the generated image.\",\n    \"Use a Text-to-Speech API to output the answer 'The main color of the object is [dominant color]'.\"\n  ],\n  \"task_nodes\": [\n    \"Image Classification: Object Detection\",\n    \"Image Manipulation: Text-to-Image\",\n    \"Image Classification: Color Detection\",\n    \"Text-to-Speech\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification: Object Detection\", \"target\": \"Image Manipulation: Text-to-Image\"},\n    {\"source\": \"Image Manipulation: Text-to-Image\", \"target\": \"Image Classification: Color Detection\"},\n    {\"source\": \"Image Classification: Object Detection\", \"target\": \"Image Classification: Color Detection\"},\n    {\"source\": \"Image Classification: Color Detection\", \"target\": \"Text-to-Speech\"}\n  ]\n}\n```", "{\n  \"task_steps\": [\n    \"Read the input text document.\",\n    \"Identify the key phrases and entities in the document using Named Entity Recognition (NER) and Part-of-Speech (POS) tagging.\",\n    \"Extract the relevant sentences related to the history of computers and the individuals mentioned as potential 'fathers of the modern computer'.\",\n    \"Apply Text Classification to label each sentence as 'relevant' or 'irrelevant' to the user's question.\",\n    \"Extract the answer from the relevant sentences using Question Answering techniques.\",\n    \"Output the answer: 'Who is known as the father of the modern computer?'\"\n  ],\n  \"task_nodes\": [\n    \"Text Classification\",\n    \"Question Answering\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Text Classification\", \"target\": \"Question Answering\"}\n  ]\n}", "{\n    \"task_steps\": [\n        \"Load the image 'example.jpg' and perform image preprocessing.\",\n        \"Perform object detection to locate the table in the image.\",\n        \"Perform image segmentation to extract the table region.\",\n        \"Perform tabular classification to identify the type of table and its structure.\",\n        \"Extract the text content from the table using OCR (Optical Character Recognition).\"\n    ],\n    \"task_nodes\": [\n        \"Image Classification: Image-to-Tabular\",\n        \"Text Generation: Tabular-to-Text\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Image Classification: Image-to-Tabular\", \"target\": \"Text Generation: Tabular-to-Text\"}\n    ]\n}"]
["{\n    \"task_steps\": [\n        \"Load the image 'example.jpg' for processing.\",\n        \"Apply image-to-painting transformation to the loaded image.\",\n        \"Perform object detection on the transformed image to identify the object present.\",\n        \"Extract the identified object from the image.\",\n        \"Perform text-based object history lookup using the reference text 'In the 18th century, the Grand Piano was invented by an Italian harpsichord maker named Bartolomeo Cristofori. His invention was a breakthrough in the world of music, enabling composers and musicians to produce a wider range of sounds and dynamics.'\",\n        \"Match the extracted object with the text-based lookup results.\",\n        \"Output the identified object and its historical context.\"\n    ],\n    \"task_nodes\": [\n        \"Image-to-Text (Text-based object history lookup)\",\n        \"Text-to-Image (Image-to-painting transformation)\",\n        \"Object Detection\",\n        \"Text Generation (Output historical context)\",\n        \"Image Classification (Identify object type)\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Text-to-Image\", \"target\": \"Image Classification\"},\n        {\"source\": \"Object Detection\", \"target\": \"Text-to-Image\"},\n        {\"source\": \"Text-to-Image\", \"target\": \"Output historical context\"},\n        {\"source\": \"Output historical context\", \"target\": \"Text Generation\"},\n        {\"source\": \"Image Classification\", \"target\": \"Object Detection\"}\n    ]\n}", "{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Perform document image recognition to extract text from the image.\",\n            \"task_name\": \"Document Question Answering\"\n        },\n        {\n            \"step_description\": \"Use Text Summarization to identify the main topics in the extracted text.\",\n            \"task_name\": \"Text Summarization\"\n        },\n        {\n            \"step_description\": \"Use Question Answering to determine the answer to the given question based on the identified main topics.\",\n            \"task_name\": \"Question Answering\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Document Question Answering\",\n        \"Text Summarization\"\n    ],\n    \"task_links\": [\n        {\n            \"source\": \"Image Classification\",\n            \"target\": \"Document Question Answering\"\n        },\n        {\n            \"source\": \"Document Question Answering\",\n            \"target\": \"Text Summarization\"\n        },\n        {\n            \"source\": \"Text Summarization\",\n            \"target\": \"Question Answering\"\n        }\n    ]\n}\n\n# EXPLANATION #:\n# The user request involves understanding the main topic of a document given as an image. To accomplish this, we will first perform document image recognition to extract text from the image.\n# Next, we will use text summarization to identify the main topics in the extracted text. Finally, we will use question answering to determine the answer to the given question based on the identified main topics.\n# The task steps and task nodes are aligned, and the task links reflect the dependencies among the tasks.\n# Note: Image Classification is assumed to be performed beforehand to ensure the provided image is indeed a document image", "```json\n{\n  \"task_steps\": [\n    {\n      \"step_description\": \"Decode the text from the example.jpg image using an OCR (Optical Character Recognition) model.\",\n      \"task_name\": \"Image-to-Text\"\n    },\n    {\n      \"step_description\": \"Preprocess and clean the extracted text from the OCR model.\",\n      \"task_name\": \"Text Preprocessing\"\n    },\n    {\n      \"step_description\": \"Perform question answering task to determine the main topic being discussed in the text.\",\n      \"task_name\": \"Question Answering\"\n    },\n    {\n      \"step_description\": \"Classify the tokens in the text using a token classification model.\",\n      \"task_name\": \"Token Classification\"\n    },\n    {\n      \"step_description\": \"Generate a conversational response based on the question and answer.\",\n      \"task_name\": \"Conversational\"\n    }\n  ],\n  \"task_nodes\": [\n    \"Image-to-Text\",\n    \"Text Preprocessing\",\n    \"Question Answering\",\n    \"Token Classification\",\n    \"Conversational\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image-to-Text\", \"target\": \"Text Preprocessing\"},\n    {\"source\": \"Text Preprocessing\", \"target\": \"Question Answering\"},\n    {\"source\": \"Question Answering\", \"target\": \"Token Classification\"},\n    {\"source\": \"Token Classification\", \"target\": \"Conversational\"}\n  ]\n}\n```", "{\n  \"task_steps\": [\n    \"Load the example.jpg image\",\n    \"Apply image editing to change the background color to blue\",\n    \"Apply image editing to change the main object color to green\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image Editing\"\n    }\n  ],\n  \"task_links\": [\n    {\n      \"source\": \"Image Classification\",\n      \"target\": \"Image Editing\"\n    },\n    {\n      \"source\": \"Image-to-Image\",\n      \"target\": \"Image Editing\"\n    }\n  ]\n}\n\n# Explanation:\n# The user request can be solved by using Image Editing task. To fulfill the user request, we first need to identify the main object in the image and then apply color editing to change the background and the main object color.\n# Since the user request does not specify any particular image classification model or any specific image-to-image model, we assume that Image Classification and Image-to-Image tasks will be used to identify the main object and apply color editing respectively.\n# Therefore, we link Image Classification and Image-to-Image tasks to Image Editing task in the task graph.\n# The task steps are described in the task_steps array, and the task nodes and task links are described in the task_nodes and task_links arrays respectively.", "{\n  \"task_steps\": [\n    \"Load the audio file 'example.wav' using an Audio File Loader API.\",\n    \"Perform Automatic Speech Recognition (ASR) on the loaded audio file using an ASR API.\",\n    \"Preprocess the transcribed text using Text Preprocessing API.\",\n    \"Use a Text-to-Speech (TTS) API to generate more natural sounding speech from the preprocessed text.\"\n  ],\n  \"task_nodes\": [\n    \"Automatic Speech Recognition\",\n    \"Text Preprocessing\",\n    \"Text-to-Speech\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Audio File Loader\", \"target\": \"Automatic Speech Recognition\"},\n    {\"source\": \"Automatic Speech Recognition\", \"target\": \"Text Preprocessing\"},\n    {\"source\": \"Text Preprocessing\", \"target\": \"Text-to-Speech\"}\n  ]\n}", "{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Load the image 'example.jpg' for object detection.\"\n        },\n        {\n            \"step_description\": \"Invoke the Image Classification API to preprocess the image and extract features.\"\n        },\n        {\n            \"step_description\": \"Invoke the Object Detection API to detect and label objects in the image using the extracted features.\"\n        },\n        {\n            \"step_description\": \"Save the output of object detection as a new file.\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Image Classification\",\n        \"Object Detection\"\n    ],\n    \"task_links\": [\n        {\n            \"source\": \"Image Classification\",\n            \"target\": \"Object Detection\"\n        }\n    ]\n}"]
["```json\n{\n  \"task_steps\": [\n    \"Load the input image\",\n    \"Perform image preprocessing to enhance text recognition\",\n    \"Use an Image-to-Text model to extract text from the image\",\n    \"Post-process the extracted text to remove any unwanted characters or formatting\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image Classification\"\n    },\n    {\n      \"task_name\": \"Image-to-Text\"\n    },\n    {\n      \"task_name\": \"Text Preprocessing\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification\", \"target\": \"Image-to-Text\"},\n    {\"source\": \"Image-to-Text\", \"target\": \"Text Preprocessing\"}\n  ]\n}\n```\n\nExplanation:\n\n1. The user request is to extract text from an image.\n2. To accomplish this, we need to perform the following tasks:\n   a. Image Classification: To ensure that the input is indeed an image and not some other type of file.\n   b. Image-to-Text: To extract text from the image.\n   c. Text Preprocessing: To clean up the extracted text and remove any unwanted characters or formatting.\n3. The tasks are executed in the following sequence: Image Classification -> Image-to-Text -> Text Preprocessing.\n4. The task links reflect the dependencies among the tasks, i.e. Image Classification must be executed before Image-to-Text, and Image-to-Text must be executed before Text Preprocessing.", "{\n    \"task_steps\": [\n        \"Load image example.jpg\",\n        \"Perform object detection on the image using Object Detection task\",\n        \"Extract descriptions of detected objects\",\n        \"Convert object descriptions to audio using Text-to-Speech task\",\n        \"Classify audio for emotions or context using Emotion or Context Classification task\",\n        \"Extract specific entities from the classified text using Named Entity Recognition task\"\n    ],\n    \"task_nodes\": [\n        \"Object Detection\",\n        \"Text-to-Speech\",\n        \"Emotion or Context Classification\",\n        \"Named Entity Recognition\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Object Detection\", \"target\": \"Text-to-Speech\"},\n        {\"source\": \"Text-to-Speech\", \"target\": \"Emotion or Context Classification\"},\n        {\"source\": \"Emotion or Context Classification\", \"target\": \"Named Entity Recognition\"}\n    ]\n}", "{\n  \"task_steps\": [\n    \"Load the image 'example.jpg' using an Image Loading API\",\n    \"Apply image editing to change the background color to light blue using an Image Editing API\",\n    \"Perform Object Detection on the edited image to identify and extract tables using an Object Detection API\",\n    \"Perform Tabular Classification on the extracted table to classify its contents using a Tabular Classification API\",\n    \"Extract the color information for apples from the classified table using a Text Extraction API\",\n    \"Determine the color of apples based on the extracted information using a Text Processing API\"\n  ],\n  \"task_nodes\": [\n    \"Image Classification or Image-to-Image: Change background color\",\n    \"Object Detection: Table Detection\",\n    \"Tabular Classification: Table Classification\",\n    \"Text Extraction: Extract color information\",\n    \"Text Processing: Determine color of apples\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification or Image-to-Image: Change background color\", \"target\": \"Object Detection: Table Detection\"},\n    {\"source\": \"Object Detection: Table Detection\", \"target\": \"Tabular Classification: Table Classification\"},\n    {\"source\": \"Tabular Classification: Table Classification\", \"target\": \"Text Extraction: Extract color information\"},\n    {\"source\": \"Text Extraction: Extract color information\", \"target\": \"Text Processing: Determine color of apples\"}\n  ]\n}", "{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Load and preprocess the tabular image file 'example.jpg' using an Image-to-Text API to extract text data from the table.\"\n        },\n        {\n            \"step_description\": \"Use a Tabular Classification API to classify and extract meaningful information from the tabular data.\"\n        },\n        {\n            \"step_description\": \"Use a Text-to-Speech API to generate an audio response based on the extracted information.\"\n        },\n        {\n            \"step_description\": \"Use an Automatic Speech Recognition API to transcribe the generated speech into text.\"\n        },\n        {\n            \"step_description\": \"Use a Conversational API to generate an intelligent conversational response based on the extracted information.\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Image-to-Text\",\n        \"Tabular Classification\",\n        \"Text-to-Speech\",\n        \"Automatic Speech Recognition\",\n        \"Conversational\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Image-to-Text\", \"target\": \"Tabular Classification\"},\n        {\"source\": \"Tabular Classification\", \"target\": \"Text-to-Speech\"},\n        {\"source\": \"Text-to-Speech\", \"target\": \"Automatic Speech Recognition\"},\n        {\"source\": \"Tabular Classification\", \"target\": \"Conversational\"}\n    ]\n}", "{\n  \"task_steps\": [\n    \"Load the image 'example.jpg' using an Image-to-Text model to extract text from the document.\",\n    \"Use a Document Question Answering model to identify and extract the total amount due information from the extracted text.\",\n    \"Output the total amount due as the final result.\"\n  ],\n  \"task_nodes\": [\n    \"Image-to-Text\",\n    \"Document Question Answering\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image-to-Text\", \"target\": \"Document Question Answering\"}\n  ]\n}", "```json\n{\n  \"task_steps\": [\n    \"Load and preprocess the document image containing the table.\",\n    \"Perform image-to-text extraction to obtain the table data as text.\",\n    \"Perform tabular classification to identify and extract the fruit and nutritional value columns.\",\n    \"Filter the extracted data to only include the fruit and Vitamin C values.\",\n    \"Perform text-to-number conversion on the Vitamin C values to obtain numerical data.\",\n    \"Find the fruit with the highest Vitamin C value.\",\n    \"Generate a response message to inform your friend about the fruit with the highest Vitamin C content.\"\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image-to-Text\"\n    },\n    {\n      \"task_name\": \"Tabular Classification\"\n    },\n    {\n      \"task_name\": \"Text-to-Number\"\n    },\n    {\n      \"task_name\": \"Question Answering\"\n    },\n    {\n      \"task_name\": \"Text Generation\"\n    }\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification\", \"target\": \"Image-to-Text\"},\n    {\"source\": \"Text-to-Number\", \"target\": \"Question Answering\"},\n    {\"source\": \"Question Answering\", \"target\": \"Text Generation\"}\n  ]\n}\n```\n\nThis JSON format represents the task steps, task nodes, and task links required to fulfill the user's request. The task steps describe the actions needed to be taken, while the task nodes represent the specific tasks to be executed in sequence. The task links indicate the dependencies between tasks, with the Image-to-Text task being a prerequis"]
["{\"task_steps\": [\n\"Read user request and understand the requirement.\",\n\"Identify the task as Document Question Answering.\",\n\"Preprocess the user request by extracting the key query words: 'Greek philosophy' and 'brief explanation'.\",\n\"Invoke the Text-to-Speech API to read out the requested information for accessibility.\",\n\"Invoke the Document Question Answering API to extract the historical facts and key figures related to Greek philosophy.\",\n\"Invoke the Text Generation API to generate a brief and concise summary of the extracted information.\",\n\"Invoke the Text-to-Speech API again to read out the generated summary for the user.\",\n\"End the task.\"\n],\n\"task_nodes\": [\n\"Document Question Answering\",\n\"Text Generation\",\n\"Text-to-Speech (x2)\"\n],\n\"task_links\": [\n{\"source\": \"Document Question Answering\", \"target\": \"Text Generation\"},\n{\"source\": \"Text Generation\", \"target\": \"Text-to-Speech\"},\n{\"source\": \"Text-to-Speech\", \"target\": \"Document Question Answering\"},\n{\"source\": \"Text-to-Speech\", \"target\": \"Text-to-Speech\"}\n]\n}", "{\n    \"task_steps\": [\n        \"Read the document and identify the question.\",\n        \"Extract the relevant information from the document.\",\n        \"Identify the person named as 'the Father of the Computer' in the document.\",\n        \"Confirm the identified person as the answer to the question.\"\n    ],\n    \"task_nodes\": [\n        {\n            \"task_name\": \"Document Question Answering\"\n        },\n        {\n            \"task_name\": \"Text Preprocessing\"\n        },\n        {\n            \"task_name\": \"Information Extraction\"\n        },\n        {\n            \"task_name\": \"Named Entity Recognition\"\n        },\n        {\n            \"task_name\": \"Confirmation\"\n        }\n    ],\n    \"task_links\": [\n        {\"source\": \"Document Question Answering\", \"target\": \"Text Preprocessing\"},\n        {\"source\": \"Text Preprocessing\", \"target\": \"Information Extraction\"},\n        {\"source\": \"Information Extraction\", \"target\": \"Named Entity Recognition\"},\n        {\"source\": \"Named Entity Recognition\", \"target\": \"Confirmation\"},\n        {\"source\": \"Document Question Answering\", \"target\": \"Confirmation\"}\n    ]\n}", "```json\n{\n  \"task_steps\": [\n    \"Load the image 'example.jpg' using an Image Classification or Object Detection API to identify and extract the car from the image.\",\n    \"Use a Text-to-Image or Image-to-Text API to generate a description of the identified car, focusing on its color.\",\n    \"Apply a Text-to-Question Answering or Visual Question Answering API to extract the answer to the question 'What color is the car in the image?' from the generated description.\"\n  ],\n  \"task_nodes\": [\n    \"Image Classification or Object Detection\",\n    \"Text-to-Image or Image-to-Text\",\n    \"Text-to-Question Answering or Visual Question Answering\"\n  ],\n  \"task_links\": [\n    {\"source\": \"Image Classification or Object Detection\", \"target\": \"Text-to-Image or Image-to-Text\"},\n    {\"source\": \"Text-to-Image or Image-to-Text\", \"target\": \"Text-to-Question Answering or Visual Question Answering\"}\n  ]\n}\n```\n\nThis JSON format outlines the steps required to answer the user's question using a Visual Question Answering tool. The task nodes represent the APIs to be invoked in sequence, and the task links illustrate the dependencies between them.", "{\n    \"task_steps\": [\n        \"Load the image 'example.jpg' for processing.\",\n        \"Preprocess the image to prepare it for input to the image classification model.\",\n        \"Invoke the Image Classification API to classify the image.\",\n        \"Parse the output of the Image Classification API to extract the predicted class label.\"\n    ],\n    \"task_nodes\": [\n        \"Image Classification\"\n    ],\n    \"task_links\": [\n        {\n            \"source\": \"Text-to-Image\",\n            \"target\": \"Image Classification\"\n        },\n        {\n            \"source\": \"Image Classification\",\n            \"target\": \"Text-to-Speech\"\n        }\n    ]\n}\n\n# Explanation:\n# The user request can be fulfilled by performing image classification on the given image.\n# Therefore, the task nodes list contains only one task: \"Image Classification\".\n# The task steps describe the process of loading the image, preprocessing it, invoking the Image Classification API, and extracting the predicted class label.\n# Since there are no dependencies among the tasks, the task links are empty in this case.", "{\n    \"task_steps\": [\n        {\n            \"step_description\": \"Perform audio-to-speech conversion to enhance the audio quality of the given text using Text-to-Speech API.\",\n            \"task_name\": \"Text-to-Speech\"\n        },\n        {\n            \"step_description\": \"Play the enhanced audio to improve its quality using an Audio Editing tool.\",\n            \"task_name\": \"Image/Audio Editing\"\n        },\n        {\n            \"step_description\": \"Perform automatic speech recognition to transcribe the enhanced audio back into text using Automatic Speech Recognition API.\",\n            \"task_name\": \"Automatic Speech Recognition\"\n        }\n    ],\n    \"task_nodes\": [\n        \"Text-to-Speech\",\n        \"Image/Audio Editing\",\n        \"Automatic Speech Recognition\"\n    ],\n    \"task_links\": [\n        {\"source\": \"Text-to-Speech\", \"target\": \"Image/Audio Editing\"},\n        {\"source\": \"Image/Audio Editing\", \"target\": \"Automatic Speech Recognition\"}\n    ]\n}", "{\n  \"task_steps\": [\n    {\n      \"step_description\": \"Perform image-to-text conversion to extract text from the PDF image 'example.jpg'\",\n      \"task_name\": \"Image-to-Text\"\n    },\n    {\n      \"step_description\": \"Perform text-based question answering to extract the main topic of the document from the extracted text\",\n      \"task_name\": \"Document Question Answering\"\n    },\n    {\n      \"step_description\": \"Perform text-based question answering to extract the author's name from the extracted text\",\n      \"task_name\": \"Document Question Answering\"\n    }\n  ],\n  \"task_nodes\": [\n    {\n      \"task_name\": \"Image-to-Text\"\n    },\n    {\n      \"task_name\": \"Document Question Answering\"\n    }\n  ],\n  \"task_links\": [\n    {\n      \"source\": \"Image-to-Text\",\n      \"target\": \"Document Question Answering\"\n    }\n  ]\n}"]
